{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7788925f",
   "metadata": {},
   "source": [
    "# Random Variables and Discrete Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e107d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"../styles/styles.css\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5ef0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.special import comb\n",
    "import pandas as pd\n",
    "from ipywidgets import interact, FloatSlider, IntSlider\n",
    "from IPython.display import HTML, display, IFrame\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9d8825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the \"resources\" directory to the path\n",
    "project_root = Path().resolve().parent\n",
    "resources_path = project_root / 'resources'\n",
    "sys.path.insert(0, str(resources_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17199d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random_variable import(generate_click_data, visualize_rv_concept, coffee_example, coffee_example_mean_var, \n",
    "                            demo_markov_ineq, demo_markov_ineq_2, demo_schebyshev_ineq, demo_chebyshev_ineq_2, \n",
    "                            demo_pdf_cdf_discrete, demo_cdf_interval_discrete, comparison_discrete_rv, mystery_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36632cf5",
   "metadata": {},
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a0dbdd",
   "metadata": {},
   "source": [
    "- Understand random variables as functions from sample spaces to numbers\n",
    "- Master discrete probability distributions (Bernoulli, Binomial, Poisson)\n",
    "- Calculate expectations and variances\n",
    "- Apply distributions to ML scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f223efe8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h4>🎯 The Distribution Detective Problem</h3>\n",
    "\n",
    "You're analyzing user engagement data for a social media platform. You notice:\n",
    "- Average of 2 clicks per day per user\n",
    "- About 41% of users click 0-1 times\n",
    "- Clicks per day range from 0 to 10+\n",
    "- The distribution has a long right tail\n",
    "\n",
    "Your boss asks: \"Model this data. Which distribution should we use?\"\n",
    "\n",
    "Choices:\n",
    "<ul>\n",
    "<li>(a) Binomial distribution (n=50, p=0.05)</li>\n",
    "<li>(b) Poisson distribution (λ=2)</li>\n",
    "<li>(c) Normal distribution (μ=2, σ=5)</li>\n",
    "</ul>\n",
    "\n",
    "Most beginners pick Normal because \"*it's always normal, right?*\"\n",
    "\n",
    "Wrong. By the end of today, you'll understand WHY distribution choice matters.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e6b06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise demo data\n",
    "generate_click_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f962d3",
   "metadata": {},
   "source": [
    "## What is a Random Variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbb57ca",
   "metadata": {},
   "source": [
    "The raw sample space $\\Omega$ can be awkward to work with. For example:\n",
    "- Coin flip: $\\Omega = \\{heads,tails\\}$  - how do you calculate an average of \"heads\"?\n",
    "- Card draw: $\\Omega = \\{A♠, K♠, ..., 2♣\\}$ - what's the expected value of a \"queen\"?\n",
    "\n",
    "By defining **a random variable**, you create a bridge from the abstract to the numerical. But a random variable is NOT like algebraic variables you know!\n",
    "\n",
    "Think of it as a FUNCTION that maps outcomes to numbers:\n",
    "- Sample space $\\Omega$ (abstract outcomes) $\\rightarrow$ Real numbers $\\mathrm{R}$ (quantifiable values)\n",
    "\n",
    "<center>\n",
    "<img src=\"img/rv.png\" alt=\"Random variable as a function\" width=\"800px\">\n",
    "</center>\n",
    "\n",
    "Examples: \n",
    "\n",
    "1. Coin toss\n",
    "- Sample space: $\\Omega = {Heads, Tails}$\n",
    "- Random variable $X: Heads \\rightarrow 1, Tails \\rightarrow 0$\n",
    "- Now we can do math compute probabilities and means: $E[X] = 0.5$, $Var(X) = 0.25$\n",
    "\n",
    "2. Card draw:\n",
    "- $\\Omega = \\{A♠, K♠, ..., 2♣\\}$\n",
    "- Random variable: $X(card) = \\text{value of card}$\n",
    "- Now you can analyze expected winnings\n",
    "\n",
    "3. In ML: \"Label for this image\" is a random variable!\n",
    "- Sample space: All possible images\n",
    "- Random variable $Y: Image \\rightarrow {0=cat, 1=dog}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948b3fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coin flipping visualisation\n",
    "visualize_rv_concept()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0effdbeb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4>Definition: Random Variable</h4>\n",
    "\n",
    "Let $\\mathcal{A}$ be a set of events associated with the sample space $\\Omega$, called **sigma-algebra** or **$\\sigma$-algebra**, satisfying the following properties:\n",
    "\n",
    "* $\\Omega \\in \\mathcal{A}$\n",
    "* $A \\in \\mathcal {A} \\Rightarrow A^c \\in \\mathcal{A}$\n",
    "* $\\forall i \\in \\mathbb{N},  A_i \\in \\mathcal{A} \\Rightarrow \\cup_{i\\in \\mathbb{N}} A_i \\in \\mathcal{A}$\n",
    "\n",
    "For finite or countably infinite $\\Omega$, we often consider $\\mathcal{A} = \\mathcal{P}(\\Omega)$.\n",
    "\n",
    "For $\\Omega = \\mathbb{R}$: $\\mathcal{A} = \\mathcal{B}(\\mathbb{R})$ where $\\mathcal{B}(\\mathbb{R})$ is a set of Borel sets, i.e., the set of parts of $\\mathbb{R}$ generated by intervals of $\\mathbb{R}$.\n",
    "\n",
    "Let $(\\Omega, \\mathcal{A})$ be an event space of the probability space $(\\Omega, \\mathcal{A}, \\mathbb{P})$ and $(E, \\mathcal{E})$ a measurable space. A **random variable, r.v.** $X$ from $\\Omega$ to $E$ is a measurable function:\n",
    "$$X : \\Omega \\rightarrow E$$\n",
    "\n",
    "such that:\n",
    "\n",
    "$$\\forall A' \\in \\mathcal{E}, X^{-1}(A') \\in \\mathcal{A}$$\n",
    "\n",
    "where $X^{-1}(A')$ is the preimage (inverse image) $X^{-1}(A') = \\{\\omega\\in \\Omega | X(\\omega)\\in A'\\}\\in \\mathcal{A}$.\n",
    "\n",
    "Often, we will consider the case where $E \\subset \\mathbb{R}$. A **real-valued random variable** (or **real random variable**) on the event space $(\\Omega, \\mathcal{A})$ is a measurable function $X : \\Omega \\rightarrow \\mathbb{R}$, such that:\n",
    "$$\\forall x\\in \\mathbb{R}, X^{-1}(]-\\infty, x])\\in \\mathcal{A}$$\n",
    "\n",
    "**Remark:** By convention, capital letters are used for the notation of random variables.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d2b140",
   "metadata": {},
   "source": [
    "## Types of Random Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9ce34c",
   "metadata": {},
   "source": [
    "> What are the values of a real random variable $X$?\n",
    "\n",
    "Depending on the value a random variable can take, we distinguish different types of random variables.\n",
    "\n",
    "|| DISCRETE r.v. | CONTINUOUS r.v. |\n",
    "|----|-----------|---------|\n",
    "|**Type of values**| Countable values (finite or countably infinite)|Uncountably infinite values (intervals)|\n",
    "|**Examples**|Number of clicks, defective items, network packets, number of TikTok posts published in the next hour|Weight, temperature, time duration, (exact) height cleared by the athlete winning the pole vault at the next Olympic Games, level of global warming reached around 2030|\n",
    "|**Use in ML**|Classification labels, token counts, layer depth|Neural network weights, loss values, confidence scores|\n",
    "\n",
    "</br>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<h4>Definition: Discrete r.v.</h4>\n",
    "\n",
    "A real r.v. $X$ is called **discrete** if it takes only a countable and/or finite number of values in $\\mathbb{R}$, i.e. $X(\\Omega) = \\left\\{x_j\\in \\mathbb{R}, j\\in J\\right\\}$ with $J \\subset \\mathbb{N}$.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<h4>Definition: Continuous r.v.</h4>\n",
    "\n",
    "In the general case, a real r.v. $X$ is called **continuous** if its image is uncountably infinite (often an interval).\n",
    "\n",
    "In the more concrete case, it concerns *absolute continuity* (in the Lebesgue sense).\n",
    "\n",
    "</div>\n",
    "\n",
    "In this session, we focus on DISCRETE r.v.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670cfccd",
   "metadata": {},
   "source": [
    "## Probability Distribution, Probability Mass Function (PMF) and Cumulative Distribution Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6fda6c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4>Definition: Probability Distribution</h4>\n",
    "\n",
    "A space $(\\Omega, \\mathcal{A})$ is equipped with a probability measure $\\mathbb{P}$ in the probability space $(\\Omega, \\mathcal{A}, \\mathbb{P})$. Thanks to the measurability of the random variable $X$, it is possible to define the probability $\\mathbb{P}_X: \\mathcal{E} \\rightarrow [0,1]$ (also called **the probability law of the r.v. $X$** or just **law of the r.v. $X$** or **probability distribution**) on the measurable space $(E, \\mathcal{E})$:\n",
    "$$\\forall A'\\in \\mathcal{E}, \\ \\ \\mathbb{P}_X(A') = \\mathbb{P}(X^{-1}(A')) = \\mathbb{P}(X\\in A')$$\n",
    "\n",
    "Thus, a probability law is a function that describes the probability of occurrence of possible outcomes of the random experiment.\n",
    "\n",
    "</div>\n",
    "\n",
    "In the general case, we can speak of the distribution function that characterizes the probability law.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a82dd3",
   "metadata": {},
   "source": [
    "<a id=\"cdf\"></a>\n",
    "<div class=\"alert alert-success\">\n",
    "<h4>Definition: Cumulative Distribution Function (CDF)</h4>\n",
    "\n",
    "Let $X$ be a real r.v. on the probability space $(\\Omega, \\mathcal{A}, \\mathbb{P})$. We call **the cumulative distribution function of a real r.v. $X$** (or **CDF**) the application $F_X$ which for $\\forall x\\in \\mathbb{R}$ associates the probability of obtaining a value less than or equal to $x$, i.e.:\n",
    "$$F_X: \\ \\left.\n",
    "    \\begin{array}{ll}\n",
    "        \\mathbb{R}\\rightarrow [0,1]  \\\\\n",
    "        x \\rightarrow \\mathbb{P}(X^{-1}(]-\\infty,x]))\n",
    "    \\end{array}\n",
    "\\right.\n",
    "$$\n",
    "In other words, $F_X(x) = \\mathbb{P}(X\\leq x)$, i.e. it answers a simple question *What's the probability that my random variable is at most this value?* or *What fraction of outcomes fall to the left of $x$?*\n",
    "\n",
    "*Intuition*: The CDF can be seen a *running total* or *accumulator of probability* as you sweep from left to right along the number line. \n",
    "\n",
    "For discrete random variables, the CDF is a STEP FUNCTION that jumps by $p(x_i)$ at each possible value $x_i$.\n",
    "\n",
    "<h5>Basic Properties of the CDF</h5>\n",
    "\n",
    "* $F_X$ is always increasing, i.e. $\\forall (a,b)\\in \\mathbb{R}^2,\\ a \\leq b \\Rightarrow F_X(a) \\leq F_X(b)$\n",
    "* $F_X$ is right-continuous\n",
    "* $\\lim\\limits_{x\\rightarrow-\\infty} F_X(x) = 0$ and $\\lim\\limits_{x\\rightarrow+\\infty} F_X(x) = 1$\n",
    "\n",
    "Note that $F_X$ is a bounded monotonic function:\n",
    "$$\\forall x\\in \\mathbb{R}, \\ 0\\leq F_X(x)\\leq 1$$\n",
    "\n",
    "The distribution function allows us to calculate the probability of a real r.v. $X$ being included in a left half-open interval $]a,b]$ where $a < b$ as follows:\n",
    "$$\\mathbb{P}(X \\in ]a,b]) = \\mathbb{P}(a < X \\leq b) = F_X(b)-F_X(a)$$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554fc60f",
   "metadata": {},
   "source": [
    "Suppose we are interested in the number of cups of coffee a student drinks before the lunch break.\n",
    "\n",
    "In the table, we present all values with non-zero probability. In our case, these are: $1$, $2$, $3$, $4$, $5$. Suppose also that we know the probability of each of its values. Let's write them in the same table.\n",
    "\n",
    "|$x$| $1$ | $2$ | $3$ | $4$ | $5$ |\n",
    "|--:|:--:|:--:|:--:|:--:|:--:|\n",
    "|$P(X=x)$| $0.4$ | $0.25$ | $0.2$ | $0.1$| $0.05$|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4412faff",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4>Definition: Probability Mass Function (PMF)</h4>\n",
    "\n",
    "Let $X$ be a discrete real r.v., $X(\\Omega) = \\left\\{x_j\\in \\mathbb{R}, j\\in J\\right\\}$ with $J \\subset \\mathbb{N}$. **The probability mass function of the real r.v. $X$** (or **pmf**) is an application $p$ such that:\n",
    "$$p \\ \\left.\n",
    "    \\begin{array}{ll}\n",
    "        J\\rightarrow [0,1]  \\\\\n",
    "        j \\rightarrow p_j\n",
    "    \\end{array}\n",
    "\\right.$$\n",
    "where $p_j = \\mathbb{P}(X = x_j)$, considering that $\\forall j \\in \\mathbb{N}\\setminus J, \\ p_j = 0$.\n",
    "\n",
    "The mass function $p$ has the following properties:\n",
    "\n",
    "* $\\forall j\\in J, \\ p_j \\geq 0,\\ p_j \\in [0,1]$\n",
    "* $\\sum\\limits_{j \\in \\mathbb{N}} p_j = 1$\n",
    "\n",
    "*Intuition*: \"How much probability MASS sits at each point?\"\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a373e9",
   "metadata": {},
   "source": [
    "Let's check if the conditions of PMF are verified for our example:\n",
    "\n",
    "1. $\\forall j\\in J, \\ p_j \\geq 0,\\ p_j \\in [0,1]$: $\\left\\{\\begin{aligned}0.4 \\geq 0 \\\\0.25\\geq 0 \\\\0.2 \\geq 0 \\\\ 0.1 \\geq 0 \\\\ 0.05 \\geq 0\\end{aligned}\\right.\\ \\checkmark$\n",
    "2. $\\sum\\limits_{j \\in \\mathbb{N}} p_j = 1$: $0.4 + 0.25 + 0.2 + 0.1 + 0.05 = 1\\ \\checkmark$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a66f12",
   "metadata": {},
   "source": [
    "Now, let's calculate the CDF.\n",
    "\n",
    "|$x$| $1$ | $2$ | $3$ | $4$ | $5$ |\n",
    "|--:|:--:|:--:|:--:|:--:|:--:|\n",
    "|$P(X=x)$| $0.4$ | $0.25$ | $0.2$ | $0.1$| $0.05$|\n",
    "|$P(X \\leq x)$ | $0.4$ | $0.4 + 0.25 = 0.65$ | $0.4 + 0.25 + 0.2 = 0.85$ | $0.4 + 0.25 + 0.2 + 0.1 = 0.95$ | $0.4 + 0.25 + 0.2 + 0.1 + 0.05 = 1$|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c61a539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IFrame(src='img/cdf_animation_html.html', width=700, height=400)\n",
    "HTML(filename='img/cdf_animation_html.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad2fc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example \n",
    "coffees = np.array([1, 2, 3, 4, 5])\n",
    "# probabilities \n",
    "probs = np.array([0.4, 0.25, 0.2, 0.1, 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad50bd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PMF and CDF of coffee example\n",
    "coffee_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed73dc8",
   "metadata": {},
   "source": [
    "Let's consider the following example:\n",
    "\n",
    "We are interested in the number of successful API calls out of 5 attempts. \n",
    "\n",
    "| $x$ | 0 | 1 | 2 | 3 | 4 | 5 |\n",
    "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| $P(X = x)$ | 0.0102 |  0.0768 | 0.2304 | 0.3456 | 0.2592 | 0.0778 |\n",
    "\n",
    "Calculate CDF, and visualise PMF and CDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f09ede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0, 1, 2, 3, 4, 5])\n",
    "# PMF\n",
    "prob_x = np.array([0.0102, 0.0768, 0.2304, 0.3456, 0.2592, 0.0778])\n",
    "# CDF\n",
    "cdf_x = np.cumsum(prob_x)\n",
    "print(f\"CDF: {cdf_x}\")\n",
    "# visualise PMF\n",
    "plt.stem(x, prob_x, linefmt='b-', markerfmt='bo', basefmt=' ', label='PMF p(x)')\n",
    "plt.title(\"PMF: Probability Mass Function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635bf727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise CDF\n",
    "plt.step(x, cdf_x, where='post', linewidth=2.5, color='red', label='CDF')\n",
    "plt.title(\"CDF: Cumulative Distribution Function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8477088",
   "metadata": {},
   "source": [
    "Let's consider the following example. We are interested in the number of successful API calls out of 5 attempts. \n",
    "\n",
    "|$x$| 0| 1|2|3|4|5|\n",
    "|--|:--:|:--:|:--:|:--:|:--:|:--:|\n",
    "|$P(X=x)$|0.0102|0.0768|0.2304|0.3456|0.2592|0.0778|\n",
    "\n",
    "Let's calculate the CDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51134c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Number of successful API calls out of 5 attempts\n",
    "f1, f2 = demo_pdf_cdf_discrete()\n",
    "# construction of CDF step by step\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d734747b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PMF and CDF of Binomial Distribution\n",
    "f2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679b414b",
   "metadata": {},
   "source": [
    "Now, let's calculate the CDF on the interval: $F(1 < X \\leq 4)$. As mentioned above (see Section [CDF](#cdf)) $\\mathbb{P}(a < X \\leq b) = F_X(b)-F_X(a)$:\n",
    "\n",
    "1. Option 1: as we are interested in $a < X \\leq b$, then the set of favourable values of $X$ is $\\{2, 3, 4\\}$. Then we can apply direct summation:\n",
    "\n",
    "$\\mathbb{P}(a < X \\leq b) = \\mathbb{P}(X = 2) + \\mathbb{P}(X = 3) + \\mathbb{P}(X = 4) = 0.2304 + 0.3456 + 0.2592 = 0.8352$\n",
    "\n",
    "2. Option 2: Using CDF formula\n",
    "\n",
    "$$F(4) = \\mathbb{P}(X \\leq 4) = 0.9222$$\n",
    "\n",
    "$$F(1) = \\mathbb{P}(X \\leq 1) = 0.0870$$\n",
    "\n",
    "$$\\mathbb{P}(1 < X \\leq 4) = F_X(4)-F_X(1) = 0.9222 - 0.0870 = 0.8352$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c16a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CDF on the interval\n",
    "demo_cdf_interval_discrete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c93073",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-primary\">\n",
    "<h4>🤖 ML Applications</h4>\n",
    "<p>PMF models discrete predictions:</p>\n",
    "\n",
    "<ul>\n",
    "<li>Softmax output: p(class=k) for k ∈ {0,1,...,9} in digit classification</li>\n",
    "<li>Token probabilities in language models</li>\n",
    "<li>Batch accuracy: P(correct predictions = k) in batch of size n\\n\")</li>\n",
    "</ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f8addc",
   "metadata": {},
   "source": [
    "## Numerical Indicators. Expectation (Mean) and Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e849d0b8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4>Definition: Expected Value</h4>\n",
    "\n",
    "**The expectation** (or **expected value** or **mean** or **average** or **first moment**) of a real r.v. $X$, denoted $\\mathbb{E}X$ or $\\mathbb{E}[X]$ or $\\mathbb{E}(X)$ is a generalization of the weighted average value. It can also be seen as the \"center of mass\" of the distribution.\n",
    "\n",
    "Its calculation (when this quantity exists) depends on the nature of $X$:\n",
    "\n",
    "* discrete real r.v.:\n",
    "$\\mathbb{E}[X] = \\sum_i x_ip_i = \\sum_i x_iP(X=x)$\n",
    "\n",
    "Note that these definitions can be generalized for the expectation of a real r.v. $g(X)$, where $g : X(\\Omega) \\rightarrow \\mathbb{R}$:\n",
    "\n",
    "* discrete case: $\\mathbb{E}[g(X)] = \\sum_i g(x_i)p_i = \\sum_i g(x_i)P(X=x)$\n",
    "\n",
    "\n",
    "<h5>Properties:</h5>\n",
    "\n",
    "* $\\mathbb{E}[X] \\geq 0$\n",
    "* $\\mathbb{E}[X + Y] = \\mathbb{E}[X] + \\mathbb{E}[Y]$\n",
    "* $\\mathbb{E}[aX + b] = a\\mathbb{E}[X] + b$\n",
    "\n",
    "Note that these results can be generalized for the expectation of a real r.v. $g(X)$, where $g : X(\\Omega) \\rightarrow \\mathbb{R}$:\n",
    "\n",
    "* $\\mathbb{E}[g(X)] \\geq 0$\n",
    "* $\\mathbb{E}[g_1(X) + g_2(X)] = \\mathbb{E}[g_1(X)] + \\mathbb{E}[g_2(X)]$\n",
    "* $\\mathbb{E}[ag(X)] = a\\mathbb{E}[g(X)] + b$\n",
    "* let $X$ be a continuous real r.v., $g_1$ and $g_2$ two functions such that $g_1 \\leq g_2$, then $\\mathbb{E}[g_1(X)] \\leq \\mathbb{E}[g_2(X)]$\n",
    "* if $X$ is a constant real r.v. on $\\Omega$ and $g$ any function, then $\\mathbb{E}[g(X)] = g(X)$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e590c59",
   "metadata": {},
   "source": [
    "Let's calculate the expected value for our example:\n",
    "\n",
    "|$x$| $1$ | $2$ | $3$ | $4$ | $5$ |\n",
    "|--:|:--:|:--:|:--:|:--:|:--:|\n",
    "|$P(X=x)$| $0.4$ | $0.25$ | $0.2$ | $0.1$| $0.05$|\n",
    "|$P(X \\leq x)$ | $0.4$ | $0.4 + 0.25 = 0.65$ | $0.4 + 0.25 + 0.2 = 0.85$ | $0.4 + 0.25 + 0.2 + 0.1 = 0.95$ | $0.4 + 0.25 + 0.2 + 0.1 + 0.05 = 1$|\n",
    "|$xP(X=x)$|$1\\times 0.4 = 0.4$| $2\\times 0.25 = 0.5$ | $3\\times 0.2 = 0.6$ | $4\\times 0.1 = 0.4$ | $5\\times 0.05 = 0.25$|\n",
    "\n",
    "Thus, \n",
    "$$\\mathbb{E}[X] = \\sum_i x_ip_i = \\sum_i x_iP(X=x) = 0.4 + 0.5 + 0.6 + 0.4 + 0.25 = 2.15$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb4ac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "expected_val = sum(coffees * probs)\n",
    "print(f\"Expected value E(X) = {expected_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd743a7",
   "metadata": {},
   "source": [
    "<div class=\"alert .alert-exercise\">\n",
    "<h4>Calculated Example</h4>\n",
    "\n",
    "If each time you get *heads* when tossing a coin, you win 5 euros, and each time you get *tails*, you lose 5 euros. What is the average gain or in other words, the expectation of gain?\n",
    "\n",
    "</div>\n",
    "\n",
    "<details>\n",
    "<summary>Reveal Solution</summary>\n",
    "\n",
    "$\\mathbb{E}[X] = \\sum_i x_ip_i = \\sum_i x_iP(X=x) = 5\\times \\frac{1}{2} + (-5)\\times \\frac{1}{2} = \\mathbf{0}$\n",
    "On average, we gain nothing.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0801057d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4>Definition: Markov's Inequality</h4>\n",
    "\n",
    "Let $X$ be a real r.v. Then:\n",
    "$\\forall a> 0, a\\in \\mathbb{R} :  \\ \\  \\mathbb{P}(|X|\\geq a) \\leq \\frac{\\mathbb{E}[|X|]}{a} $\n",
    "\n",
    "**Remark:** it's a worst-case bound, real probability is usually much smaller.\n",
    "\n",
    "</div>\n",
    "\n",
    "This inequality can be illustrated with the following *budget constraint* analogy: \n",
    "\n",
    "You know the average wealth in a country is $50,000 per person. \n",
    "\n",
    "> What's the maximum fraction of people who could be millionaires?\n",
    "\n",
    "**Answer**: at most 5%.\n",
    "\n",
    "If more than 5% were millionaires, the average would have to exceed \\$50,000: \n",
    "- If 5% have \\$1,000,000 and 95\\% have $0: $Average = 0.05 \\times 1,000,000 + 0.95 \\times 0 = 50,000\\ \\checkmark$\n",
    "- If 6% have \\$1,000,000 and 94\\% have $0: $Average = 0.06 \\times 1,000,000 + 0.95 \\times 0 = 60,000\\ X$ (contradicts our known average)\n",
    "\n",
    "This problem can be formulated as Markov's inequality as follows:\n",
    "\n",
    "$$\\mathbb{P}(wealth\\geq 1,000,000) \\leq \\frac{50,000}{1,000,000} = 0.05$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4644d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo\n",
    "demo_markov_ineq_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91abe20a",
   "metadata": {},
   "source": [
    "<div class=\"alert .alert-exercise\">\n",
    "<h4>Calculated Example</h4>\n",
    "\n",
    "Average training time per epoch is 10 minutes. What's the probability an epoch takes ≥ 50 minutes?\n",
    "\n",
    "</div>\n",
    "\n",
    "<details>\n",
    "<summary>Reveal Solution</summary>\n",
    "\n",
    "Let $X = \\text{time per epoch}$, $\\mathbb{E}[X] = 10$, $\\alpha = 50$.\n",
    "\n",
    "Using Markov's inequality:\n",
    "\n",
    "$$P(X \\geq alpha) = P(X \\geq 50) \\leq \\frac{10}{50} = 0.2$$\n",
    "\n",
    "**Answer:** at most 20%. If more than 20% of epochs took ≥50 min, the average would exceed 10 min.\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e57808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation \n",
    "# usually training time is modelled as exponential distributions\n",
    "demo_markov_ineq()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5a53c3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4>Definition: Variance</h4>\n",
    "\n",
    "**The variance** of the real r.v. $X$, denoted $Var(X)$ or $\\sigma^2$, is a measure of the dispersion of data around its expectation $\\mathbb{E}X$.\n",
    "\n",
    "Its calculation (when this quantity exists) depends on the nature of $X$:\n",
    "\n",
    "* discrete real r.v.:\n",
    "$Var(X) = \\mathbb{E}[(X-\\mathbb{E}X)^2] = \\mathbb{E}[X^2]-(\\mathbb{E}X)^2=\\sum_i (x_i-\\mathbb{E}X)^2 p_i$\n",
    "\n",
    "* continuous real r.v.:\n",
    "$Var(X) = \\mathbb{E}[(X-\\mathbb{E}X)^2] = \\mathbb{E}[X^2]-(\\mathbb{E}X)^2=\\int_{a}^{b}(x-\\mathbb{E}X)^2f(x)dx$\n",
    "\n",
    "<h5>Properties:</h5>\n",
    "\n",
    "* $Var(X) \\geq 0$\n",
    "* $Var(X + Y) = Var[X] + Var[Y]\\text{, (if } X\\text{ and } Y\\text{ indep.)}$\n",
    "* $Var(aX + b) = a^2Var(X)$\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<h4>Definition: Standard Deviation</h4>\n",
    "\n",
    "**The standard deviation** (or **std**) of the real r.v. $X$, denoted $\\sqrt{Var(X)}$ or $\\sigma$, is a measure of the deviation between the values taken by $X$ and its expectation $\\mathbb{E}X$\n",
    "\n",
    "$\\sigma(X)=\\sigma_X = \\sqrt{Var(X)}$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fff890b",
   "metadata": {},
   "source": [
    "Let's calculate the variance and standard deviation for our example:\n",
    "\n",
    "|$x$| $1$ | $2$ | $3$ | $4$ | $5$ |\n",
    "|--:|:--:|:--:|:--:|:--:|:--:|\n",
    "|$P(X=x)$| $0.4$ | $0.25$ | $0.2$ | $0.1$| $0.05$|\n",
    "|$P(X \\leq x)$ | $0.4$ | $0.4 + 0.25 = 0.65$ | $0.4 + 0.25 + 0.2 = 0.85$ | $0.4 + 0.25 + 0.2 + 0.1 = 0.95$ | $0.4 + 0.25 + 0.2 + 0.1 + 0.05 = 1$|\n",
    "|$xP(X=x)$|$1\\times 0.4 = 0.4$| $2\\times 0.25 = 0.5$ | $3\\times 0.2 = 0.6$ | $4\\times 0.1 = 0.4$ | $5\\times 0.05 = 0.25$|\n",
    "|$x - \\mathbb{E}[X]$ | $1 - 2.15 = -1.15$ | $2 - 2.15 = -0.15$ | $3 - 2.15 = 0.85$ | $4 - 2.15 = 1.85$ | $5 - 2.15 = 2.85$|\n",
    "|$(x - \\mathbb{E}[X])^2$| $(-1.15)^2 \\approx 1.3225$ | $(-0.15)^2 = 0.0225$ | $0.85^2 \\approx 0.7225$ | $1.85^2 \\approx 3.4225$ | $2.85^2 = 8.1225$ |\n",
    "|$(x - \\mathbb{E}[X])^2P(X=x)$| $1.3225 \\times 0.4 = 0.529$ | $0.0225 \\times 0.25 = 0.005625$ | $0.7225 \\times 0.2 = 0.1445$ | $3.4225 \\times 0.1 = 0.34225$ | $8.1225\\times 0.05 = 0.406125$ |\n",
    "\n",
    "Hence:\n",
    "\n",
    "$$Var(X) = \\mathbb{E}[(X-\\mathbb{E}X)^2] = \\mathbb{E}[X^2]-(\\mathbb{E}X)^2=\\sum_i (x_i-\\mathbb{E}X)^2 p_i = 0.529 + 0.005625 + 0.1445 + 0.34225 + 0.406125 = 1.4275$$\n",
    "\n",
    "Now:\n",
    "\n",
    "$$\\sigma(X) = \\sqrt{Var(X)} = \\sqrt{1.4275} \\approx 1.1948$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f597fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variance of our toy example\n",
    "var = sum((coffees - expected_val)**2 * probs)\n",
    "print(f\"Variance Var(X) = {var:.4f}\")\n",
    "# standard deviation \n",
    "std = np.sqrt(var)\n",
    "print(f\"Standard deviation std(X) = {std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a115dbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation\n",
    "coffee_example_mean_var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d8a65b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4>Definition: Chebyshev's Inequality</h4>\n",
    "\n",
    "Let $X$ be a real r.v. Then:\n",
    "$$\\forall \\alpha > 0, \\alpha\\in \\mathbb{R} : \\ \\ \\mathbb{P}(|X - \\mathbb{E}X|\\geq \\alpha) \\leq \\frac{Var(X)}{\\alpha^2}$$\n",
    "\n",
    "Or equivalently (using $k$ standard deviations, i.e. $k = \\alpha\\sigma$):\n",
    "\n",
    "$$\\mathbb{P}(|X - \\mathbb{E}X|\\geq k\\sigma) \\leq \\frac{1}{k^2}$$\n",
    "\n",
    "</div>\n",
    "\n",
    "Chebyshev's inequality is a powerful refinement of Markov's inequality that uses information about variance to make much tighter statements about how data clusters around the mean.\n",
    "\n",
    "It can be illustrated with the *\"spread cannot lie\" principle*: \n",
    "If variance is small, the data MUST be concentrated near the mean. Low variance means values can't stray far from the mean without violating the variance constraint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ffc945",
   "metadata": {},
   "source": [
    "<div class=\"alert .alert-exercise\">\n",
    "<h4>Calculated Example</h4>\n",
    "\n",
    "Class average is 75, standard deviation is 5 points. What fraction of students could have scored ≥ 95 (20 points above mean)?\n",
    "\n",
    "</div>\n",
    "\n",
    "<details>\n",
    "<summary>Reveal Solution</summary>\n",
    "\n",
    "Let $X = \\text{student's grade}$, $\\mathbb{E}[X] = 75$, $\\sigma(X) = 5$, $\\alpha = 95 - 75 = 20$ (distance from the mean).\n",
    "\n",
    "Using Chebychev's inequality:\n",
    "\n",
    "$$P(|X - 75| \\geq 20) \\leq \\frac{5^2}{20^2} = \\frac{25}{400} = 0.0625$$\n",
    "\n",
    "**Answer:** at most 6.25% of students scored ≥95 or ≤55 (combined). If more students were at extremes, the variance would have to be larger than 25.\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f3ee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation\n",
    "demo_schebyshev_ineq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd52300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo Chebyshev's inequality\n",
    "demo_chebyshev_ineq_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999eebc2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4>Definition: Moment of order p</h4>\n",
    "\n",
    "**A moment of order $p\\ (p\\in \\mathbb{N})$** of the real r.v. $X$ is a real number $\\mathbb{E}(|X|^p)$, when it exists.\n",
    "\n",
    "**A centered moment of order $p\\ (p\\in \\mathbb{N})$** of the real r.v. $X$ is a real number $\\mathbb{E}(|X - \\mathbb{E}X|^p)$, when it exists.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897e70cb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<h4>💡 Key Insight: Expected Value and Variance</h4>\n",
    "\n",
    "$E[X]$ tells you *'typical value'*, $Var(X)$ tells you *'how much variation to expect'*.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b8c420",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-primary\">\n",
    "<h4>🤖 ML Applications</h4>\n",
    "\n",
    "<ul>\n",
    "<li>Expected loss: E[Loss] guides optimization</li>\n",
    "<li>Variance of gradients: affects training stability (high var → noisy updates)</li>\n",
    "<li>Weight initialization: control E[W]=0, Var(W)=σ² for stable forward pass</li>\n",
    "</ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ef2d57",
   "metadata": {},
   "source": [
    "## Common Discrete Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559f9a05",
   "metadata": {},
   "source": [
    "### Bernoulli Distribution, $Bernoulli(p)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d2446a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-example\">\n",
    "<h4>Bernoulli Distribution</h4>\n",
    "\n",
    "$X \\sim Bernoulli(p)$ or $X \\sim Bern(p)$\n",
    "\n",
    "**When to use:**\n",
    "\n",
    "Models a single binary trial with two outcomes: success (1) or failure (0). Use when you have exactly one experiment with two possible outcomes, where the probability of success is $p$.\n",
    "\n",
    "**Parameters & Domain:**\n",
    "- Parameter: $p \\in [0, 1]$ (probability of success)\n",
    "- Domain (what values $X$ can take): $X \\in \\{0, 1\\}$\n",
    "\n",
    "| PMF | CDF | $E(X)$ | $Var(X)$|\n",
    "|:---:|:---:|:----:|:---:|\n",
    "|$$P(X = k) = \\begin{cases} 1-p & \\text{if } k=0 \\\\ p & \\text{if } k=1 \\\\ 0 & \\text{otherwise} \\end{cases}$$</br>or $P(X=k) = p^k(1−p)^{1−k}$ for $k \\in \\{0,1\\}$| $$F(x) = P(X \\leq x) = \\begin{cases} 0 & \\text{if } x < 0 \\\\ 1-p & \\text{if } 0 \\leq x < 1 \\\\ 1 & \\text{if } x \\geq 1 \\end{cases}$$| $$p$$ | $$p(1-p)$$ </br> Variance is maximized when $p = 0.5$ |\n",
    "\n",
    "**Key Properties:**\n",
    "- Mode: $\\begin{cases} 1 & \\text{if } p > 0.5 \\\\ 0 & \\text{if } p < 0.5 \\\\ \\text{both } 0 \\text{ and } 1  & \\text{if } p = 0.5 \\end{cases}$\n",
    "- Symmetry: Symmetric only when $p = 0.5$\n",
    "- Special case: $Bernoulli(0.5)$ is a fair coin flip\n",
    "\n",
    "**Real-world examples:**\n",
    "- Coin flip (fair: $p = 0.5$, biased: $p \\neq 0.5$)\n",
    "- Single customer makes purchase (yes/no)\n",
    "- Single patient recovers (yes/no)\n",
    "- Quality control: single item is defective or not\n",
    "\n",
    "**Typical Events This Describes**\n",
    "\n",
    "- Single classification prediction (correct/incorrect)\n",
    "- Single packet transmitted successfully/failed\n",
    "- Single user clicks ad (yes/no)\n",
    "- Single neuron fires (active/inactive)\n",
    "- Single A/B test participant converts (yes/no)\n",
    "\n",
    "**Relationships to Other Distributions:**\n",
    "- Binomial: Bernoulli is Binomial(n=1, p)\n",
    "- Sum: Sum of n independent Bernoulli(p) trials = Binomial(n, p)\n",
    "- Categorical: Bernoulli is Categorical distribution with 2 categories\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-primary\">\n",
    "<h4>🤖 ML Applications</h4>\n",
    "\n",
    "Training:\n",
    "- Dropout mask for a single neuron: keep with probability p\n",
    "- Data augmentation decision: apply transform with probability p\n",
    "- Stochastic decision gates in neural architectures\n",
    "\n",
    "Modeling:\n",
    "- Binary classification output (after sigmoid/threshold)\n",
    "- Bernoulli likelihood in generative models\n",
    "- Binary labels in supervised learning\n",
    "\n",
    "Evaluation:\n",
    "- Single prediction correctness\n",
    "- Binary event detection (anomaly present: yes/no)\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "<h4>⚠️ Common Pitfalls:</h4>\n",
    "\n",
    "- Don't use for multiple trials (use Binomial instead)\n",
    "- Don't confuse $p$ (parameter) with $P(X=k)$ (probability at $k$)\n",
    "- Remember: $Var(X) \\neq p$ (it's $p(1-p)$)\n",
    "- Maximum variance is 0.25, not 1\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bea185",
   "metadata": {},
   "source": [
    "We can use SciPy implementation of this distribution, [`scipy.stats.bernoulli`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bernoulli.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf90f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create distribution\n",
    "X = stats.bernoulli(p=0.7)\n",
    "\n",
    "# Calculate probabilities\n",
    "print(f\"P(X = 1) = {X.pmf(1)}\")        # P(X=1) = 0.7\n",
    "print(f\"P(X≤0) = {X.cdf(0)}\")        # P(X≤0) = 0.3\n",
    "print(f\"Generated 10 samples: {X.rvs(size=10)}\")  # Generate 10 samples\n",
    "\n",
    "# Moments\n",
    "print(f\"E(X) = {X.mean()}\")        # E[X] = 0.7\n",
    "print(f\"Var(X) = {X.var()}\")         # Var(X) = 0.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc248f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bernoulli(p=0.7):\n",
    "    print(\"Visual Characteristics\")\n",
    "    print(\"Two bars at x=0 and x=1\")\n",
    "    print(\"Height at x=1 is p, height at x=0 is 1-p\")\n",
    "    print(\"Symmetric when p=0.5, skewed otherwise\\n\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    x = [0, 1]\n",
    "    pmf = [1-p, p]\n",
    "    ax.bar(x, pmf, color=['salmon', 'lightgreen'], edgecolor='black', alpha=0.7)\n",
    "    ax.set_xlabel('Outcome')\n",
    "    ax.set_ylabel('Probability')\n",
    "    ax.set_title(f'Bernoulli({p}): E[X]={p:.2f}, Var(X)={p*(1-p):.4f}')\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels(['Failure (0)', 'Success (1)'])\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.close()\n",
    "    return fig\n",
    "\n",
    "interact(plot_bernoulli, p=FloatSlider(min=0.1, max=0.9, step=0.1, value=0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87a34b0",
   "metadata": {},
   "source": [
    "### Binomial Distribution, $\\mathcal{B}(n, p)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dced78a0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-example\">\n",
    "<h4>Binomial Distribution</h4>\n",
    "\n",
    "$X \\sim Bin(n, p)$ or $X \\sim \\mathcal{B}(n, p)$\n",
    "\n",
    "**When to use:**\n",
    "\n",
    "Models the number of successes in $n$ independent identical trials, where each trial has probability $p$ of success. Use when you have:\n",
    "\n",
    "- Fixed number of trials ($n$)\n",
    "- Each trial is independent\n",
    "- Each trial has only two outcomes (success/failure)\n",
    "- Probability of success ($p$) is constant across trials\n",
    "\n",
    "**Parameters & Domain:**\n",
    "- Parameters: \n",
    "\n",
    "$n \\in \\mathbb{N}$ (number of trials, $n\\geq 1$)\n",
    "\n",
    "$p \\in [0, 1]$ (probability of success per trial)\n",
    "- Support (what values $X$ can take): $X \\in \\{0, 1, 2, ..., n\\}$\n",
    "\n",
    "| PMF | CDF | $E(X)$ | $Var(X)$|\n",
    "|:---:|:---:|:----:|:---:|\n",
    "|$$P(X = k) = \\left(\\begin{matrix}n\\\\k\\end{matrix}\\right)p^k(1-p)^{n-k} = \\frac{n!}{k!(n-k)!}p^k(1-p)^{n-k}$$ for $k\\in \\{0, 1, 2, ..., n\\}$</br> *Interpretation:*</br>$\\binom{n}{k}$ = number of ways to choose $k$ successes from $n$ trials</br>$p^k$ = probability of $k$ successes </br> $(1-p)^{n-k}$ = probability of $(n-k)$ failures| $$F(x) = P(X \\leq x) = \\sum_{k=0}^{⌊x⌋}\\left(\\begin{matrix}n\\\\k\\end{matrix}\\right)p^k(1-p)^{n-k}$$ for $x\\geq 0$ ($F(x) = 0$ for $x < 0$, $F(x) = 1$ for $x\\geq n$) </br> *Note*: No closed-form expression; typically computed numerically or via tables| $$np$$ | $$np(1-p)$$ </br>Variance decreases as p → 0 or p → 1 (less uncertainty)</br>Variance is maximized when $p = 0.5$ |\n",
    "\n",
    "**Key Properties:**\n",
    "- Mode: $⌊(n + 1)p⌋$ (floor of $(n+1)p$)\n",
    "\n",
    "Can have two modes if $(n+1)p$ is an integer\n",
    "\n",
    "- Symmetry: Symmetric when $p = 0.5$, otherwise skewed\n",
    "    * Right-skewed if p < 0.5\n",
    "    * Left-skewed if p > 0.5\n",
    "\n",
    "- Sum property: If $X_1 \\sim Bin(n_1, p)$ and $X_2 \\sim Bin(n_2, p)$ are independent, then $X_1 + X+2 \\sim Bin(n_1 + n_2, p)$\n",
    "\n",
    "**Real-world examples:**\n",
    "- Number of heads in 10 coin flips\n",
    "- Number of defective items in a batch of 100\n",
    "- Number of patients who recover out of 50 treated\n",
    "- Number of emails marked as spam out of 200\n",
    "\n",
    "**Typical Events This Describes**\n",
    "\n",
    "Counting successes in repeated trials:\n",
    "\n",
    "- Number of website visitors who make a purchase (out of n visitors)\n",
    "- Number of correctly classified samples (out of n test samples)\n",
    "- Number of successful HTTP requests (out of n total requests)\n",
    "- Number of spam emails (out of n total emails)\n",
    "- Number of defective products in quality control\n",
    "- Number of students passing an exam (out of n students)\n",
    "- Number of \"heads\" in n coin flips\n",
    "- Number of winning lottery tickets purchased\n",
    "\n",
    "**Relationships to Other Distributions:**\n",
    "1. Special cases:\n",
    "\n",
    "- Bernoulli: $Binomial(n=1, p) = Bernoulli(p)$\n",
    "- Certain event: $Binomial(n, p=1)$ gives $X = n$ always\n",
    "- Impossible event: $Binomial(n, p=0)$ gives $X = 0$ always\n",
    "\n",
    "2. Limiting cases:\n",
    "\n",
    "- Normal approximation: As $n \\rightarrow \\infty$ with $np$ and $n(1-p)$ both large (typically ≥ 5):\n",
    "\n",
    "$$\\text{Binomial}(n,p) \\approx \\mathcal{N}(np, np(1-p))$$\n",
    "\n",
    "- Poisson approximation: When $n$ is large, $p$ is small, and $np = \\lambda$ remains moderate:\n",
    "\n",
    "$$\\text{Binomial}(n,p) \\approx \\text{Poisson}(\\lambda = np)$$\n",
    "  (Rule of thumb: $n \\geq 20, p \\leq 0.05$)\n",
    "\n",
    "\n",
    "3. Composition:\n",
    "\n",
    "Binomial is the sum of $n$ independent $Bernoulli(p)$ trials\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eff92ee",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-primary\">\n",
    "<h4>🤖 ML Applications</h4>\n",
    "\n",
    "Model Training:\n",
    "\n",
    "- Batch accuracy: Number of correct predictions in a mini-batch of size $n$\n",
    "\n",
    "If model has accuracy $p$, correct predictions $\\sim Bin(n, p)$\n",
    "\n",
    "- Ensemble methods: Number of models (out of $n$) that agree on a prediction\n",
    "- Dropout: Total number of neurons kept in a layer with $n$ neurons and keep probability $p$\n",
    "- Bootstrap sampling: Number of unique samples in bootstrap (related)\n",
    "\n",
    "Model Evaluation:\n",
    "\n",
    "- Cross-validation: Number of folds where model performs above threshold\n",
    "- Statistical testing: Count successes in repeated experiments\n",
    "- A/B testing: Number of conversions in treatment group of size n\n",
    "\n",
    "Data Analysis:\n",
    "\n",
    "- Binary classification metrics: At threshold, count of true positives\n",
    "- Sample statistics: Modeling counts in repeated binary outcomes\n",
    "- Confidence intervals: For proportions and success rates\n",
    "\n",
    "Generative Models:\n",
    "\n",
    "- Likelihood: Binomial likelihood for count data\n",
    "- Bayesian inference: Conjugate with Beta prior for Bayesian updating\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e491c4af",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<h4>⚠️ Common Pitfalls:</h4>\n",
    "\n",
    "❌ Don't use when:\n",
    "\n",
    "- Trials are not independent (use Hypergeometric instead)\n",
    "- Probability changes between trials (use Beta-Binomial)\n",
    "- Number of trials is not fixed in advance (use Negative Binomial or Poisson)\n",
    "\n",
    "⚠️ Common mistakes:\n",
    "\n",
    "- Confusing $n$ (number of trials) with $k$ (number of successes)\n",
    "- Using when trials have different success probabilities\n",
    "- Forgetting that $P(X = k)$ requires the binomial coefficient\n",
    "- Assuming Normal approximation works for small $n$\n",
    "\n",
    "⚠️ Computational issues:\n",
    "\n",
    "- Binomial coefficients can overflow for large $n$\n",
    "- Use log probabilities for numerical stability\n",
    "- `scipy.stats` handles this automatically\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562c9a78",
   "metadata": {},
   "source": [
    "We can use SciPy implementation of this distribution, [`scipy.stats.binom`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694f285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create distribution: 10 trials, p=0.3\n",
    "X = stats.binom(n=10, p=0.3)\n",
    "\n",
    "# Probabilities\n",
    "print(f\"PMF: P(X=5) = {X.pmf(5)}\")           # P(X=5) = probability of exactly 5 successes\n",
    "print(f\"CDF: P(X≤5) = {X.cdf(5)}\")           # P(X≤5) = cumulative probability\n",
    "print(f\"P(X>4) = {1 - X.cdf(4)}\")       # P(X>4) = P(X≥5) for discrete\n",
    "\n",
    "# Interval probability\n",
    "print(f\"P(3 < X ≤ 7) = {X.cdf(7) - X.cdf(3)}\")  # P(3 < X ≤ 7) = P(X ∈ {4,5,6,7})\n",
    "\n",
    "# Moments\n",
    "print(f\"E[X] = {X.mean()}\")           # E[X] = np = 3.0\n",
    "print(f\"Var(X) = {X.var()}\")            # Var(X) = np(1-p) = 2.1\n",
    "print(f\"σ = {X.std()}\")            # σ = √2.1 ≈ 1.45\n",
    "\n",
    "# Random sampling\n",
    "samples = X.rvs(size=10, random_state=42)\n",
    "print(f\"Generated 10 samples: {samples}\")\n",
    "\n",
    "# Survival function\n",
    "print(f\"Survival function, P(X > 5) = {X.sf(5)}\")            # P(X > 5) = 1 - F(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a92bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_binomial(n=10, p=0.7):\n",
    "    print(\"Visual Characteristics\")\n",
    "    print(\"     p = 0.5: Symmetric, bell-shaped (approaches Normal as n increases)\")\n",
    "    print(\"     p < 0.5: Right-skewed (tail extends right)\")\n",
    "    print(\"     p > 0.5: Left-skewed (tail extends left)\")\n",
    "    print(\"Width: Spread increases with n\")\n",
    "    print(\"Peak: Centered around np\")\n",
    "    print(\"As n increases:\")\n",
    "    print(\"     Distribution becomes smoother\")\n",
    "    print(\"     Approaches Normal distribution (Central Limit Theorem preview)\")\n",
    "    print(\"     More concentrated around the mean (by Law of Large Numbers)\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    x = np.arange(0, n + 1)\n",
    "    pmf = []\n",
    "    for xx in x:\n",
    "        pmf.append(stats.binom.pmf(xx, n, p))\n",
    "    ax.stem(x, pmf, basefmt=' ', linefmt='salmon', markerfmt='mo')\n",
    "    ax.set_xlabel('x (number of successes)')\n",
    "    ax.set_ylabel('Probability')\n",
    "    ax.set_title(f'Binomial({n}, {p}): E[X]={p:.2f}, Var(X)={p*(1-p):.4f}')\n",
    "    #ax.set_ylim(0, 1)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.close()\n",
    "    return fig\n",
    "\n",
    "interact(plot_binomial, p=FloatSlider(min=0.1, max=0.9, step=0.1, value=0.7), n=IntSlider(min=1, max=100, step=1, value=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d28fe1",
   "metadata": {},
   "source": [
    "Let's consider the following example:\n",
    "\n",
    "We are interested in the number of successful API calls out of 5 attempts. Each attempt can have a binary outcome: success or failure. The probability of success is 0.6. \n",
    "Define PMF, CDF.\n",
    "\n",
    "As each API call has a binary outcome, the outcomes are independent, and the total number of trials is $n = 5$, then $X = \\text{number of successful API calls}$ follows Binomial distribution with $p=0.6$ and $n=5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fb6916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Number of successful API calls out of 5 attempts\n",
    "f1, f2 = demo_pdf_cdf_discrete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9653ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PMF and CDF of Binomial Distribution\n",
    "f2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3d0f6a",
   "metadata": {},
   "source": [
    "### Geometric Distribution, $\\mathcal{G}(p)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe5064b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-example\">\n",
    "<h4>Geometric Distribution</h4>\n",
    "\n",
    "$X \\sim \\mathcal{G}(p)$ or $X \\sim Geometric(p)$ or $X \\sim Geo(p)$\n",
    "\n",
    "**When to use:**\n",
    "\n",
    "Models the **number of trials needed to get the first success** in a sequence of independent Bernoulli trials. Use when you're waiting for the first occurrence of an event with:\n",
    "\n",
    "- Independent trials\n",
    "- Constant probability $p$ of success per trial\n",
    "- No memory of previous failures (memoryless property)\n",
    "- Counting trials until first success\n",
    "\n",
    "**Parameters & Domain:**\n",
    "- Parameter: $p \\in (0, 1]$ (probability of success per trial)\n",
    "\n",
    "There are two common definitions:\n",
    "\n",
    "- Number of trials until first success (includes the success) - support: {1, 2, 3, ...}\n",
    "- Number of failures before first success - support: {0, 1, 2, ...}\n",
    "\n",
    "We use convention 1, which is `scipy`'s default.\n",
    "\n",
    "*Note*: $X = 1$ means success on first trial.\n",
    "\n",
    "| PMF | CDF | $E(X)$ | $Var(X)$|\n",
    "|:---:|:---:|:----:|:---:|\n",
    "|$$P(X = k) = (1 - p)^{k-1}\\cdot p$$ for $k \\in \\{1, 2, 3, ...\\}$</br>- $(1 - p)^{k-1}$ is the probability of $(k-1)$ failures</br>- $p$ is the probability of success on the $k$-th trial</br>No binomial coefficient needed (order is fixed: failures then success)<br>*Alternative form (failures before success)*$$P(Y=k) = (1 - p)^k\\cdot p$$ for $k\\in \\{0,1,2,...\\}$| $$F(x) = P(X \\leq x) = 1 - (1 - p)^{⌊x⌋}$$ for $x\\geq 1$ </br>*Intuition*: P(success within k trials) = 1 - P(all k trials fail)</br>**Survival function** (often more useful): $$P(X > k) = (1 - p)^k$$ This is the probability of needing more than k trials (all k trials fail)| $$1/p$$ - If $p = 0.5$ (coin flip): expect 2 trials for first heads </br> - If $p = 0.1$ (rare event): expect 10 trials for first success </br> - If $p = 0.01$: expect 100 trials for first success| $$(1-p)/p^2$$ </br> Variance increases (more uncertainty) as $p$ decreases |\n",
    "\n",
    "**Key Properties:**\n",
    "\n",
    "1. **Memoryless Property** (UNIQUE to Geometric and Exponential):\n",
    "$$P(X > s + t ∣ X > s) = P(X > t)$$\n",
    "\n",
    "*Interpretation*: If you've already had $s$ failures, the probability of needing $t$ more trials is the same as if you were starting fresh. Past failures don't affect future probabilities.\n",
    "\n",
    "*Example*: If you flip 10 tails, the probability of needing 5 more flips for heads is still the same as needing 5 flips from the start.\n",
    "2. **Minimum Property**: If $X_1, X_2, ..., X_n$ are independent $Geometric(p)$ random variables, then:\n",
    "\n",
    "$$\\min⁡(X_1, X_2, ..., X_n) \\sim Geometric(1−(1−p)^n)$$\n",
    "\n",
    "3. Lack of Memory in Practical Terms:\n",
    "\n",
    "The distribution \"resets\" after each failure. This makes it suitable for modeling processes where each trial is truly independent.\n",
    "\n",
    "4. Mode:\n",
    "\n",
    "- $Mode = 1$ (first trial is most likely to be the success)\n",
    "- Distribution is always right-skewed (long tail)\n",
    "\n",
    "**Real-world examples:**\n",
    "- Number of coin flips until first heads\n",
    "- Number of job applications until first interview\n",
    "- Number of attempts until passing a test\n",
    "- Number of products inspected until finding first defect\n",
    "- Number of customers until first sale\n",
    "- Number of days until first rain\n",
    "\n",
    "**Typical Events This Describes**\n",
    "\n",
    "\"How many trials until first success?\"\n",
    "\n",
    "- Number of coin flips until first heads\n",
    "- Number of dice rolls until first six\n",
    "- Number of packets sent until first successful transmission\n",
    "- Number of job interviews until first offer\n",
    "- Number of sales calls until first conversion\n",
    "- Number of attempts until first bug is found\n",
    "- Number of generations until mutation occurs\n",
    "- Number of iterations until convergence criterion met\n",
    "- Number of samples until finding a rare class\n",
    "- Number of epochs until model improvement\n",
    "\n",
    "*Key characteristic*: Counting discrete waiting time in a memoryless process.\n",
    "\n",
    "**Relationships to Other Distributions:**\n",
    "1. Special cases:\n",
    "\n",
    "- Certain success: $Geometric(p=1)$ gives $X = 1$ always (success on first trial)\n",
    "- Impossible success: $Geometric(p\\rightarrow 0)$ gives $X \\infty ∞$ (never succeed)\n",
    "\n",
    "2. Related distributions:\n",
    "\n",
    "- Negative Binomial: Geometric is Negative Binomial with $r = 1$ (waiting for first success vs. $r$-th success)\n",
    "- Exponential: Continuous analog of Geometric (memoryless property shared)\n",
    "\n",
    "If trials happen continuously at rate $\\lambda$, $Geometric \\rightarrow Exponential(\\lambda)$\n",
    "\n",
    "3. Sum property: If $X_1, X_2, ..., X_r$ are independent $Geometric(p)$, then:\n",
    "\n",
    "$X_1 + X_2 + ... + X_ r \\sim NegativeBinomial(r,p)$\n",
    "\n",
    "This counts trials needed for r successes.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0db39f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-primary\">\n",
    "<h4>🤖 ML Applications</h4>\n",
    "\n",
    "Training & Optimization:\n",
    "\n",
    "- Convergence analysis: Number of epochs until loss < threshold\n",
    "- Early stopping: Iterations until validation improvement\n",
    "- Hyperparameter search: Number of configurations tested until finding good one\n",
    "- Gradient descent: Steps until reaching local minimum\n",
    "- Stochastic processes: Modeling random exploration until success\n",
    "\n",
    "Sampling & Data:\n",
    "\n",
    "- Rare class sampling: Samples needed until finding minority class example\n",
    "- Rejection sampling: Proposals needed until acceptance\n",
    "- Active learning: Queries needed until finding informative sample\n",
    "- Data augmentation: Attempts until generating valid augmented sample\n",
    "\n",
    "Reinforcement Learning:\n",
    "\n",
    "- Episode length: Steps until reaching terminal state\n",
    "- Exploration: Actions until discovering reward\n",
    "- Success probability: Trials until agent succeeds at task\n",
    "\n",
    "System Monitoring:\n",
    "\n",
    "- Failure detection: Requests until first failure\n",
    "- Anomaly detection: Events until first anomaly\n",
    "- Testing: Test cases until first bug found\n",
    "\n",
    "Networking & Distributed Systems:\n",
    "\n",
    "- Retry mechanisms: Attempts until successful connection\n",
    "- Leader election: Rounds until consensus\n",
    "- Packet transmission: Retransmissions until ACK received\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6eee7b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<h4>⚠️ Common Pitfalls:</h4>\n",
    "\n",
    "❌ Don't use when:\n",
    "\n",
    "- Trials are not independent (use Markov chains)\n",
    "- Success probability changes over time (use non-stationary models)\n",
    "- You're waiting for multiple successes (use Negative Binomial)\n",
    "- Dealing with continuous time (use Exponential instead)\n",
    "- There's a maximum number of trials (use truncated Geometric)\n",
    "\n",
    "⚠️ Common mistakes:\n",
    "\n",
    "- Confusing \"trials until success\" vs \"failures before success\" conventions\n",
    "- Forgetting the memoryless property doesn't apply to real-world \"learning\" situations\n",
    "- Using when success probability improves with practice (violates constant p)\n",
    "- Misapplying to situations with \"hot streaks\" or \"cold streaks\"\n",
    "\n",
    "⚠️ Memoryless property misuse:\n",
    "\n",
    "- Valid: Independent coin flips, random sampling with replacement\n",
    "- Invalid: \"*I've failed 10 job interviews, so I'm due for success*\" (human learning violates independence)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3b5835",
   "metadata": {},
   "source": [
    "We can use SciPy implementation of this distribution, [`scipy.stats.geom`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.geom.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34688d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.3\n",
    "\n",
    "# Create distribution\n",
    "X = stats.geom(p)\n",
    "\n",
    "# PMF: P(k trials until success)\n",
    "print(f\"P(X = 0) = {X.pmf(0)}\")           # X = 0 (not in support)\n",
    "print(f\"P(X = 1) = {X.pmf(1)}\")           # P(success on 1st trial) = (1-p)p\n",
    "k = 5\n",
    "print(f\"P(X = k) = {X.pmf(k)}\")           # P(success on (k)-th trial)\n",
    "\n",
    "# CDF\n",
    "print(f\"P(X≤5) = {X.cdf(5)}\")           # P(success within 5 trials)\n",
    "print(f\"P(need more than 5 trials) = {1 - X.cdf(5)}\")       # P(need more than 5 trials) = (1-p)^5\n",
    "\n",
    "# Survival function (often more useful)\n",
    "print(f\"Survival function P(X > k) = {X.sf(k)}\")            # P(X > k) = (1-p)^k\n",
    "\n",
    "# Moments\n",
    "print(f\"E[X] = {X.mean()}\")           # E[X] = (1-p)/p (failures), or 1/p (trials)\n",
    "print(f\"Var(X) = {X.var()}\")            # Var(X) = (1-p)/p²\n",
    "print(f\"σ = {X.std()}\")            # σ\n",
    "\n",
    "# Random sampling\n",
    "samples = X.rvs(size=10, random_state=42)\n",
    "# These are number of failures; add 1 for number of trials\n",
    "print(f\"Generated 10 samples: {samples}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d24eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memoryless property demonstration:\n",
    "p = 0.3\n",
    "\n",
    "# P(X > 10) - probability of more than 10 failures\n",
    "prob_more_than_10 = (1-p)**10\n",
    "print(f\"P(X > 10) = {prob_more_than_10:.4f}\")\n",
    "\n",
    "# P(X > 15 | X > 5) should equal P(X > 10)\n",
    "# (After 5 failures, probability of 10 more failures)\n",
    "prob_conditional = (1-p)**10  # Same!\n",
    "print(f\"P(X > 15 | X > 5) = {prob_conditional:.4f}\")\n",
    "\n",
    "# Memoryless: past doesn't affect future!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc72294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_geom(p=0.7):\n",
    "    print(\"Visual Characteristics\")\n",
    "    print(\"Always right-skewed (long tail to the right)\")\n",
    "    print(\"Mode at k=1 (most likely to succeed immediately)\")\n",
    "    print(\"Decreasing probabilities: P(X=k) decreases geometrically as k increases\")\n",
    "    print(\"Rate of decrease: Faster decay for larger p (success more likely)\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    x = np.linspace(1, 10, num=10)\n",
    "    X = stats.geom(p)\n",
    "    \n",
    "    pmf = []\n",
    "    for xx in x:\n",
    "        pmf.append(X.pmf(xx))\n",
    "    ax.bar(x, pmf, color=['salmon', 'lightgreen'], edgecolor='black', alpha=0.7)\n",
    "    ax.set_xlabel('x (trials until first success)')\n",
    "    ax.set_ylabel('Probability')\n",
    "    ax.set_title(f'Geometric({p}): E[X]={1/p:.2f}, Var(X)={(1-p)/p**2:.4f}')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.close()\n",
    "    return fig\n",
    "\n",
    "interact(plot_geom, p=FloatSlider(min=0.1, max=0.9, step=0.1, value=0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f24e745",
   "metadata": {},
   "source": [
    "### Poisson Distribution, $\\mathcal{P}(\\lambda)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11a95b2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-example\">\n",
    "<h4>Poisson Distribution</h4>\n",
    "\n",
    "$X \\sim \\mathcal{P}(\\lambda)$ or $X \\sim Pois(\\lambda)$\n",
    "\n",
    "**When to use:**\n",
    "\n",
    "Models the number of events occurring in a fixed interval (time, space, volume, etc.) when events occur:\n",
    "\n",
    "- Independently\n",
    "- At a constant average rate $\\lambda$\n",
    "- One at a time (no simultaneous events)\n",
    "\n",
    "Use for rare events or when counting occurrences with:\n",
    "\n",
    "- No fixed upper limit on counts\n",
    "- Events occur randomly over time/space\n",
    "- Average rate is known\n",
    "\n",
    "**Parameters & Support/Domain:**\n",
    "- Parameter: $\\lambda > 0$ (rate parameter, average number of events per interval)\n",
    "- Support (what values $X$ can take): $X \\in \\{0, 1, 2, ...\\}$ (all non-negative integers)\n",
    "\n",
    "| PMF | CDF | $E(X)$ | $Var(X)$|\n",
    "|:---:|:---:|:----:|:---:|\n",
    "|$$P(X = k) = \\frac{e^{-\\lambda}\\lambda^k}{k!}$$ for $k\\in \\{0,1,2,...\\}$</br>*Interpretation:*</br> $\\lambda^k$ grows with more events</br>$e^{-\\lambda}$ is the normalizing constant</br>$k!$ accounts for the different orderings| $$F(x) = P(X \\leq x) = e^{-\\lambda}\\sum_{k=0}^{⌊x⌋}\\frac{\\lambda^k}{k!}$$| $$\\lambda$$ | $$\\lambda$$ |\n",
    "\n",
    "**Key Properties:**\n",
    "\n",
    "*KEY PROPERTY*: Mean equals variance! This is the signature of the Poisson distribution.\n",
    "\n",
    "- If you observe data where sample mean ≈ sample variance, suspect Poisson\n",
    "- Coefficient of variation: $CV = \\frac{\\sigma}{\\mu} = \\frac{\\sqrt{\\lambda}}{\\lambda} = \\frac{1}{\\sqrt{\\lambda}}$ (decreases as $\\lambda$ increases)\n",
    "\n",
    "1. Mode:\n",
    "- $⌊\\lambda⌋$ (floor of $\\lambda$)\n",
    "- Both $⌊\\lambda⌋$ and $⌊\\lambda⌋+1$ if $\\lambda$ is an integer\n",
    "\n",
    "2. Symmetry:\n",
    "- Right-skewed for small $\\lambda$\n",
    "- Approaches symmetry as $\\lambda$ increases\n",
    "- Nearly symmetric for $\\lambda \\geq 10$\n",
    "\n",
    "3. Sum property: If $X_1 \\sim Pois(\\lambda_1)$ and $X_2 \\sim Pois(\\lambda_2)$ are independent, then $X_1 + X_2 \\sim Pois(\\lambda_1 + \\lambda_2)$\n",
    "4. Divisibility: If $X \\sim Pois(\\lambda)$ over interval $T$, then $X \\sim Pois(\\lambda t)$ over a shorter interval interval $t$ (where $0 < t \\leq T$) (e.g. time or space scaling)\n",
    "5. Memoryless (between events): Related to exponential distribution for waiting times\n",
    "\n",
    "**Real-world examples:**\n",
    "- Number of phone calls received per hour\n",
    "- Number of typos per page in a book\n",
    "- Number of earthquakes per year in a region\n",
    "- Number of customers arriving at a store per day\n",
    "- Number of mutations in a DNA sequence\n",
    "- Number of radioactive decay events per second\n",
    "\n",
    "**Typical Events This Describes**\n",
    "\n",
    "Count data with no fixed upper bound:\n",
    "\n",
    "- Number of server requests per second\n",
    "- Number of errors/bugs per 1000 lines of code\n",
    "- Number of clicks on an ad per day\n",
    "- Number of API calls per minute\n",
    "- Number of network packets dropped per hour\n",
    "- Number of fraud attempts per day\n",
    "- Number of customer support tickets per week\n",
    "- Number of rare disease cases per year\n",
    "- Number of typos/errors in a document\n",
    "- Number of goals scored in a soccer match\n",
    "- Number of accidents at an intersection per month\n",
    "\n",
    "Key characteristic: Events are rare relative to the possible opportunities.\n",
    "\n",
    "**Relationships to Other Distributions:**\n",
    "\n",
    "1. Special cases:\n",
    "\n",
    "- Zero inflation: $Poisson(\\lambda=0)$ gives $P(X=0) = 1$ (no events)\n",
    "- Rare events: Poisson models \"needle in haystack\" scenarios\n",
    "\n",
    "2. Limiting cases:\n",
    "\n",
    "- From Binomial: Poisson is the limit of $Binomial(n, p)$ as $n \\rightarrow \\infty, p \\rightarrow 0$, with $np = \\lambda$ fixed\n",
    "\n",
    "Rule of thumb: $n \\geq 20, p \\leq 0.05$, use $Poisson(\\lambda = np)$\n",
    "\n",
    "\n",
    "- To Normal: As $\\lambda \\rightarrow \\infty$:\n",
    "\n",
    "$$\\text{Poisson}(\\lambda) \\approx \\mathcal{N}(\\lambda, \\lambda)$$\n",
    "\n",
    "Rule of thumb: $\\lambda \\geq 10$ for reasonable approximation, $\\lambda \\geq 30$ for good approximation\n",
    "\n",
    "3. Related distributions:\n",
    "\n",
    "- Exponential: If events follow $Poisson(\\lambda)$ per unit time, waiting time between events $\\sim Exponential(\\lambda)$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabd890e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-primary\">\n",
    "<h4>🤖 ML Applications</h4>\n",
    "\n",
    "Anomaly Detection:\n",
    "\n",
    "- Rare event modeling: Detect anomalies in event counts (fraud, intrusion, failures)\n",
    "- If normal behavior $\\sim Pois(\\lambda)$, unusually high counts indicate anomalies\n",
    "- Network security: Unusual number of failed login attempts\n",
    "- Quality control: Defects per product unit\n",
    "\n",
    "System Monitoring:\n",
    "\n",
    "- Server load: Model request rates, predict capacity needs\n",
    "- Traffic analysis: Number of users per time window\n",
    "- Error rates: Number of exceptions/crashes per deployment\n",
    "- Queue length: Number of pending jobs/requests\n",
    "\n",
    "Natural Language Processing:\n",
    "\n",
    "- Word frequency: Model rare word occurrences in text\n",
    "- Document statistics: Number of mentions of rare entities\n",
    "- Topic modeling: Word counts in topics (though often overdispersed)\n",
    "\n",
    "Computer Vision:\n",
    "\n",
    "- Object counting: Number of objects in an image (when rare)\n",
    "- Event detection: Number of events per frame in video\n",
    "\n",
    "Recommendation Systems:\n",
    "\n",
    "- Impression modeling: Number of times user sees an item\n",
    "- Click modeling: Number of clicks per user (when rare)\n",
    "\n",
    "Generative Models:\n",
    "\n",
    "- Poisson regression: Model count outcomes as function of features\n",
    "- Poisson processes: Model event streams over time\n",
    "- Count-based likelihoods: Bayesian models for count data\n",
    "\n",
    "A/B Testing:\n",
    "\n",
    "- Model conversion counts when rates are low\n",
    "- Test differences in rare event rates\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff77ee7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<h4>⚠️ Common Pitfalls:</h4>\n",
    "\n",
    "❌ Don't use when:\n",
    "- Events are not independent\n",
    "- Rate varies over time (use non-homogeneous Poisson process)\n",
    "- Variance >> Mean (overdispersion → use Negative Binomial)\n",
    "- Variance << Mean (underdispersion → use constrained models)\n",
    "- Number of trials is fixed (use Binomial instead)\n",
    "\n",
    "⚠️ Common mistakes:\n",
    "\n",
    "- Using Poisson when $mean \\neq variance$ (check empirical data!)\n",
    "- Confusing $\\lambda$ (rate) with the actual count $X$\n",
    "- Forgetting that support is infinite (though probability becomes negligible for large $k$)\n",
    "- Using when events are not rare or independent\n",
    "\n",
    "⚠️ When to question Poisson:\n",
    "\n",
    "- If sample variance > 2 × sample mean, consider Negative Binomial\n",
    "- If many zeros beyond what Poisson predicts, consider Zero-Inflated Poisson\n",
    "- If events are clustered in time/space, Poisson assumptions violated\n",
    "\n",
    "⚠️ Computational issues:\n",
    "\n",
    "- For large $\\lambda$ and $k$, factorial $k!$ can overflow\n",
    "- Use log probabilities: $log(P(X=k)) = k·log(\\lambda) - \\lambda - log(k!)$\n",
    "- `scipy.stats` uses numerically stable algorithms\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5f5c1c",
   "metadata": {},
   "source": [
    "We can use SciPy implementation of this distribution, [`scipy.stats.poisson`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.poisson.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d397d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create distribution: average rate λ = 3.5\n",
    "X = stats.poisson(mu=3.5)\n",
    "\n",
    "# Probabilities\n",
    "print(f\"P(X=5) = {X.pmf(5)}\")           # P(X=5) = probability of exactly 5 events\n",
    "print(f\"P(X≤5) = {X.cdf(5)}\")           # P(X≤5) = cumulative probability\n",
    "print(f\"P(X>4) = {1 - X.cdf(4)}\")       # P(X>4) = P(X≥5) for discrete\n",
    "print(f\"Survival function, P(X>4) = {X.sf(4)}\")            # P(X>4) = survival function (same as above)\n",
    "\n",
    "# Interval probability\n",
    "print(f\"P(2 < X ≤ 8) = {X.cdf(8) - X.cdf(2)}\")  # P(2 < X ≤ 8) = P(X ∈ {3,4,5,6,7,8})\n",
    "\n",
    "# Moments\n",
    "print(f\"E[X]: {X.mean()}\")           # E[X] = λ = 3.5\n",
    "print(f\"Var(X): {X.var()}\")            # Var(X) = λ = 3.5 (same as mean!)\n",
    "print(f\"σ: {X.std()}\")            # σ = √3.5 ≈ 1.87\n",
    "\n",
    "# Random sampling\n",
    "samples = X.rvs(size=10, random_state=42)\n",
    "print(f\"Generated 10 samples: {samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91237087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_poisson(lam=0.7):\n",
    "    print(\"Visual Characteristics\")\n",
    "    print(\"For small λ (< 1):\")\n",
    "    print(\"     Strongly right-skewed\")\n",
    "    print(\"     Mode at 0\")\n",
    "    print(\"     Most probability mass at 0 and 1\")\n",
    "    print(\"For moderate λ (1-10):\")\n",
    "    print(\"     Still right-skewed but less pronounced\")\n",
    "    print(\"     Mode shifts right\")\n",
    "    print(\"     Bell-shape starts emerging\")\n",
    "    print(\"For large λ (> 10):\")\n",
    "    print(\"     Nearly symmetric\")\n",
    "    print(\"     Bell-shaped (resembles Normal)\")\n",
    "    print(\"     Well-approximated by Normal distribution\\n\")\n",
    "    print(\"As λ increases:\")\n",
    "    print(\"     Distribution shifts right (higher mean)\")\n",
    "    print(\"     Distribution spreads out (higher variance)\")\n",
    "    print(\"     Distribution becomes more symmetric\")\n",
    "    print(\"     Approaches Normal distribution\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    x = np.linspace(1, 40, num=40)\n",
    "    X = stats.poisson(lam)\n",
    "    \n",
    "    pmf = []\n",
    "    for xx in x:\n",
    "        pmf.append(X.pmf(xx))\n",
    "    ax.bar(x, pmf, color=['salmon', 'lightgreen'], edgecolor='black', alpha=0.7)\n",
    "    ax.set_xlabel('x (number of events)')\n",
    "    ax.set_ylabel('Probability')\n",
    "    ax.set_title(f'Poisson({lam:.2f}): E[X]={1/p:.2f}, Var(X)={(1-p)/p**2:.4f}')\n",
    "    ax.set_xticks(x)\n",
    "    #ax.set_ylim(0, 1)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.close()\n",
    "    return fig\n",
    "\n",
    "interact(plot_poisson, lam=FloatSlider(min=0.1, max=20, step=0.1, value=0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81b7d3d",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b3281c",
   "metadata": {},
   "source": [
    "|Property | $Bernoulli(p)$ | $Binomial(n, p)$ | $Geometric(p)$ | $Poisson(\\lambda)$ | \n",
    "|------|:-------:|:-----:|:------:|:------:|\n",
    "|**What it counts** | Single trial outcome |Successes in n trials | Trials until 1st success | Events in interval | \n",
    "|**Support** | $\\{0, 1\\}$ |$\\{0, 1, ..., n\\}$| $\\{1, 2, 3, ...\\}$ (infinite) | $\\{0, 1, 2, ...\\}$ (infinite)| \n",
    "|**Parameters** |$p$ |$n, p$| $p$ | $\\lambda$| \n",
    "|**PMF** | $p^k(1-p)^{1-k}$ | $\\binom{n}{k}p^k(1-p)^{n-k}$ | $(1-p)^{k-1}p$ | $\\frac{\\lambda^k e^{-\\lambda}}{k!}$ |\n",
    "|$E[X]$| $p$ | $np$ | $\\frac{1}{p}$ | $\\lambda$ |\n",
    "|$Var(X)$| $p(1-p)$| $np(1-p)$ | $\\frac{1-p}{p^2}$ | $\\lambda$ | \n",
    "|**Mean = Variance?**| No| No| No | ✓ Yes (signature property)|\n",
    "|**Memoryless?**| N/A (single trial) | No | ✓ Yes (signature property) | No (discrete) |\n",
    "|**Fixed # trials?**| Yes ($n=1$) |Yes | No (stops at success) | No|\n",
    "|**Shape** | Two bars | Bell (large n) | Right-skewed (mode=1) | Right-skewed → Normal |\n",
    "|**When to use**| One binary event |Fixed repeated trials| Waiting for 1st event | Rare events, no limit|\n",
    "|**Relationships** |$Bin(1,p)$| Sum of n Bernoullis| $NegBin(r=1, p)$ | Limit of Binomial| \n",
    "|**Typical ML use**| Single neuron dropout| Batch accuracy| Epochs to converge | Server requests|\n",
    "|**Example question** | \"Is prediction correct?\" | \"How many correct in batch?\" | \"How many tries until success?\" | \"How many errors per hour?\" |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aed3a44",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"img/distribution_decision_tree_svg.svg\" alt=\"Choosing distribution decision tree\" width=\"700px\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ffb94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_discrete_rv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995ade3a",
   "metadata": {},
   "source": [
    "## Return to Opening Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35d74c6",
   "metadata": {},
   "source": [
    "Let's analyze our mystery click data systematically:\n",
    "\n",
    "1. Check if it matches $Binomial(n=50, p=0.05)$\n",
    "2. Check if it matches $Poisson(λ=2)$\n",
    "3. Check if it matches $Normal(μ=2, σ²=25)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d25259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mystery_prob()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18394be2",
   "metadata": {},
   "source": [
    "The answer is (b) Poisson(λ=2)!\n",
    "\n",
    "WHY?\n",
    "1. Data is discrete counts $(0, 1, 2, ...)$ → Rules out Normal\n",
    "2. $Mean ≈ Variance ≈ 2$ → Characteristic of Poisson\n",
    "3. Rare events (clicks) over time → Poisson models this well\n",
    "4. No fixed $n$ trials → Binomial doesn't fit\n",
    "\n",
    "KEY LESSON: Distribution choice encodes assumptions about data generation!\n",
    "- Binomial: Fixed $n$ trials, binary outcomes\n",
    "- Poisson: Rare events, no fixed $n$\n",
    "- Normal: Continuous, symmetric around mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe0642b",
   "metadata": {},
   "source": [
    "## Common Mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0620db14",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<h4>⚠️ Common Pitfalls to Avoid:</h4>\n",
    "\n",
    "1. Don't use Normal for discrete counts!\n",
    "2. Binomial needs fixed $n$; Poisson doesn't\n",
    "3. Mean ≈ Variance is Poisson signature\n",
    "4. Remember: $P(X=x)$ vs $P(X\\leq x)$ are different!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f26f034",
   "metadata": {},
   "source": [
    "## Applications in Machine Learning\n",
    "\n",
    "<div class=\"alert alert-secondary\">\n",
    "<h4>🤖 ML Applications Summary</h4>\n",
    "\n",
    "- Bernoulli: Dropout, binary classification outputs\n",
    "- Binomial: Batch accuracy, ensemble voting\n",
    "- Poisson: Rare events (anomalies, server load)\n",
    "- Always check: Does $E[X]$ and $Var(X)$ match your distribution?\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-secondary\">\n",
    "<h4>🔧 Python Essentials</h4>\n",
    "\n",
    "`from scipy import stats`\n",
    "- `stats.binom.pmf(k, n, p)` → $P(X=k)$\n",
    "- `stats.binom.cdf(k, n, p)` → $P(X\\leq k)$\n",
    "- `stats.binom.rvs(n, p, size)` → random samples\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5faf0c7",
   "metadata": {},
   "source": [
    "## Key Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035d1540",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-summary\">\n",
    "<h4>🎓 Key Takeaways</h4>\n",
    "\n",
    "1. Random Variables transform outcomes → numbers (enables math!)\n",
    "2. Discrete R.V.: PMF $p(x) = P(X=x)$, CDF $F(x) = P(X\\leq x)$\n",
    "3. The PMF gives the jump sizes in the CDF\n",
    "4. The CDF is the sum of all PMF values up to x\n",
    "5. Expectation $E[X]$ = center, Variance $Var(X)$ = spread\n",
    "6. Distribution choice encodes data generation assumptions:\n",
    "   - $Bernoulli(p)$: Single binary trial\n",
    "   - $Binomial(n,p)$: Count successes in $n$ trials\n",
    "   - $Poisson(\\lambda)$: Rare events, no fixed $n$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1fd7e1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
