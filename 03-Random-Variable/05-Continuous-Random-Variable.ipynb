{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbd20185",
   "metadata": {},
   "source": [
    "# Random Variables and Continuous Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1b01f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"../styles/styles.css\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d08634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.special import comb\n",
    "import pandas as pd\n",
    "from ipywidgets import interact, FloatSlider, IntSlider\n",
    "from IPython.display import HTML, display, IFrame\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768949c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the \"resources\" directory to the path\n",
    "project_root = Path().resolve().parent\n",
    "resources_path = project_root / 'resources'\n",
    "sys.path.insert(0, str(resources_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51706dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random_variable import(demo_pmf_limitations_cont_rv, discrete_vs_cont_rv, demo_pdf, demo_cdf_disrete_vs_cont, cdf_interval, show_complementary_event_cdf, demo_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ae212d",
   "metadata": {},
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b9911c",
   "metadata": {},
   "source": [
    "- Master continuous probability distributions (Normal, Exponential)\n",
    "- Calculate expectations and variances\n",
    "- Apply distributions to ML scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a499d9ff",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h4>üéØ Weight Initialization Paradox</h3>\n",
    "\n",
    "You're initializing weights for a neural network layer with 100 neurons.\n",
    "\n",
    "**Scenario 1**: Uniform initialization $W \\sim Uniform(-1, 1)$\n",
    "\n",
    "*Question*: What is $P(W = 0.5\\text{ exactly})$?\n",
    "\n",
    "*Your intuition*: \"There are infinite values in $[-1,1]$, so maybe $1/\\infty = 0$?\"\n",
    "\n",
    "*Correct answer*: $P(W = 0.5000000...) = 0$\n",
    "\n",
    "But wait... If EVERY exact value has probability 0, how can ANY weight exist?!\n",
    "\n",
    "**Scenario 2**: Normal initialization $W \\sim \\mathcal{N}(0, 0.01)$\n",
    "\n",
    "You measure a weight: $W = 0.0234$\n",
    "\n",
    "*Question*: What was the probability of getting exactly this value?\n",
    "\n",
    "*Answer*: Also 0!\n",
    "\n",
    "Yet the weight exists... How is this possible?\n",
    "\n",
    "**Scenario 3**: The Real Question</br>\n",
    "If $P(W = \\text{any exact value}) = 0$, how do we calculate:\n",
    "- $P(0.4 < W \\leq 0.6)$?\n",
    "- $P(|W| \\leq 0.1)$?\n",
    "- What's the \"typical\" range for weights?\n",
    "\n",
    "This is the difference between DENSITY and PROBABILITY.\n",
    "\n",
    "Today you'll understand continuous distributions and solve weight initialization properly.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b384fe1",
   "metadata": {},
   "source": [
    "## From Discrete to Continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad489d7",
   "metadata": {},
   "source": [
    "> Why can't we use PMF for continuous variables?\n",
    "</br>\n",
    "\n",
    "Let's consider the following case. We observe 1000 data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1a0d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo hist of 1000 points\n",
    "demo_pmf_limitations_cont_rv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2f36bf",
   "metadata": {},
   "source": [
    "<div class=\"alert .alert-warning\">\n",
    "<h4>üí° Key Insight: Fundamental Difference between Discrete and Continuous R.V.</h4>\n",
    "\n",
    "DISCRETE: $P(X = x)$ can be > 0\n",
    "- Count people: $P(Height = 175\\text{cm exactly})$ makes sense\n",
    "- Finite/countable values\n",
    "\n",
    "CONTINUOUS: $P(X = x) = 0$ always!\n",
    "- Measure height: $P(Height = 175.0000...\\text{ cm})$ = 0\n",
    "- Uncountably infinite values\n",
    "- Instead, we ask: $P(174.5 < Height \\leq 175.5)$?\n",
    "\n",
    "Solution: Use DENSITY, not PROBABILITY\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4284812d",
   "metadata": {},
   "source": [
    "## Probability Density Function, PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8d0c78",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4>Definition: Probability Density Function (PDF)</h4>\n",
    "\n",
    "Let $X$ be an absolutely continuous real r.v. **The probability density function** (or **pdf**) $f_X(x)$ is a positive and integrable function on $\\mathbb{R}$, such that:\n",
    "$$\\mathbb{P}(a\\leq X\\leq b) = \\int_{a}^{b}f(t)dt$$\n",
    "\n",
    "Note that:\n",
    "$f_X(x) = \\frac{d}{dx}F_X(x)$\n",
    "almost everywhere.\n",
    "\n",
    "Properties:\n",
    "\n",
    "* $f_X(x)$ is a **density** (probability per unit length): $f_X(x) = \\lim_{\\Delta\\rightarrow 0}\\frac{\\mathbb{P}(x< X\\leq x + \\Delta)}{\\Delta}$\n",
    "* $f_X(x) \\geq 0$ for all $x$\n",
    "* $f_X(x)$ can be > 1 (unlike PMF)\n",
    "* $\\forall t\\in \\mathbb{R}, \\ f_X(t)\\in \\mathbb{R}^+$\n",
    "* $\\int_{\\mathbb{R}}f(t)dt = 1$\n",
    "* Probability = AREA under $f_X(x)$, not HEIGHT\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d2df1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo PDF can be > 1\n",
    "demo_pdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c12b99",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<h4>‚ö†Ô∏è Common Mistake:</h4>\n",
    "\n",
    "WRONG: \"$f_X(0.5) = 0.8$ means $P(X=0.5) = 0.8$\"</br>\n",
    "RIGHT: \"$f_X(0.5) = 0.8$ means density at $x=0.5$ is $0.8$\"\n",
    "\n",
    "Think of density like \"people per square km\":\n",
    "- 1000 people/km¬≤ doesn't mean 1000 people at a single point!\n",
    "- It means 1000 people spread over 1 km¬≤\n",
    "- Similarly, $f(x)=0.8$ means probability density, not probability\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0600bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo comparison PMF vs PDF\n",
    "discrete_vs_cont_rv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78617a7",
   "metadata": {},
   "source": [
    "## CDF for Continuous Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82387fe5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4>Definition: CDF for Continuous R.V.</h4>\n",
    "\n",
    "$F_X(x) = \\mathbb{P}(X \\leq x) = \\int_{-\\infty}^{x}f_X(t)dt$\n",
    "\n",
    "Thus, the distribution function $F_X(x)$ corresponds to the area under the curve $f_X(x)$\n",
    "\n",
    "Relationship: $f_X(x) = \\frac{d}{dx}F_X(x)$ (PDF is derivative of CDF)\n",
    "\n",
    "**Properties**:\n",
    "\n",
    "1. $F(x)$ is continuous (no jumps!)\n",
    "2. $0 \\leq F(x) \\leq 1$\n",
    "3. $F(-\\infty) = 0$, $F(+\\infty) = 1$\n",
    "4. $F(x)$ is non-decreasing\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d90a214",
   "metadata": {},
   "source": [
    "### Comparison: Discrete vs Continuous CDF Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dbe7aa",
   "metadata": {},
   "source": [
    "| Property | Discrete | Continuous |\n",
    "|---|---|---|\n",
    "| CDF Shape | Step function (jumps at values) | Smooth curve (no jumps)|\n",
    "| $P(X = x)$ | Can be > 0 (height of jump) | Always = 0 (single point)|\n",
    "| $F(x)$ calculation | $F(x) = \\sum_{i} p(x_i)$ for all $x_i ‚â§ x$| $F(x) = \\int_{-\\infty}^x f(t)dt$|\n",
    "| $P(a < X \\leq b)$ formula | $F(b) - F(a)$ </br> SAME FORMULA |  $F(b) - F(a)$ </br> SAME FORMULA |\n",
    "| $P(a < X \\leq b)$ interpretation | Sum of probabilities at discrete points | Area under PDF curve in interval |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce07513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison CDF for cont vs discrete rv\n",
    "demo_cdf_disrete_vs_cont()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f9cb2c",
   "metadata": {},
   "source": [
    "### Interval Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d70bfe",
   "metadata": {},
   "source": [
    "The formula for interval probability holds for the continuous case:\n",
    "\n",
    "$$\\mathbb{P}(a< X\\leq b) = F_X(b) - F_X(a)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a6c62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo CDF on the interval \n",
    "cdf_interval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31095564",
   "metadata": {},
   "source": [
    "### Probability of the Complementary Event"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100779db",
   "metadata": {},
   "source": [
    "Similar to finding the probability of the complementary event, we can find the probability $\\mathbb{P}(X > a)$ as follows:\n",
    "$\\mathbb{P}(X > a) = 1 - \\mathbb{P}(X \\leq a)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5505d1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complementary event CDF\n",
    "show_complementary_event_cdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dea8da2",
   "metadata": {},
   "source": [
    "<div class=\"alert .alert-exercise\">\n",
    "<h4>Calculated Example</h4>\n",
    "\n",
    "Let's take the example proposed in [@orloff2014].\n",
    "\n",
    "The r.v. $X$ is defined on the interval $[0,2]$ by the density function $f(x) = cx^2$.\n",
    "\n",
    "1. What is the value of $c$?\n",
    "2. What is the distribution function $F(x)$?\n",
    "3. What is the probability $\\mathbb{P}(1\\leq X \\leq 2)$?\n",
    "\n",
    "</div>\n",
    "\n",
    "<details>\n",
    "<summary>Reveal solution</summary>\n",
    "\n",
    "1. What is the value of $c$?\n",
    "\n",
    "The sum of probabilities over the entire interval $[a,b]$ on which $X$ is defined must be equal to 1, i.e. $\\int_a^b f(x)dx = 1$. In our case, $X$ is defined on $[0,2]$. Then:\n",
    "\n",
    "$\\int_a^b f(x)dx = \\int_0^2 cx^2 dx = c\\frac{x^3}{3}\\Bigg\\rvert_{0}^2 = c\\frac{8}{3} - 0 = c\\frac{8}{3} = 1$\n",
    "Hence $c = \\mathbf{\\frac{3}{8}}$.\n",
    "\n",
    "By replacing $c$ with this value, we obtain $f(x) = \\frac{3}{8}x^2$.\n",
    "\n",
    "2. What is the distribution function $F(x)$?\n",
    "\n",
    "As a reminder, the distribution function is given by $F(x) = \\mathbb{P}(X\\leq x) = \\int_{-\\infty}^x f(t)dt$. Thus, knowing $f(x)$, we can find $F(x)$.\n",
    "\n",
    "Note that by definition, the density function $f(x)=0$ outside the interval on which $X$ is defined. In our case, we can rewrite $f(x)$ as follows:\n",
    "$f(x) = \\left\\{ \\begin{array}{ll} 0, \\text{ if } x < 0 \\\\ \\frac{3}{8}x^2, \\text{ if } x\\in [0,2] \\\\ 0, \\text{ if } x>2 \\end{array} \\right.$\n",
    "Therefore, the distribution function $F(x) = 0, \\text{ if } x<0$ and $F(x) = 1, \\text{ if } x>2$. It remains to find the distribution function for $x\\in [0, 2]$.\n",
    "\n",
    "$F(x) = \\int_{-\\infty}^x f(t)dt = \\int_{\\mathbf{0}}^x ct^2dt = c\\frac{t^3}{3}\\Bigg\\rvert_{0}^x = c\\frac{x^3}{3} = \\frac{3}{8}\\cdot\\frac{x^3}{3} = \\frac{x^3}{8} = \\left(\\frac{x}{2}\\right)^3$\n",
    "So, putting it all together:\n",
    "\n",
    "$F(x) = \\left\\{ \\begin{array}{ll} 0, \\text{ if } x < 0 \\\\ \\left(\\frac{x}{2}\\right)^3, \\text{ if } x\\in [0,2] \\\\ 1, \\text{ if } x>2 \\end{array} \\right.$\n",
    "\n",
    "\n",
    "3. What is the probability $\\mathbb{P}(1\\leq X \\leq 2)$?\n",
    "We can approach the calculation of $\\mathbb{P}(a\\leq X\\leq b)$ in two ways:\n",
    "\n",
    "1. $\\mathbb{P}(a\\leq X\\leq b) = \\int_a^b f(x)dx$\n",
    "2. $\\mathbb{P}(a\\leq X\\leq b) = F(b) - F(a)$\n",
    "\n",
    "Let's try both options.\n",
    "\n",
    "3.1. Option 1: $\\mathbb{P}(a\\leq X\\leq b) = \\int_a^b f(x)dx$\n",
    "\n",
    "$\\mathbb{P}(1\\leq X\\leq 2) = \\int_1^2 cx^2 dx = c\\frac{x^3}{3}\\Bigg\\rvert_{1}^2 = \\frac{3}{8}\\cdot\\frac{x^3}{3}\\Bigg\\rvert_{1}^2 = \\frac{x^3}{8}\\Bigg\\rvert_{1}^2 = \\frac{8}{8} - \\frac{1}{8} = \\mathbf{\\frac{7}{8}}$\n",
    "\n",
    "3.2. Option 2: $\\mathbb{P}(a\\leq X\\leq b) = F(b) - F(a)$\n",
    "\n",
    "Note that $1\\in [0,2]$ and $2\\in [0,2]$. On the interval in question, the distribution function takes the form $F(x) = \\left(\\frac{x}{2}\\right)^3$. Therefore:\n",
    "\n",
    "$\\mathbb{P}(1\\leq X\\leq 2) = F(2) - F(1) = \\left(\\frac{2}{2}\\right)^3 - \\left(\\frac{1}{2}\\right)^3 = 1 - \\frac{1}{8} = \\mathbf{\\frac{7}{8}}$\n",
    "\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d1c15b",
   "metadata": {},
   "source": [
    "## Expected Value and Variance for Continuous R.V."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5379c7b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4>Definition: Expected Value</h4>\n",
    "\n",
    "**The expectation** (or **expected value** or **mean** or **average** or **first moment**) of a real r.v. $X$, denoted $\\mathbb{E}X$ or $\\mathbb{E}[X]$ or $\\mathbb{E}(X)$ is a generalization of the weighted average value. It can also be seen as the \"center of mass\" of the distribution.\n",
    "\n",
    "Its calculation (when this quantity exists) depends on the nature of $X$:\n",
    "\n",
    "* continuous real r.v.:\n",
    "$\\mathbb{E}[X] = \\int_{-\\infty}^{+\\infty}tf(t)dt$\n",
    "\n",
    "\n",
    "Note that these definitions can be generalized for the expectation of a real r.v. $g(X)$, where $g : X(\\Omega) \\rightarrow \\mathbb{R}$:\n",
    "\n",
    "* continuous case: $\\mathbb{E}[g(X)] = \\int_{-\\infty}^{+\\infty}g(t)f(t)dt$\n",
    "\n",
    "\n",
    "<h5>Properties:</h5>\n",
    "\n",
    "* $\\mathbb{E}[X] \\geq 0$\n",
    "* $\\mathbb{E}[X + Y] = \\mathbb{E}[X] + \\mathbb{E}[Y]$\n",
    "* $\\mathbb{E}[aX + b] = a\\mathbb{E}[X] + b$\n",
    "\n",
    "Note that these results can be generalized for the expectation of a real r.v. $g(X)$, where $g : X(\\Omega) \\rightarrow \\mathbb{R}$:\n",
    "\n",
    "* $\\mathbb{E}[g(X)] \\geq 0$\n",
    "* $\\mathbb{E}[g_1(X) + g_2(X)] = \\mathbb{E}[g_1(X)] + \\mathbb{E}[g_2(X)]$\n",
    "* $\\mathbb{E}[ag(X)] = a\\mathbb{E}[g(X)] + b$\n",
    "* let $X$ be a continuous real r.v., $g_1$ and $g_2$ two functions such that $g_1 \\leq g_2$, then $\\mathbb{E}[g_1(X)] \\leq \\mathbb{E}[g_2(X)]$\n",
    "* if $X$ is a constant real r.v. on $\\Omega$ and $g$ any function, then $\\mathbb{E}[g(X)] = g(X)$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dfd7ce",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4>Definition: Variance</h4>\n",
    "\n",
    "**The variance** of the real r.v. $X$, denoted $Var(X)$ or $\\sigma^2$, is a measure of the dispersion of data around its expectation $\\mathbb{E}X$.\n",
    "\n",
    "Its calculation (when this quantity exists) depends on the nature of $X$:\n",
    "\n",
    "* continuous real r.v.:\n",
    "$Var(X) = \\mathbb{E}[(X-\\mathbb{E}X)^2] = \\mathbb{E}[X^2]-(\\mathbb{E}X)^2=\\int_{a}^{b}(x-\\mathbb{E}X)^2f(x)dx$\n",
    "\n",
    "<h5>Properties:</h5>\n",
    "\n",
    "* $Var(X) \\geq 0$\n",
    "* $Var(X + Y) = Var[X] + Var[Y]\\text{, (if } X\\text{ and } Y\\text{ indep.)}$\n",
    "* $Var(aX + b) = a^2Var(X)$\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<h4>Definition: Standard Deviation</h4>\n",
    "\n",
    "**The standard deviation** (or **std**) of the real r.v. $X$, denoted $\\sqrt{Var(X)}$ or $\\sigma$, is a measure of the deviation between the values taken by $X$ and its expectation $\\mathbb{E}X$\n",
    "\n",
    "$\\sigma(X)=\\sigma_X = \\sqrt{Var(X)}$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a3b253",
   "metadata": {},
   "source": [
    "## Common Continuous Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8b52ac",
   "metadata": {},
   "source": [
    "### Uniform Distribution, $\\mathcal{U}(a, b)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d01388",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-example\">\n",
    "<h4>Uniform Distribution</h4>\n",
    "\n",
    "$X \\sim \\mathcal{U}(a,b)$ or $X \\sim \\mathcal{U}[a,b]$ or $X \\sim Uniform(a,b)$\n",
    "\n",
    "**When to use:**\n",
    "\n",
    "Models situations where **all values in an interval are equally likely**. It represents complete uncertainty within a bounded range - no value is preferred over any other.\n",
    "\n",
    "- All outcomes in a range are equally probable\n",
    "- You have no reason to prefer one value over another\n",
    "- Modeling random selection from an interval\n",
    "- Need a \"baseline\" or \"uninformative\" distribution\n",
    "\n",
    "**Parameters & Domain:**\n",
    "- Parameters: \n",
    "\n",
    "    * $a \\in \\mathbb{R}$: lower bound (minimum value)\n",
    "    * $b \\in \\mathbb{R}$: upper bound (maximum value)\n",
    "    * Constraint: $a < b$\n",
    "\n",
    "- Support (Domain): $X \\in [a, b]$\n",
    "\n",
    "\n",
    "\n",
    "| PMF | CDF | $E(X)$ | $Var(X)$| $\\sigma$|\n",
    "|:---:|:---:|:----:|:---:|:---:|\n",
    "|$$f(x) = \\begin{cases} \\frac{1}{b-a} & \\text{if } a \\leq x \\leq b \\\\0 & \\text{otherwise}\\end{cases}$$ *Interpretation:*</br> Constant density across the entire interval</br>Height = 1/(width) ensures total area = 1</br> Rectangular shape (hence \"rectangular distribution\")| $$F(x) = P(X \\leq x) = \\begin{cases} 0 & \\text{if } x < a \\\\ \\frac{x-a}{b-a} & \\text{if } a \\leq x \\leq b \\\\1 & \\text{if } x > b\\end{cases}$$ *Interpretation:* </br> Linear growth from 0 to 1 across $[a, b]$</br> $Slope = 1/(b-a)$ = constant density| $$\\frac{a + b}{2}$$ Midpoint of the interval (by symmetry)| $$\\frac{(b-a)^2}{12}$$ | $$\\frac{b-a}{2\\sqrt{3}}\\approx 0.289(b-a)$$|\n",
    "\n",
    "**Key Properties:**\n",
    "\n",
    "1. Symmetry: Symmetric around the midpoint $(a+b)/2$\n",
    "2. Memoryless on intervals: If $X \\sim U(a,b)$ and you know $X \\in (c,d) ‚äÇ (a,b)$, then $X|(X \\in (c,d)) \\sim U(c,d)$\n",
    "3. Transformation property: If $X \\sim U(0,1)$, then $Y = a + (b-a)X \\sim U(a,b)$\n",
    "4. Standard uniform: $U(0,1)$ is the base case:\n",
    "\n",
    "- Computer random number generators produce U(0,1)\n",
    "- Can transform to any other distribution\n",
    "\n",
    "5. Maximum entropy: Among all distributions on $[a,b]$, Uniform has maximum entropy (maximum uncertainty)\n",
    "6. Quantile function (inverse CDF):\n",
    " $$F^{-1}(p) = a + p(b-a)$$\n",
    "7. Mode: Not unique (all values in $[a,b]$ are equally likely)\n",
    "\n",
    "**Real-world examples:**\n",
    "1. Physical/Natural:\n",
    "\n",
    "- Angle of a spinner ($U(0, 360¬∞)$)\n",
    "- Position where a dart hits (if truly random)\n",
    "- Breaking point of a uniformly weak rod\n",
    "- Round-off errors in measurements\n",
    "\n",
    "2. Time-based:\n",
    "\n",
    "- Arrival time when \"sometime between 2-3 PM\" with equal probability\n",
    "- Random moment within a time window\n",
    "- Phase of a periodic signal at random observation\n",
    "\n",
    "3. Selection:\n",
    "\n",
    "- Random number from a range\n",
    "- Coordinates within a square/rectangle\n",
    "- Random point on a line segment\n",
    "\n",
    "**Typical Events This Describes**\n",
    "\n",
    "\"Anywhere in this range is equally likely\":\n",
    "\n",
    "- Initial guess when you know bounds but nothing else\n",
    "- Random sampling from a known range\n",
    "- Uniform allocation across resources\n",
    "- Monte Carlo sampling baseline\n",
    "\n",
    "*Key characteristic*: Complete lack of bias within the interval\n",
    "\n",
    "**Relationships to Other Distributions:**\n",
    "1. Parent/Child Relationships:\n",
    "\n",
    "- Standard Uniform $U(0,1)$: Base case for all distributions\n",
    "- If $U \\sim U(0,1)$: Then $a + (b-a)U \\sim U(a,b)$\n",
    "\n",
    "2. Connection to other distributions:\n",
    "\n",
    "- Order statistics: If $X_1, ..., X_n \\sim U(0,1)$ are ordered, the gaps follow Beta distributions\n",
    "- Sum of Uniforms: Sum of $n$ independent $U(0,1) \\rightarrow Normal$ (by CLT as $n\\rightarrow \\infty$)\n",
    "- Max/Min of Uniforms: $Max$ of $n$ $U(0,1)$ $\\sim Beta(n, 1)$, $Min \\sim Beta(1, n)$\n",
    "\n",
    "3. Inverse Transform Method:\n",
    "\n",
    "- If $F$ is any CDF and $U \\sim U(0,1)$, then $F^{-1}(U)$ follows distribution $F$\n",
    "\n",
    "This is how we generate random samples from any distribution!\n",
    "\n",
    "4. Limiting case:\n",
    "\n",
    "- Can approximate any distribution over $[a,b]$ with mixture of uniforms\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b3b7ae",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-primary\">\n",
    "<h4>ü§ñ ML Applications</h4>\n",
    "\n",
    "1. Initialization:\n",
    "\n",
    "- Weight initialization (old method): $W \\sim U(-c, c)$\n",
    "\n",
    "Before Xavier/He, uniform was common\n",
    "\n",
    "Example: $U(-1/\\sqrt{n}, 1/\\sqrt{n})$ for layer with $n$ inputs\n",
    "\n",
    "Still used for some architectures (embeddings)\n",
    "\n",
    "\n",
    "2. Regularization:\n",
    "\n",
    "- Dropout variant: Random dropout rate $\\sim U(0.1, 0.5)$\n",
    "- Data augmentation: Random crop position, rotation angle\n",
    "- Label smoothing: Mix true label with uniform over all classes\n",
    "\n",
    "3. Optimization:\n",
    "\n",
    "- Random search: Hyperparameter values ~ Uniform over range\n",
    "- Batch shuffling: Random permutation of training data\n",
    "- Random restart: Initial guess ~ Uniform over feasible region\n",
    "\n",
    "4. Sampling:\n",
    "\n",
    "- Monte Carlo integration: Sample points $\\sim U(domain)$\n",
    "- Rejection sampling: Accept/reject based on $U(0,1)$\n",
    "- Stochastic gradient descent: Random mini-batch selection\n",
    "\n",
    "5. Exploration:\n",
    "\n",
    "- Epsilon-greedy: With probability $\\epsilon$, choose action $\\sim Uniform$\n",
    "- Uniform exploration: Random action selection in RL\n",
    "- Random feature generation: Random Fourier features\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff93ae1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<h4>‚ö†Ô∏è Common Pitfalls:</h4>\n",
    "\n",
    "‚ùå Thinking it's appropriate for unbounded ranges\n",
    "\n",
    "- Uniform ONLY works on finite intervals $[a, b]$\n",
    "- Can't have $U(-\\infty, \\infty)$ (doesn't integrate to 1)\n",
    "\n",
    "‚ùå Confusing discrete uniform with continuous uniform\n",
    "\n",
    "- Discrete: $U\\{1,2,3,4,5,6\\}$ (die roll) - PMF\n",
    "- Continuous: $U(1,6)$ - PDF\n",
    "- They're different distributions!\n",
    "\n",
    "‚ùå Assuming \"random\" means uniform\n",
    "\n",
    "- Many processes are NOT uniform (e.g., human reaction times)\n",
    "- Check assumptions before using uniform\n",
    "\n",
    "‚ùå Forgetting the 1/12 factor in variance\n",
    "\n",
    "- Common mistake: using $(b-a)^2$ instead of $(b-a)^2/12$\n",
    "\n",
    "‚ùå Using uniform for everything in early ML\n",
    "\n",
    "- Xavier/He initialization (Normal) is usually better\n",
    "- Uniform can work but Normal often preferred\n",
    "\n",
    "‚ö†Ô∏è Edge cases:\n",
    "\n",
    "- Check if endpoints $a$, $b$ are included (closed interval $[a,b]$)\n",
    "- $P(X = a) = P(X = b) = 0$ (continuous), but support includes them\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c878f35",
   "metadata": {},
   "source": [
    "We can use SciPy implementation of this distribution, [`scipy.stats.uniform`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.uniform.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f788091",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = 2, 5\n",
    "X = stats.uniform(loc=a, scale=b-a)  # loc=a, scale=width\n",
    "\n",
    "# IMPORTANT: scipy uses loc (start) and scale (width), NOT (a, b) directly!\n",
    "# For U(a, b): use loc=a, scale=b-a\n",
    "\n",
    "x = 3.5\n",
    "# PDF\n",
    "print(f\"f({x}) = {X.pdf(x):.4f}\")  # P(X = 3.5) = 1/(b-a) = 1/3\n",
    "\n",
    "# CDF\n",
    "print(f\"F({x}) = {X.cdf(x):.4f}\")  # F(x) = (x-a)/(b-a) = 0.5\n",
    "\n",
    "# Probability of interval\n",
    "prob = X.cdf(4) - X.cdf(3)\n",
    "print(f\"P(3 ‚â§ X ‚â§ 4) = {prob:.4f}\")  # F(4) - F(3) = 1/3\n",
    "\n",
    "# Moments\n",
    "print(f\"E[X] = {X.mean()}\")           # E[X] = (1-p)/p (failures), or 1/p (trials)\n",
    "print(f\"Var(X) = {X.var()}\")            # Var(X) = (1-p)/p¬≤\n",
    "print(f\"œÉ = {X.std()}\")            # œÉ\n",
    "\n",
    "# Random sampling\n",
    "samples = X.rvs(size=10, random_state=42)\n",
    "# These are number of failures; add 1 for number of trials\n",
    "print(f\"Generated 10 samples: {samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de6454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_uniform(a=-2.0, b=3.0):\n",
    "    \"\"\"\n",
    "    Interactive visualization of Uniform distribution\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    a : float - lower bound\n",
    "    b : float - upper bound\n",
    "    \"\"\"\n",
    "    print(\"Visual Characteristics\")\n",
    "    print(\"PDF Shape:\")\n",
    "    print(\"      Rectangular/flat across [a, b]\")\n",
    "    print(\"      Height = 1/(b-a)\")\n",
    "    print(\"      Zero outside [a, b]\")\n",
    "    print(\"      Sharp discontinuities at endpoints\")\n",
    "    print(\"CDF Shape:\")\n",
    "    print(\"      Linear ramp from 0 to 1\")\n",
    "    print(\"      Constant slope = 1/(b-a)\")\n",
    "    print(\"      Horizontal at 0 before a\")\n",
    "    print(\"      Horizontal at 1 after b\")\n",
    "    print(\"Key visual features:\")\n",
    "    print(\"      Perfect symmetry\")\n",
    "    print(\"      No peak (uniform height)\")\n",
    "    print(\"      Clear bounded support\")\n",
    "    \n",
    "    \n",
    "    # Create distribution\n",
    "    if a >= b:\n",
    "        print(\"Error: a must be < b\")\n",
    "        return\n",
    "    \n",
    "    uniform_dist = stats.uniform(loc=a, scale=b-a)\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig = plt.figure(figsize=(8, 4))\n",
    "    gs = fig.add_gridspec(1, 2, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Panel 1: PDF\n",
    "    # ========================================================================\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    \n",
    "    x_range = np.linspace(a-1, b+1, 500)\n",
    "    pdf_values = uniform_dist.pdf(x_range)\n",
    "    \n",
    "    ax1.fill_between(x_range, pdf_values, alpha=0.3, color='skyblue')\n",
    "    ax1.plot(x_range, pdf_values, 'b-', linewidth=2.5)\n",
    "    ax1.axvline(a, color='red', linestyle='--', alpha=0.7, linewidth=1.5, label='Bounds')\n",
    "    ax1.axvline(b, color='red', linestyle='--', alpha=0.7, linewidth=1.5)\n",
    "    ax1.axvline((a+b)/2, color='green', linestyle=':', linewidth=2, label='Mean')\n",
    "    \n",
    "    ax1.set_xlabel('x', fontsize=11)\n",
    "    ax1.set_ylabel('f(x) - Density', fontsize=11)\n",
    "    ax1.set_title(f'PDF: Uniform({a:.2f}, {b:.2f})', fontsize=12, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_ylim(0, max(pdf_values) * 1.3 if max(pdf_values) > 0 else 1)\n",
    "    \n",
    "    # Add text box with PDF formula\n",
    "    pdf_text = f'f(x) = {1/(b-a):.3f} for x ' + r'$\\in$' + f' [{a:.1f}, {b:.1f}]'\n",
    "    ax1.text(0.5, 0.95, pdf_text, transform=ax1.transAxes,\n",
    "            verticalalignment='top', horizontalalignment='center',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),\n",
    "            fontsize=10)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Panel 2: CDF\n",
    "    # ========================================================================\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    \n",
    "    cdf_values = uniform_dist.cdf(x_range)\n",
    "    \n",
    "    ax2.plot(x_range, cdf_values, 'r-', linewidth=2.5)\n",
    "    ax2.axhline(0, color='gray', linestyle=':', alpha=0.5)\n",
    "    ax2.axhline(1, color='gray', linestyle=':', alpha=0.5)\n",
    "    ax2.axhline(0.5, color='green', linestyle=':', linewidth=1.5, label='Median')\n",
    "    ax2.axvline(a, color='red', linestyle='--', alpha=0.7, linewidth=1.5)\n",
    "    ax2.axvline(b, color='red', linestyle='--', alpha=0.7, linewidth=1.5)\n",
    "    \n",
    "    ax2.set_xlabel('x', fontsize=11)\n",
    "    ax2.set_ylabel('F(x) = P(X ‚â§ x)', fontsize=11)\n",
    "    ax2.set_title('CDF: Cumulative Distribution', fontsize=12, fontweight='bold')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_ylim(-0.05, 1.05)\n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "interact(plot_uniform,\n",
    "         a=FloatSlider(min=-10, max=0, step=0.5, value=-2, description='Lower (a):'),\n",
    "         b=FloatSlider(min=0, max=10, step=0.5, value=3, description='Upper (b):'))\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f39abec",
   "metadata": {},
   "source": [
    "### Exponential Distribution, $\\mathcal{E}(\\lambda)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3fc0c1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-example\">\n",
    "<h4>Exponential Distribution</h4>\n",
    "\n",
    "$X \\sim \\mathcal{E}(\\lambda)$ or $X \\sim Exp(\\lambda)$ or $X \\sim Exponential(\\lambda)$\n",
    "\n",
    "**When to use:**\n",
    "\n",
    "The exponential distribution models **waiting times** or **time between events** in a Poisson process. It describes how long you wait for the **first occurrence** of an event when events happen randomly at a constant average rate.\n",
    "\n",
    "- Modeling time until an event occurs\n",
    "- Events happen independently at a constant rate\n",
    "- You're measuring \"time until failure\" or \"duration\"\n",
    "- Analyzing lifetimes or survival times\n",
    "- Continuous analog of the Geometric distribution\n",
    "\n",
    "**Parameters & Domain:**\n",
    "- Parameter: $\\lambda > 0$ rate parameter (events per unit time) \n",
    "\n",
    "    * $\\lambda = 1/\\mu$ where $\\mu$ is the mean waiting time\n",
    "    * Higher $Œª$ ‚Üí shorter waiting times (events happen more frequently)\n",
    "\n",
    "Alternative Parameterization:\n",
    "\n",
    "- Some sources use $\\beta = 1/\\lambda$ (scale parameter = mean)\n",
    "- `scipy` uses `scale = 1/Œª`    \n",
    "\n",
    "- Support (Domain): $X \\in [0, \\infty]$\n",
    "\n",
    "Always non-negative (can't have negative waiting times)\n",
    "\n",
    "\n",
    "\n",
    "| PMF | CDF | $E(X)$ | $Var(X)$| $\\sigma$|\n",
    "|:---:|:---:|:----:|:---:|:---:| \n",
    "|$$f(x) = \\begin{cases} \\lambda e^{-\\lambda x} & \\text{if } x \\geq 0 \\\\0 & \\text{if } x < 0\\end{cases}$$ or $\\lambda e^{-\\lambda x}$ for $x\\geq 0$</br>*Interpretation:*</br>Exponential decay starting from $\\lambda$ at $x=0$</br>Peak at $x=0$ ($mode = 0$)</br>Long right tail (some events take much longer)</br>Decay rate controlled by $\\lambda$ | $$F(x) = P(X \\leq x) = \\begin{cases} 1 - e^{-\\lambda x} & \\text{if } x \\geq 0 \\\\ 0 & \\text{if } x < 0 \\end{cases}$$ **Survival function** $$S(x) = P(X > x) = e^{-\\lambda x}$$ *Interpretation:*</br>$F(x)$ grows from 0 to 1 (asymptotically) </br>$S(x)$ = probability of waiting longer than $x$</br>Half-life: time for $S(x)$ to reach 0.5| $$\\frac{1}{\\lambda}$$ Average waiting time = inverse of rate| $$\\frac{1}{\\lambda^2}$$ | $$\\frac{1}{\\lambda}$$ mean = standard deviation|\n",
    "\n",
    "**Key Properties:**\n",
    "\n",
    "1. Mode: 0 (distribution peaks at zero, then decays)\n",
    "2. Memoryless Property (Most Important!): \n",
    "$$P(X > s + t ‚à£ X > s) = P(X>t)$$\n",
    "*Interpretation:* \"The future doesn't depend on the past\". If you've already waited $s$ time units, the probability of waiting $t$ more is the same as waiting $t$ from the start\n",
    "3. Relationship to Poisson Process: If events occur according to $Poisson(\\lambda)$ process:\n",
    "\n",
    "- Number of events in time $t \\sim Poisson(\\lambda t)$\n",
    "- Time until first event $\\sim Exponential(\\lambda)$\n",
    "- Time between consecutive events $\\sim Exponential(\\lambda)$\n",
    "4. Minimum of Exponentials: If $X_1, ..., X_n$ are independent $Exp(\\lambda_i)$:\n",
    "$$min(X_1‚Äã,...,X_n‚Äã)‚àºExp(\\lambda_1‚Äã + ... + \\lambda_n‚Äã)$$\n",
    "5. Sum of Exponentials: Sum of $n$ independent $Exp(\\lambda) ‚Üí Gamma(n, \\lambda)$ distribution\n",
    "6. Scaling Property: If $X \\sim Exp(\\lambda)$, then $cX \\sim Exp(\\lambda/c)$ for $c > 0$\n",
    "\n",
    "\n",
    "**Real-world examples:**\n",
    "1. Time-Based:\n",
    "\n",
    "- Time until next phone call arrives\n",
    "- Lifetime of electronic components\n",
    "- Time between arrivals at service counter\n",
    "- Duration of phone calls\n",
    "- Time until radioactive decay\n",
    "\n",
    "2. System Reliability:\n",
    "\n",
    "- Time to failure for devices with constant hazard rate\n",
    "- Server uptime before crash\n",
    "- Time between network packet arrivals\n",
    "- Battery lifetime (simplified model)\n",
    "\n",
    "3. Natural Phenomena:\n",
    "\n",
    "- Time between earthquakes (approximation)\n",
    "- Intervals between lightning strikes\n",
    "- Waiting time for rain to start\n",
    "\n",
    "4. Service/Queue:\n",
    "\n",
    "- Service time at a server (if memory-less)\n",
    "- Inter-arrival times in queuing systems\n",
    "- Time to complete a task\n",
    "\n",
    "**Typical Events This Describes**\n",
    "\n",
    "\"Time until something happens\" when:\n",
    "\n",
    "- Events occur randomly\n",
    "- No \"aging\" or \"learning\" (memoryless)\n",
    "- Constant hazard rate\n",
    "- Independent events\n",
    "\n",
    "*Key characteristics:*\n",
    "\n",
    "- Most events happen quickly (mode at 0)\n",
    "- Some events take much longer (long tail)\n",
    "- No memory of past waiting\n",
    "\n",
    "**Relationships to Other Distributions:**\n",
    "1. Discrete Analog:\n",
    "\n",
    "- Geometric distribution is discrete version\n",
    "- Geometric counts trials, Exponential measures time\n",
    "- Both are memoryless\n",
    "\n",
    "2. Parent Distribution:\n",
    "\n",
    "- $Gamma(k, \\lambda)$: Exponential is $Gamma(1, \\lambda)$\n",
    "- Sum of $k$ independent $Exp(\\lambda) ~ Gamma(k, \\lambda)$\n",
    "\n",
    "3. Related to Poisson:\n",
    "\n",
    "- If $N(t) \\sim Poisson(\\lambda t)$ counts events, then inter-arrival times $\\sim Exp(\\lambda)$\n",
    "\n",
    "4. Continuous Uniform Connection:\n",
    "\n",
    "If $X \\sim Exp(\\lambda)$, then $1 - e^{-\\lambda X} \\sim Uniform(0, 1)$\n",
    "Used for generating exponential random variables\n",
    "\n",
    "5. Weibull Distribution:\n",
    "\n",
    "- Exponential is Weibull with shape parameter $k=1$\n",
    "- Weibull allows non-constant hazard rates\n",
    "\n",
    "6. Chi-squared:\n",
    "\n",
    "$2\\lambda X \\sim \\chi^2(2)$ if $X \\sim Exp(\\lambda)$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f86a80",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-primary\">\n",
    "<h4>ü§ñ ML Applications</h4>\n",
    "\n",
    "1. System Monitoring:\n",
    "\n",
    "- Server failure prediction: Time until server fails\n",
    "- Request inter-arrival times: Model traffic patterns\n",
    "- Session duration: How long users stay active\n",
    "- Response time modeling: Server/API latency (simplified)\n",
    "\n",
    "2. Reinforcement Learning:\n",
    "\n",
    "- Episode length: Time until termination in continuous time\n",
    "- Event-triggered learning: Time between state changes\n",
    "- Exploration strategies: Random wait times\n",
    "\n",
    "3. Generative Models:\n",
    "\n",
    "- Event timing in sequences: Time stamps in temporal data\n",
    "- Survival analysis: Time until event (customer churn, etc.)\n",
    "- Hawkes processes: Self-exciting point processes\n",
    "\n",
    "4. Network & Communication:\n",
    "\n",
    "- Packet inter-arrival: Time between network packets\n",
    "- Transmission delays: Simplified communication models\n",
    "- Timeout settings: When to declare connection lost\n",
    "\n",
    "5. Anomaly Detection:\n",
    "\n",
    "- Baseline timing model: Normal inter-event times\n",
    "- Deviation detection: Unusually long/short waits indicate anomalies\n",
    "- Failure prediction: Based on time since last event\n",
    "\n",
    "6. Queueing Systems:\n",
    "\n",
    "- Service time distribution: Time to serve a request\n",
    "- Arrival process modeling: $M/M/1$ queues (Markovian)\n",
    "- Wait time analysis: Expected delays\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1df5528",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<h4>‚ö†Ô∏è Common Pitfalls:</h4>\n",
    "\n",
    "‚ùå Assuming memoryless property applies to real systems\n",
    "\n",
    "- Many real systems DO have memory (aging, learning)\n",
    "- Example: Battery life increases failure rate over time (NOT exponential)\n",
    "- Example: Human waiting patience decreases (NOT memoryless)\n",
    "- Exponential is an approximation, often valid only for short times\n",
    "\n",
    "‚ùå Confusing rate $\\lambda$ with mean\n",
    "\n",
    "- $Mean = 1/\\lambda$ (inverse relationship!)\n",
    "- $\\lambda = 2\\text{ events/hour} \\rightarrow \\text{mean wait} = 0.5\\text{ hours}$\n",
    "- Common error: using $\\lambda$ directly as mean\n",
    "\n",
    "‚ùå Using for non-constant hazard rates\n",
    "\n",
    "- Exponential assumes constant failure rate\n",
    "- If hazard rate changes over time, use Weibull or other distributions\n",
    "- Bathtub curve (early failures, stable, wear-out) NOT exponential\n",
    "\n",
    "‚ùå `scipy` parameterization confusion\n",
    "\n",
    "- `scipy` uses `scale = 1/Œª` (mean), not `Œª` directly!\n",
    "- `stats.expon(scale=2)` has $Œª=0.5$, $mean=2$\n",
    "- Must remember to use `scale = 1/Œª`\n",
    "\n",
    "‚ùå Forgetting support is $[0, \\infty)$\n",
    "\n",
    "- Cannot have negative waiting times\n",
    "- Check if data has natural lower bound at 0\n",
    "\n",
    "‚ö†Ô∏è Overdispersion issues:\n",
    "\n",
    "- Exponential has $Var = Mean^2$ (high variance relative to mean)\n",
    "- If real data has lower variance, consider other distributions\n",
    "- If higher variance, consider mixture models\n",
    "\n",
    "‚ùå Using for \"time to nth event\"\n",
    "\n",
    "- Exponential is for FIRST event\n",
    "- For $n$-th event, use $Gamma(n, \\lambda)$ or Erlang distribution\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc83db57",
   "metadata": {},
   "source": [
    "We can use SciPy implementation of this distribution, [`scipy.stats.expon`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.expon.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25f421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_rate = 3.0  # events per minute\n",
    "mean_time = 1 / lambda_rate  # mean waiting time = 1/3 minute\n",
    "\n",
    "# IMPORTANT: scipy uses scale (mean), not rate!\n",
    "exp_dist = stats.expon(scale=mean_time)  # scale = 1/Œª = 1/3\n",
    "\n",
    "# Alternative (equivalent)\n",
    "exp_dist_alt = stats.expon(scale=1/lambda_rate)\n",
    "\n",
    "# PDF\n",
    "x = 0.5  # 0.5 minutes\n",
    "pdf_value = exp_dist.pdf(x)\n",
    "print(f\"PDF at {x}: f({x}) = {pdf_value:.4f}\")\n",
    "# Manual: Œª * e^(-Œªx) = 3 * e^(-3*0.5) ‚âà 0.669\n",
    "\n",
    "# CDF\n",
    "cdf_value = exp_dist.cdf(x)\n",
    "print(f\"CDF at {x}: F({x}) = {cdf_value:.4f}\")\n",
    "print(f\"P(wait ‚â§ {x} min) = {cdf_value:.4f}\")\n",
    "# Manual: 1 - e^(-Œªx) = 1 - e^(-1.5) ‚âà 0.777\n",
    "\n",
    "# Survival function (more intuitive for waiting times)\n",
    "survival = exp_dist.sf(x)  # P(X > x) = e^(-Œªx)\n",
    "print(f\"P(wait > {x} min) = {survival:.4f}\")\n",
    "print(f\"Verification: {1 - cdf_value:.4f}\")\n",
    "\n",
    "# Mean and variance\n",
    "print(f\"\\nMean: {exp_dist.mean():.4f} (should be {1/lambda_rate:.4f})\")\n",
    "print(f\"Variance: {exp_dist.var():.4f} (should be {(1/lambda_rate)**2:.4f})\")\n",
    "print(f\"Std: {exp_dist.std():.4f} (equals mean for exponential!)\\n\")\n",
    "\n",
    "# Random sampling\n",
    "samples = exp_dist.rvs(size=10, random_state=42)\n",
    "print(f\"Generated 10 samples: {samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c0ff64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_expon(lambda_rate=2.0):    \n",
    "    \"\"\"\n",
    "    Interactive visualization of Exponential distribution\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    lambda_rate : float - rate parameter (events per unit time)\n",
    "    \"\"\"\n",
    "    print(\"Visual Characteristics\")\n",
    "    print(\"PDF Shape:\")\n",
    "    print(\"     Monotonically decreasing from maximum at x=0\")\n",
    "    print(\"     Long right tail (some values much larger than mean)\")\n",
    "    print(\"     Exponential decay: f(x) = Œªe^(-Œªx)\")\n",
    "    print(\"     Peak at zero (mode = 0)\")\n",
    "    print(\"     Most probability mass near zero\")\n",
    "    print(\"CDF Shape:\")\n",
    "    print(\"     Starts at 0 (at x=0)\")\n",
    "    print(\"     Asymptotically approaches 1 (never quite reaches it)\")\n",
    "    print(\"     Concave (second derivative negative)\")\n",
    "    print(\"     Steeper rise for larger Œª (events happen faster)\")\n",
    "    print(\"Effect of Œª:\")\n",
    "    print(\"     Large Œª: Steep decay, short waiting times, concentrated near zero\")\n",
    "    print(\"     Small Œª: Slow decay, long waiting times, more spread out\")\n",
    "    print(\"Key visual features:\")\n",
    "    print(\"     Always skewed right (positive skew)\")\n",
    "    print(\"     No inflection point\")\n",
    "    print(\"     Simple exponential curve\")\n",
    "    \n",
    "    if lambda_rate <= 0:\n",
    "        print(\"Error: Œª must be > 0\")\n",
    "        return\n",
    "    \n",
    "    # Create distribution (remember: scipy uses scale = 1/Œª)\n",
    "    exp_dist = stats.expon(scale=1/lambda_rate)\n",
    "    \n",
    "    mean_val = 1 / lambda_rate\n",
    "    var_val = 1 / (lambda_rate ** 2)\n",
    "    std_val = 1 / lambda_rate\n",
    "    median_val = np.log(2) / lambda_rate\n",
    "    \n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=(8, 4))\n",
    "    gs = fig.add_gridspec(1, 2, hspace=0.35, wspace=0.3)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Panel 1: PDF\n",
    "    # ========================================================================\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    \n",
    "    x_max = max(10/lambda_rate, 5)  # Show enough of the tail\n",
    "    x_range = np.linspace(0, x_max, 500)\n",
    "    pdf_values = exp_dist.pdf(x_range)\n",
    "    \n",
    "    ax1.fill_between(x_range, pdf_values, alpha=0.3, color='orange')\n",
    "    ax1.plot(x_range, pdf_values, 'darkorange', linewidth=2.5)\n",
    "    ax1.axvline(mean_val, color='blue', linestyle='--', linewidth=2, label=f'Mean={mean_val:.3f}')\n",
    "    ax1.axvline(median_val, color='green', linestyle=':', linewidth=2, label=f'Median={median_val:.3f}')\n",
    "    ax1.axvline(0, color='red', linestyle='-', linewidth=1.5, alpha=0.7, label='Mode=0')\n",
    "    \n",
    "    ax1.set_xlabel('x (time)', fontsize=11)\n",
    "    ax1.set_ylabel('f(x) - Density', fontsize=11)\n",
    "    ax1.set_title(f'PDF: Exponential(Œª={lambda_rate:.3f})', fontsize=12, fontweight='bold')\n",
    "    ax1.legend(fontsize=9)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add formula\n",
    "    ax1.text(0.98, 0.98, f'f(x) = {lambda_rate:.3f}e^(-{lambda_rate:.3f}x)',\n",
    "            transform=ax1.transAxes, verticalalignment='top', horizontalalignment='right',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),\n",
    "            fontsize=10)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Panel 2: CDF and Survival Function\n",
    "    # ========================================================================\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    \n",
    "    cdf_values = exp_dist.cdf(x_range)\n",
    "    sf_values = exp_dist.sf(x_range)  # Survival function = 1 - CDF\n",
    "    \n",
    "    ax2.plot(x_range, cdf_values, 'b-', linewidth=2.5, label='CDF F(x)')\n",
    "    ax2.plot(x_range, sf_values, 'r--', linewidth=2.5, label='Survival S(x)=1-F(x)')\n",
    "    ax2.axhline(0.5, color='green', linestyle=':', alpha=0.7)\n",
    "    ax2.axvline(median_val, color='green', linestyle=':', alpha=0.7)\n",
    "    ax2.plot(median_val, 0.5, 'go', markersize=10, label='Median')\n",
    "    \n",
    "    ax2.set_xlabel('x (time)', fontsize=11)\n",
    "    ax2.set_ylabel('Probability', fontsize=11)\n",
    "    ax2.set_title('CDF and Survival Function', fontsize=12, fontweight='bold')\n",
    "    ax2.legend(fontsize=9)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_ylim(-0.05, 1.05)\n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "interact(plot_expon,\n",
    "         lambda_rate=FloatSlider(min=0.1, max=10, step=0.1, value=0.7, description='Rate (# events per unit time)'),\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edcf949",
   "metadata": {},
   "source": [
    "### Normal (Gaussian) Distribution, $\\mathcal{N}(\\mu, \\sigma^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb18d91",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-example\">\n",
    "<h4>Normal Distribution</h4>\n",
    "\n",
    "$X \\sim \\mathcal{N}(\\mu, \\sigma^2)$ or $X \\sim Normal(\\mu, \\sigma^2)$\n",
    "\n",
    "**When to use:**\n",
    "\n",
    "The most important distribution in statistics and machine learning. It models phenomena where values cluster symmetrically around a central mean, with variation governed by a bell-shaped curve.\n",
    "\n",
    "- Data is symmetric around the mean\n",
    "- Variation comes from many small, independent random effects\n",
    "- Modeling measurement errors\n",
    "- Central Limit Theorem applies (sum/average of many variables)\n",
    "- Natural variation in populations\n",
    "- You need a mathematically tractable model\n",
    "\n",
    "> Why it's everywhere:\n",
    "\n",
    "- Natural phenomena often approximately normal\n",
    "- CLT makes sums/means converge to normal\n",
    "- Mathematical convenience (closed under addition, scaling)\n",
    "- Well-understood statistical properties\n",
    "- Foundation of classical statistics\n",
    "\n",
    "**Parameters & Domain:**\n",
    "- Parameters: \n",
    "\n",
    "    * $\\mu \\in \\mathbb{R}$:  location parameter (mean, center of distribution)\n",
    "    * $\\sigma^2 > 0 \\in \\mathbb{R}$: scale parameter (variance, spread of distribution)\n",
    "    * $\\sigma > 0$: standard deviation\n",
    "\n",
    "- Support (Domain): $X \\in (-\\infty, \\infty)$\n",
    "\n",
    "    * Can take any real value\n",
    "    * No bounds (though extreme values have tiny probability)\n",
    "\n",
    "- Standard Normal: $\\mathcal{N}(0, 1)$\n",
    "    * Mean = 0, Variance = 1\n",
    "    * Base case for all normal distributions\n",
    "    * Used for Z-scores and standardization\n",
    "\n",
    "|Variant| PMF | CDF | $E(X)$ | $Var(X)$| $\\sigma$|\n",
    "|---|:---:|:---:|:----:|:---:|:---:|\n",
    "|$\\mathcal{N}(\\mu, \\sigma^2)$|$$f(x)=\\frac{1}{\\sigma\\sqrt{2\\pi}}‚Äãexp(‚àí\\frac{(x‚àí\\mu)^2}{2\\sigma^2}‚Äã)$$ *Interpretation:*</br> Bell-shaped curve symmetric around $\\mu$</br>Maximum at $x = \\mu$ (peak at the mean) </br> Inflection points at $\\mu \\pm \\sigma$ </br> Shape determined by $\\sigma$ (wider for larger $\\sigma$)</br> Total area under curve = 1| $$\\Phi(\\frac{x - \\mu}{\\sigma}) = \\int_{-\\infty}^x \\frac{1}{\\sigma\\sqrt{2\\pi}}{e^{-\\frac{(t - \\mu)^2}{2\\sigma^2}}}dt$$ *Important!:*</br> No closed-form solution! Must use: numerical integration, statistical tables (Z-tables) or computer functions (`scipy.stats.norm.cdf`)| $$\\mu$$ | $$\\sigma^2$$| $$\\sigma$$|\n",
    "|$\\mathcal{N}(0, 1)$| $$\\phi(z) = \\frac{1}{2\\pi}‚Äãe^{‚àí\\frac{z^2}{2}}‚Äã$$| $$\\Phi(z) = \\int_{-\\infty}^x \\frac{1}{\\sqrt{2\\pi}}{e^{-\\frac{t^2}{2}}}dt$$ *Properties*:</br> $\\Phi(0) = 0.5$ (median at $\\mu$)</br> $\\Phi(-z) = 1 - \\Phi(z)$ (symmetry) </br> Smooth S-shaped curve | $$0$$ | $$1$$ | $$1$$\n",
    "\n",
    "**Key Properties:**\n",
    "\n",
    "1. Mode: $\\mu$ (peak at the mean)\n",
    "2. Skewness: 0 (perfectly symmetric)\n",
    "3. Empirical Rule (68-95-99.7 Rule):  \n",
    "For $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$:\n",
    "\n",
    "- 68% of values within $\\mu ¬± \\sigma$ (1 standard deviation)\n",
    "- 95% of values within $\\mu ¬± 2\\sigma$ (2 standard deviations)\n",
    "- 99.7% of values within $\\mu ¬± 3\\sigma$ (3 standard deviations)\n",
    "\n",
    "More precisely:\n",
    "\n",
    "- $P(\\mu - \\sigma ‚â§ X ‚â§ \\mu + \\sigma) = 0.6827$\n",
    "- $P(\\mu - 2\\sigma ‚â§ X ‚â§ \\mu + 2\\sigma) = 0.9545$\n",
    "- $P(\\mu - 3\\sigma ‚â§ X ‚â§ \\mu + 3\\sigma) = 0.9973$\n",
    "\n",
    "Practical: Almost all values (99.7%) within 3\\sigma of mean!\n",
    "\n",
    "4. Standardization (Z-Score Transformation)\n",
    "$$Z = \\frac{X - \\mu}{\\sigma} \\sim \\mathcal{N}(0, 1)$$\n",
    "Purpose:\n",
    "\n",
    "- Convert any normal to standard normal\n",
    "- Compare values from different normal distributions\n",
    "- Use standard normal tables\n",
    "- Interpretable scale (units of standard deviation)\n",
    "\n",
    "Reverse: $X = \\mu + \\sigma Z$\n",
    "\n",
    "5. Linear Transformation Property\n",
    "If $X ~ N(\\mu, \\sigma^2)$, then:\n",
    "\n",
    "$$aX + b \\sim \\mathcal{N}(a\\mu + b, a^2\\sigma^2)$$\n",
    "\n",
    "4. Sum of Independent Normals\n",
    "If $X_1 \\sim N(\\mu_1, \\sigma_1^2)$ and $X_2 \\sim N(\\mu_2, \\sigma_2^2)$ are independent:\n",
    "\n",
    "$$X_1 + X_2 \\sim N(\\mu_1 + \\mu_2, \\sigma_1^2 + \\sigma_2^2)$$\n",
    "General: Sum of $n$ independent normals is normal!\n",
    "\n",
    "- Means add: $\\mu_{sum} = \\sum\\mu_i$\n",
    "- Variances add: $\\sigma^2_{sum} = \\sum \\sigma_i^2$\n",
    "\n",
    "5. Maximum Entropy\n",
    "Among all distributions with:\n",
    "\n",
    "- Fixed mean $\\mu$\n",
    "- Fixed variance $\\sigma^2$\n",
    "- Support on entire real line\n",
    "\n",
    "The normal distribution has maximum entropy (maximum uncertainty/randomness).\n",
    "6. Reproductive Property\n",
    "Normal family is closed under:\n",
    "\n",
    "- Linear combinations\n",
    "- Convolution (sums)\n",
    "- Affine transformations\n",
    "\n",
    "If you start with normals and do these operations, you get normals!\n",
    "7. Symmetry\n",
    "$$f(\\mu + x) = f(\\mu - x)$$\n",
    "PDF is symmetric about Œº.\n",
    "8. Relationship to Chi-Squared: If $Z \\sim N(0,1)$, then $Z^2 \\sim \\chi^2(1)$. \n",
    "More generally, sum of $n$ squared standard normals $\\sim \\chi^2(n)$\n",
    "\n",
    "**Real-world examples:**\n",
    "1. Physical Measurements:\n",
    "\n",
    "- Heights of people in a population\n",
    "- Weights (approximately, with slight right skew)\n",
    "- Blood pressure readings\n",
    "- IQ scores (designed to be normal)\n",
    "- Measurement errors in instruments\n",
    "\n",
    "2. Natural Phenomena:\n",
    "\n",
    "- Distribution of particle velocities (Maxwell-Boltzmann)\n",
    "- Thermal noise in electronics\n",
    "- Positions in Brownian motion\n",
    "- Quantum mechanical position/momentum (wave function squared)\n",
    "\n",
    "3. Social Sciences:\n",
    "\n",
    "- Test scores (when well-designed)\n",
    "- Reaction times (approximately)\n",
    "- Psychological trait measures\n",
    "- Survey response aggregates\n",
    "\n",
    "4. Finance:\n",
    "\n",
    "- Log returns of stock prices (approximately)\n",
    "- Portfolio returns (by CLT)\n",
    "- Option pricing (Black-Scholes assumes normal)\n",
    "\n",
    "5. Manufacturing:\n",
    "\n",
    "- Product dimensions (when process is in control)\n",
    "- Quality control measurements\n",
    "- Process variations\n",
    "\n",
    "**Typical Events This Describes**\n",
    "\n",
    "\"Sum of many small independent effects\":\n",
    "\n",
    "- Measurement with many error sources\n",
    "- Aggregate of many random influences\n",
    "- Average of many samples (CLT)\n",
    "- Natural variation around a fixed target\n",
    "\n",
    "*Key characteristics:*\n",
    "\n",
    "- Symmetric variation around center\n",
    "- Most values near mean\n",
    "- Extreme values rare but possible\n",
    "- No inherent bounds (unlike uniform)\n",
    "\n",
    "**Relationships to Other Distributions:**\n",
    "1. Parent/Child Relationships:\n",
    "**Central Limit Theorem Connection** (Most Important Relationship)\n",
    "\n",
    "If $X_1, X_2, ..., X_n$ are i.i.d. with mean $\\mu$ and variance $\\sigma^2$:\n",
    "\n",
    "$$\\frac{\\bar{X} - \\mu}{\\sigma/\\sqrt{n}} \\xrightarrow{d} N(0, 1)$$\n",
    "\n",
    "*Consequence*: Sample means converge to normal, regardless of original distribution!\n",
    "This is why normal appears everywhere.\n",
    "\n",
    "2. Special Cases and Limits\n",
    "- From Binomial:\n",
    "\n",
    "    * $Binomial(n, p) \\rightarrow N(np, np(1-p))$ as $n \\rightarrow \\infty$\n",
    "    * Rule of thumb: $np \\geq 5$ and $n(1-p) geq 5$\n",
    "\n",
    "- From Poisson:\n",
    "\n",
    "    * $Poisson(\\lambda) \\rightarrow N(\\lambda, \\lambda)$ as $\\lambda \\rightarrow \\infty$\n",
    "    * Rule of thumb: $\\lambda \\geq 10$\n",
    "\n",
    "- To Lognormal:\n",
    "\n",
    "If $X \\sim N(\\mu, \\sigma^2)$, then $e^X \\sim Lognormal(\\mu, \\sigma^2)$. Used for modeling positive quantities with multiplicative growth\n",
    "\n",
    "3. Related Distributions\n",
    "- Chi-Squared:\n",
    "\n",
    "Sum of $n$ squared independent $N(0,1)$ $\\sim \\chi^2(n)$\n",
    "\n",
    "- Student's $t$:\n",
    "\n",
    "Ratio of $N(0,1)$ to $\\sqrt{\\chi^2(n)/n} \\sim t(n)$. Approaches normal as $n \\rightarrow \\infty$\n",
    "\n",
    "- $F$-distribution:\n",
    "\n",
    "Ratio of two chi-squared variables (related to normals)\n",
    "\n",
    "- Multivariate Normal:\n",
    "\n",
    "Vector generalization: $X \\sim N(\\mathbf{Œº}, \\mathbf{\\Sigma})$ where $\\Sigma$ is covariance matrix\n",
    "\n",
    "- Cauchy:\n",
    "\n",
    "Ratio of two independent $N(0,1) \\sim Cauchy$. Heavy tails, no mean!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac9369a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-primary\">\n",
    "<h4>ü§ñ ML Applications</h4>\n",
    "\n",
    "*Fundamental Assumptions*\n",
    "\n",
    "1. Gaussian Noise Model:\n",
    "\n",
    "- Linear regression: Y = XŒ≤ + Œµ, where Œµ ~ N(0, œÉ¬≤)\n",
    "- Leads to least squares estimation\n",
    "- Maximum likelihood = minimize squared error\n",
    "\n",
    "2. Weight Initialization:\n",
    "\n",
    "- Xavier: W ~ N(0, 1/n_in)\n",
    "- He: W ~ N(0, 2/n_in) for ReLU\n",
    "- Controls variance propagation\n",
    "\n",
    "3. Feature Engineering:\n",
    "\n",
    "- Standardization: z = (x - Œº)/œÉ ‚Üí N(0, 1)\n",
    "- Many algorithms assume/prefer normalized features\n",
    "- Improves gradient descent convergence\n",
    "</br>\n",
    "\n",
    "*Probabilistic Models*\n",
    "\n",
    "4. Gaussian Mixture Models (GMM):\n",
    "\n",
    "- Mixture of K normal distributions\n",
    "- Clustering with soft assignments\n",
    "- Density estimation\n",
    "\n",
    "5. Naive Bayes (Gaussian):\n",
    "\n",
    "- P(feature|class) ~ N(Œº_class, œÉ¬≤_class)\n",
    "- Simple but effective classifier\n",
    "\n",
    "6. Gaussian Processes:\n",
    "\n",
    "- Distribution over functions\n",
    "- Bayesian non-parametric regression\n",
    "- Uncertainty quantification\n",
    "</br>\n",
    "\n",
    "*Deep Learning*\n",
    "\n",
    "7. Variational Autoencoders (VAE):\n",
    "\n",
    "- Latent space ~ N(0, I)\n",
    "- Reparameterization trick: z = Œº + œÉŒµ, Œµ ~ N(0,1)\n",
    "- Learn mean and variance functions\n",
    "\n",
    "8. Batch Normalization:\n",
    "\n",
    "- Normalize activations: (x - Œº_batch)/œÉ_batch\n",
    "- Stabilizes training\n",
    "- Reduces internal covariate shift\n",
    "\n",
    "9. Gradient Noise:\n",
    "\n",
    "- Mini-batch gradients have noise ~ N(true_gradient, variance)\n",
    "- Helps escape sharp minima\n",
    "- Adds regularization effect\n",
    "\n",
    "10. Dropout Approximation:\n",
    "\n",
    "- Dropout can be viewed as approximate Gaussian noise\n",
    "- Connection to Bayesian neural networks\n",
    "</br>\n",
    "\n",
    "*Optimization*\n",
    "\n",
    "11. Gaussian Approximations:\n",
    "\n",
    "- Laplace approximation for posterior\n",
    "- Variational inference with Gaussian family\n",
    "- Natural gradient methods\n",
    "\n",
    "12. Confidence Intervals:\n",
    "\n",
    "- Parameter estimates ¬± z_Œ±/2 √ó SE\n",
    "- Based on asymptotic normality\n",
    "</br>\n",
    "\n",
    "*Generative Models*\n",
    "\n",
    "13. Diffusion Models:\n",
    "\n",
    "- Add Gaussian noise progressively\n",
    "- Learn to denoise\n",
    "- State-of-the-art image generation\n",
    "\n",
    "14. Score Matching:\n",
    "\n",
    "- Learn gradient of log-density\n",
    "- Gaussian perturbations\n",
    "</br>\n",
    "\n",
    "*Anomaly Detection*\n",
    "\n",
    "15. Outlier Detection:\n",
    "\n",
    "- Flag points > 3œÉ from mean\n",
    "- Mahalanobis distance for multivariate\n",
    "- Assumes normal baseline\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0a8302",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<h4>‚ö†Ô∏è Common Pitfalls:</h4>\n",
    "\n",
    "‚ùå Assuming everything is normal\n",
    "\n",
    "- Many real distributions are NOT normal\n",
    "- Check with Q-Q plots, Shapiro-Wilk test\n",
    "- Example: Income (lognormal), waiting times (exponential)\n",
    "\n",
    "‚ùå Ignoring outliers\n",
    "\n",
    "- Normal has light tails\n",
    "- Real data often has heavier tails\n",
    "- Outliers can distort Œº and œÉ estimates\n",
    "\n",
    "‚ùå Forgetting it's unbounded\n",
    "\n",
    "- Normal can theoretically produce any value\n",
    "- Problems when modeling bounded quantities (e.g., probabilities)\n",
    "- Use logistic/beta for [0,1], lognormal for positive\n",
    "\n",
    "‚ùå Confusing $\\sigma$ with $\\sigma^2$\n",
    "\n",
    "- Parameters are $(\\mu, \\sigma^2)$ but we often think in terms of $\\sigma$\n",
    "- `scipy` uses $scale=\\sigma$ not $scale=\\sigma^2$\n",
    "\n",
    "‚ùå Misapplying CLT\n",
    "\n",
    "- CLT requires sufficiently large $n$\n",
    "- Original distribution matters (heavy tails need larger $n$)\n",
    "- Rule of thumb: $n \\geq 30$ (but depends on skewness)\n",
    "\n",
    "‚ùå Treating correlation as independence\n",
    "\n",
    "- Joint normal needs covariance matrix\n",
    "- Uncorrelated ‚â† independent (generally), but = for normal!\n",
    "\n",
    "‚ö†Ô∏è Standardization errors:\n",
    "\n",
    "- Using sample std when population std is known\n",
    "- Dividing by $n$ instead of $\\sqrt{n}$ for standard error\n",
    "- Forgetting to center (subtract mean) before scaling\n",
    "\n",
    "‚ùå Inappropriate hypothesis tests\n",
    "\n",
    "- Using normal-based tests on non-normal data\n",
    "- Small samples need $t$-distribution not normal\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6031a1",
   "metadata": {},
   "source": [
    "We can use SciPy implementation of this distribution, [`scipy.stats.norm`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c387185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 75\n",
    "sigma = 10\n",
    "norm_dist = stats.norm(loc=mu, scale=sigma)  # loc=mean, scale=std\n",
    "\n",
    "# Note: scipy uses (Œº, œÉ) NOT (Œº, œÉ¬≤)\n",
    "# Alternative: stats.norm(75, 10)\n",
    "\n",
    "# PDF\n",
    "x = 80\n",
    "pdf_value = norm_dist.pdf(x)\n",
    "print(f\"\\nPDF at x={x}: f({x}) = {pdf_value:.6f}\")\n",
    "\n",
    "# CDF\n",
    "cdf_value = norm_dist.cdf(x)\n",
    "print(f\"CDF at x={x}: P(X ‚â§ {x}) = {cdf_value:.4f}\")\n",
    "print(f\"Interpretation: {cdf_value*100:.2f}% scored ‚â§ {x}\")\n",
    "\n",
    "# Survival function\n",
    "sf_value = norm_dist.sf(x)  # P(X > x) = 1 - CDF(x)\n",
    "print(f\"P(X > {x}) = {sf_value:.4f}\")\n",
    "\n",
    "# Random sampling\n",
    "samples = norm_dist.rvs(size=10, random_state=42)\n",
    "print(f\"Generated 10 samples: {samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06496c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 68-95-99.7 Rule Verification\n",
    "# Within 1 sigma\n",
    "prob_1sigma = norm_dist.cdf(mu + sigma) - norm_dist.cdf(mu - sigma)\n",
    "print(f\"\\nP(Œº-œÉ ‚â§ X ‚â§ Œº+œÉ) = P({mu-sigma} ‚â§ X ‚â§ {mu+sigma})\")\n",
    "print(f\"  = {prob_1sigma:.4f} ‚âà 0.6827 (68.27%)\")\n",
    "\n",
    "# Within 2 sigma\n",
    "prob_2sigma = norm_dist.cdf(mu + 2*sigma) - norm_dist.cdf(mu - 2*sigma)\n",
    "print(f\"\\nP(Œº-2œÉ ‚â§ X ‚â§ Œº+2œÉ) = P({mu-2*sigma} ‚â§ X ‚â§ {mu+2*sigma})\")\n",
    "print(f\"  = {prob_2sigma:.4f} ‚âà 0.9545 (95.45%)\")\n",
    "\n",
    "# Within 3 sigma\n",
    "prob_3sigma = norm_dist.cdf(mu + 3*sigma) - norm_dist.cdf(mu - 3*sigma)\n",
    "print(f\"\\nP(Œº-3œÉ ‚â§ X ‚â§ Œº+3œÉ) = P({mu-3*sigma} ‚â§ X ‚â§ {mu+3*sigma})\")\n",
    "print(f\"  = {prob_3sigma:.4f} ‚âà 0.9973 (99.73%)\")\n",
    "\n",
    "# Practical rule: 95% within 1.96 sigma (for confidence intervals)\n",
    "prob_196sigma = norm_dist.cdf(mu + 1.96*sigma) - norm_dist.cdf(mu - 1.96*sigma)\n",
    "print(f\"\\nP(Œº-1.96œÉ ‚â§ X ‚â§ Œº+1.96œÉ) = {prob_196sigma:.4f} (exactly 95%)\")\n",
    "print(f\"This is used for 95% confidence intervals!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae33f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "# Original score\n",
    "x_score = 90\n",
    "z_score = (x_score - mu) / sigma\n",
    "print(f\"\\nOriginal score: {x_score}\")\n",
    "print(f\"Z-score: z = (x-Œº)/œÉ = ({x_score}-{mu})/{sigma} = {z_score:.2f}\")\n",
    "print(f\"Interpretation: {x_score} is {z_score:.2f} standard deviations above the mean\")\n",
    "\n",
    "# Using standardized normal\n",
    "std_norm = stats.norm(0, 1)\n",
    "prob_above = std_norm.sf(z_score)\n",
    "print(f\"\\nP(X > {x_score}) = P(Z > {z_score:.2f}) = {prob_above:.4f}\")\n",
    "print(f\"About {prob_above*100:.2f}% scored higher than {x_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2035c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive visualisation\n",
    "def plot_normal(mu=0.0, sigma=1.0):    \n",
    "    \"\"\"\n",
    "    Interactive visualization of Normal distribution\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    mu : float - mean (location parameter)\n",
    "    sigma : float - standard deviation (scale parameter)\n",
    "    \"\"\"\n",
    "    print(\"Visual Characteristics\")\n",
    "    print(\"PDF Shape:\")\n",
    "    print(\"     Symmetric bell curve centered at Œº\")\n",
    "    print(\"     Maximum at Œº (mode = median = mean)\")\n",
    "    print(\"     Inflection points at Œº ¬± œÉ\")\n",
    "    print(\"     Gaussian shape: f(x) = (1/(œÉ‚àö(2œÄ)))e^(-(x-Œº)¬≤/(2œÉ¬≤))\")\n",
    "    print(\"     Tails extend to ¬±‚àû (theoretically)\")\n",
    "    print(\"     68% of data within Œº ¬± œÉ\")\n",
    "    print(\"     95% of data within Œº ¬± 2œÉ\")\n",
    "    print(\"     99.7% of data within Œº ¬± 3œÉ (empirical rule)\")\n",
    "    print(\"CDF Shape:\")\n",
    "    print(\"     S-shaped (sigmoid) curve\")\n",
    "    print(\"     Point of inflection at Œº (where CDF = 0.5)\")\n",
    "    print(\"     Symmetric around Œº\")\n",
    "    print(\"     Steepest slope at Œº\")\n",
    "    print(\"     Asymptotically approaches 0 and 1\")\n",
    "    print(\"Effect of Œº (mean):\")\n",
    "    print(\"     Shifts entire distribution left/right\")\n",
    "    print(\"     Does not change shape\")\n",
    "    print(\"     Centers the bell curve at new location\")\n",
    "    print(\"Effect of œÉ (std dev):\")\n",
    "    print(\"     Large œÉ: Wider, flatter bell, more spread\")\n",
    "    print(\"     Small œÉ: Narrower, taller bell, more concentrated\")\n",
    "    print(\"     Controls dispersion around mean\")\n",
    "    print(\"Key visual features:\")\n",
    "    print(\"     Perfect symmetry (skewness = 0)\")\n",
    "    print(\"     Mean = Median = Mode (all coincide)\")\n",
    "    print(\"     Unimodal (single peak)\")\n",
    "    print(\"     Tails never touch x-axis\")\n",
    "    print(\"     Universal 68-95-99.7 rule applies\")\n",
    "    \n",
    "    if sigma <= 0:\n",
    "        print(\"Error: œÉ must be > 0\")\n",
    "        return\n",
    "    \n",
    "    # Create distribution\n",
    "    norm_dist = stats.norm(loc=mu, scale=sigma)\n",
    "    \n",
    "    mean_val = mu\n",
    "    var_val = sigma ** 2\n",
    "    std_val = sigma\n",
    "    median_val = mu\n",
    "    mode_val = mu\n",
    "    \n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=(16, 5))\n",
    "    gs = fig.add_gridspec(1, 3, hspace=0.35, wspace=0.3)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Panel 1: PDF\n",
    "    # ========================================================================\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    \n",
    "    # Show range: mean ¬± 4 standard deviations\n",
    "    x_range = np.linspace(mu - 4*sigma, mu + 4*sigma, 1000)\n",
    "    pdf_values = norm_dist.pdf(x_range)\n",
    "    \n",
    "    ax1.fill_between(x_range, pdf_values, alpha=0.3, color='skyblue')\n",
    "    ax1.plot(x_range, pdf_values, 'darkblue', linewidth=2.5)\n",
    "    \n",
    "    # Mark mean/median/mode (all same for normal)\n",
    "    ax1.axvline(mean_val, color='red', linestyle='--', linewidth=2, \n",
    "                label=f'Mean=Median=Mode={mean_val:.3f}')\n",
    "    \n",
    "    # Mark Œº ¬± œÉ (inflection points)\n",
    "    ax1.axvline(mu - sigma, color='orange', linestyle=':', linewidth=2, \n",
    "                label=f'Œº-œÉ={mu-sigma:.3f}')\n",
    "    ax1.axvline(mu + sigma, color='orange', linestyle=':', linewidth=2, \n",
    "                label=f'Œº+œÉ={mu+sigma:.3f}')\n",
    "    \n",
    "    # Shade the 68% region (Œº ¬± œÉ)\n",
    "    mask_1sigma = (x_range >= mu - sigma) & (x_range <= mu + sigma)\n",
    "    ax1.fill_between(x_range[mask_1sigma], pdf_values[mask_1sigma], \n",
    "                      alpha=0.2, color='green', label='68% area (Œº¬±œÉ)')\n",
    "    \n",
    "    ax1.set_xlabel('x', fontsize=11)\n",
    "    ax1.set_ylabel('f(x) - Density', fontsize=11)\n",
    "    ax1.set_title(f'PDF: Normal(Œº={mu:.3f}, œÉ={sigma:.3f})', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "    ax1.legend(fontsize=9, loc='upper right')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add formula\n",
    "    formula_text = f'f(x) = (1/({sigma:.2f}‚àö(2œÄ)))e^(-(x-{mu:.2f})¬≤/(2¬∑{sigma:.2f}¬≤))'\n",
    "    ax1.text(0.02, 0.05, formula_text,\n",
    "            transform=ax1.transAxes, verticalalignment='top', \n",
    "            horizontalalignment='left',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),\n",
    "            fontsize=9)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Panel 2: CDF\n",
    "    # ========================================================================\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    \n",
    "    cdf_values = norm_dist.cdf(x_range)\n",
    "    \n",
    "    ax2.plot(x_range, cdf_values, 'b-', linewidth=2.5, label='CDF F(x)')\n",
    "    \n",
    "    # Mark median (where CDF = 0.5)\n",
    "    ax2.axhline(0.5, color='green', linestyle=':', alpha=0.7, linewidth=2)\n",
    "    ax2.axvline(median_val, color='green', linestyle=':', alpha=0.7, linewidth=2)\n",
    "    ax2.plot(median_val, 0.5, 'go', markersize=10, label=f'Median={median_val:.3f}')\n",
    "    \n",
    "    # Mark 68%, 95%, 99.7% points\n",
    "    ax2.axhline(norm_dist.cdf(mu + sigma), color='orange', linestyle='--', \n",
    "                alpha=0.5, label='F(Œº+œÉ)‚âà0.84')\n",
    "    ax2.axhline(norm_dist.cdf(mu - sigma), color='orange', linestyle='--', \n",
    "                alpha=0.5, label='F(Œº-œÉ)‚âà0.16')\n",
    "    \n",
    "    ax2.set_xlabel('x', fontsize=11)\n",
    "    ax2.set_ylabel('F(x) - Cumulative Probability', fontsize=11)\n",
    "    ax2.set_title('CDF: Cumulative Distribution Function', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "    ax2.legend(fontsize=9)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_ylim(-0.05, 1.05)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Panel 3: Empirical Rule Visualization\n",
    "    # ========================================================================\n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    \n",
    "    ax3.fill_between(x_range, pdf_values, alpha=0.2, color='lightgray', \n",
    "                     label='Total area = 1')\n",
    "    ax3.plot(x_range, pdf_values, 'darkblue', linewidth=2.5)\n",
    "    \n",
    "    # 68% region (Œº ¬± œÉ)\n",
    "    mask_1sigma = (x_range >= mu - sigma) & (x_range <= mu + sigma)\n",
    "    ax3.fill_between(x_range[mask_1sigma], pdf_values[mask_1sigma], \n",
    "                      alpha=0.4, color='green', label='68.27% (Œº¬±œÉ)')\n",
    "    \n",
    "    # 95% region (Œº ¬± 2œÉ)\n",
    "    mask_2sigma = (x_range >= mu - 2*sigma) & (x_range <= mu + 2*sigma)\n",
    "    ax3.fill_between(x_range[mask_2sigma], pdf_values[mask_2sigma], \n",
    "                      alpha=0.3, color='yellow', label='95.45% (Œº¬±2œÉ)')\n",
    "    \n",
    "    # 99.7% region (Œº ¬± 3œÉ)\n",
    "    mask_3sigma = (x_range >= mu - 3*sigma) & (x_range <= mu + 3*sigma)\n",
    "    ax3.fill_between(x_range[mask_3sigma], pdf_values[mask_3sigma], \n",
    "                      alpha=0.2, color='orange', label='99.73% (Œº¬±3œÉ)')\n",
    "    \n",
    "    # Mark the boundaries\n",
    "    for i in range(1, 4):\n",
    "        ax3.axvline(mu - i*sigma, color='red', linestyle='--', \n",
    "                    alpha=0.5, linewidth=1)\n",
    "        ax3.axvline(mu + i*sigma, color='red', linestyle='--', \n",
    "                    alpha=0.5, linewidth=1)\n",
    "    \n",
    "    ax3.set_xlabel('x', fontsize=11)\n",
    "    ax3.set_ylabel('f(x) - Density', fontsize=11)\n",
    "    ax3.set_title('Empirical Rule (68-95-99.7)', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "    ax3.legend(fontsize=9, loc='upper right')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add text annotations for percentages\n",
    "    ax3.text(mu, max(pdf_values)*0.5, '68%', \n",
    "             ha='center', va='center', fontsize=12, fontweight='bold', \n",
    "             color='darkgreen')\n",
    "    ax3.text(mu, max(pdf_values)*0.7, '95%', \n",
    "             ha='center', va='center', fontsize=11, fontweight='bold', \n",
    "             color='darkorange')\n",
    "    ax3.text(mu, max(pdf_values)*0.85, '99.7%', \n",
    "             ha='center', va='center', fontsize=10, fontweight='bold', \n",
    "             color='red')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.close()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Interactive widget\n",
    "interact(plot_normal,\n",
    "         mu=FloatSlider(min=-10, max=10, step=0.5, value=0, \n",
    "                        description='Mean (Œº)'),\n",
    "         sigma=FloatSlider(min=0.1, max=5, step=0.1, value=1, \n",
    "                          description='Std Dev (œÉ)'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce6de89",
   "metadata": {},
   "source": [
    "## Return to Opening Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd26d28",
   "metadata": {},
   "source": [
    "QUESTION 1: P(W = 0.5 exactly) = ?\n",
    "ANSWER: 0\n",
    "\n",
    "WHY? Because continuous distributions have:\n",
    "- Uncountably infinite values\n",
    "- Probability is AREA, not height\n",
    "- Single point has zero width ‚Üí zero area\n",
    "\n",
    "QUESTION 2: But the weight exists as 0.5. How?\n",
    "\n",
    "ANSWER: The event happened, even though it had probability 0!\n",
    "- Probability 0 ‚â† Impossible\n",
    "- Individual outcomes have probability 0\n",
    "- But SOME outcome must occur\n",
    "\n",
    "QUESTION 3: How do we work with this?\n",
    "\n",
    "ANSWER: Use intervals!\n",
    "- Don't ask: P(W = 0.5)\n",
    "- Ask: $P(0.49 \\leq W \\leq 0.51) = \\int_{0.49}^{0.51} f(w)dw$\n",
    "\n",
    "QUESTION 4: Weight initialization?\n",
    "\n",
    "ANSWER: W ~ N(0, 1/n_in) means:\n",
    "- NOT that each weight has specific probability\n",
    "- But that weights are distributed according to PDF\n",
    "- We care about VARIANCE staying constant: œÉ¬≤ = 1/n_in\n",
    "- This prevents explosion/vanishing\n",
    "\n",
    "KEY LESSON:\n",
    "\n",
    "Continuous distributions describe:\n",
    "- Not individual outcomes (all have P=0)\n",
    "- But the DENSITY of outcomes over intervals\n",
    "- And the SHAPE of the distribution (where values concentrate)\n",
    "\n",
    "PRACTICAL TAKEAWAY:\n",
    "When you initialize weights W ~ N(0, œÉ¬≤):\n",
    "\n",
    "- You're not assigning probabilities to exact values\n",
    "- You're defining how weights SPREAD around 0\n",
    "- The œÉ determines concentration vs dispersion\n",
    "- Choose œÉ = 1/‚àön_in to keep activations stable!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25870a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo\n",
    "demo_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d933d38d",
   "metadata": {},
   "source": [
    "## Common Mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad004b4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<h4>‚ö†Ô∏è Common Pitfalls to Avoid:</h4>\n",
    "\n",
    "- Thinking $f(x)$ is a probability                                   \n",
    "- Expecting $P(X=x) > 0$ for continuous                            \n",
    "- Using PMF formulas for continuous R.V.                         \n",
    "- Forgetting that $f(x)$ can exceed 1                              \n",
    "- Confusing $\\sigma$ (std dev) with $\\sigma^2$ (variance)                       \n",
    "- Using $\\mathcal{N}(0,1)$ for all weight initialization \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970b667d",
   "metadata": {},
   "source": [
    "## Applications in Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81901353",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div class=\"alert alert-secondary\">\n",
    "<h4>ü§ñ ML Applications Summary</h4>\n",
    "\n",
    "1. Weight Initialization\n",
    "- Xavier:  $W \\sim \\mathcal{N}(0, 1/n_in)$      [tanh, sigmoid]                  \n",
    "- He:      $W \\sim \\mathcal{N}(0, 2/n_in)$      [ReLU] \n",
    "\n",
    "2. Feature Scaling\n",
    "$$Z = \\frac{X - \\mu} {\\sigma} \\sim \\mathcal{N}(0, 1)$$\n",
    "\n",
    "3. Gaussian Noise\n",
    "- Add $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$ for regularization \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-secondary\">\n",
    "<h4>üîß Python Essentials</h4>\n",
    "\n",
    "```\n",
    "from scipy import stats`\n",
    "\n",
    "# PDF (density)\n",
    "stats.norm.pdf(x, loc=mu, scale=sigma)\n",
    "\n",
    "# CDF (probability)\n",
    "stats.norm.cdf(x, loc=mu, scale=sigma)\n",
    "                                                                   \n",
    "# Inverse CDF (quantiles)\n",
    "stats.norm.ppf(0.95, loc=mu, scale=sigma)  # 95th percentile\n",
    "                                                                  \n",
    "# Random sampling\n",
    "stats.norm.rvs(loc=mu, scale=sigma, size=n)\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2146b7",
   "metadata": {},
   "source": [
    "## Key Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11468638",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-summary\">\n",
    "<h4>üéì Key Takeaways</h4>\n",
    "\n",
    "1. CONTINUOUS vs DISCRETE\n",
    "   - Discrete: $P(X=x)$ can be > 0 (PMF)\n",
    "   - Continuous: $P(X=x) = 0$ always (PDF)\n",
    "   - Continuous: Use $P(a ‚â§ X ‚â§ b) = \\int_a^b f(x)dx$\n",
    "\n",
    "2. PROBABILITY DENSITY FUNCTION (PDF)\n",
    "   - $f(x) ‚â• 0$ everywhere\n",
    "   - $\\int_{-\\infty}^{\\infty} f(x)dx = 1$\n",
    "   - $f(x)$ is DENSITY, not probability\n",
    "   - $f(x)$ CAN exceed 1! (unlike PMF)\n",
    "\n",
    "3. CUMULATIVE DISTRIBUTION FUNCTION (CDF)\n",
    "   - $F(x) = P(X ‚â§ x) = \\int_{-\\infty}^x f(t)dt$\n",
    "   - $F(x)$ is CONTINUOUS (no jumps)\n",
    "   - $f(x) = dF/dx$ (derivative relationship)\n",
    "   - $P(a < X ‚â§ b) = F(b) - F(a)$\n",
    "\n",
    "4. KEY DISTRIBUTIONS\n",
    "   \n",
    "   UNIFORM(a,b):\n",
    "   - $f(x) = 1/(b-a)$ on $[a,b]$\n",
    "   - All values equally likely\n",
    "   - $E[X] = (a+b)/2$, $Var = (b-a)^2/12$\n",
    "   \n",
    "   EXPONENTIAL($\\lambda$):\n",
    "   - $f(x) = \\lambda e^(-\\lambda x)$ for $x\\geq 0$\n",
    "   - Waiting times\n",
    "   - Memoryless property\n",
    "   - $E[X] = 1/\\lambda$, $Var = 1/\\lambda^2$\n",
    "   \n",
    "   NORMAL($\\mu$, $\\sigma^2$): ‚≠ê MOST IMPORTANT\n",
    "   - $f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}exp(-(x-\\mu)^2/(2\\sigma^2))$\n",
    "   - Bell-shaped, symmetric\n",
    "   - 68-95-99.7 rule\n",
    "   - $E[X] = \\mu$, $Var = \\sigma^2$\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810a1564",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
