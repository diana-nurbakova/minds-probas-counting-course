{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b4d718e",
   "metadata": {},
   "source": [
    "# Sampling, Monte Carlo Methods and Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2841ff",
   "metadata": {},
   "source": [
    "Author & Instructor: Diana NURBAKOVA, PhD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c692fd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"../styles/styles.css\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336f50ca",
   "metadata": {},
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9326683a",
   "metadata": {},
   "source": [
    "By the end of this lesson, you will be able to:\n",
    "1. Define what sampling from a distribution means and distinguish between population and sample\n",
    "2. Explain the difference between population parameters ($\\mu$, $\\sigma$) and sample statistics ($\\bar{x}$, $s$)\n",
    "3. Understand and apply Monte Carlo methods: using randomness to solve deterministic problems\n",
    "4. Generate bootstrap samples by resampling with replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6288b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better-looking plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "#sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba668c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, IntSlider, Dropdown\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec14322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = ['DejaVu Sans', 'Segoe UI Emoji']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf98c4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Circle, Rectangle\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0e295a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee78def7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the \"resources\" directory to the path\n",
    "project_root = Path().resolve().parent\n",
    "resources_path = project_root / 'resources'\n",
    "sys.path.insert(0, str(resources_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0462e8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from montecarlo import(estimate_pi_visual, interactive_population_sample_demo, demonstrate_sampling_concept, sampling_process_diagram, motivating_examples_visualization, \n",
    "                       interactive_sampling_demo, ml_sampling_example, bootstrap_demo, visualize_uncertainty_concept, bootstrap_uncertainty_explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1366296a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h4>üéØ Today's Challenge: Can We Trust This Model?</h4>\n",
    "<p><strong>Scenario:</strong> You've trained a deep learning model that predicts customer churn with 87% accuracy on your test set. Your CEO wants to invest $50M based on this model's predictions.</p>\n",
    "\n",
    "<p><strong>The Questions:</strong></p>\n",
    "<ul>\n",
    "<li>How confident are you that the <em>real</em> accuracy is above 85%?</li>\n",
    "<li>How much would this estimate vary with different test data? What if you only have 500 samples? What if you have 500,000?</li>\n",
    "<li>Can you quantify the uncertainty in this 87% figure?</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>Make your guess:</strong> Green light the $50M investment?</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225a72a1",
   "metadata": {},
   "source": [
    "## Population vs Sample: We Can't Measure Everything"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac49dbc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-example\">\n",
    "<h4>The Real-World Dilemma</h4>\n",
    "\n",
    "<p><strong>Imagine you're hired by Netflix to answer:</strong></p>\n",
    "<p style=\"font-size: 1.1em; font-style: italic;\">\"What percentage of our users will enjoy our new recommendation algorithm?\"</p>\n",
    "\n",
    "<p><strong>The Impossible Approach:</strong></p>\n",
    "<ul>\n",
    "<li>Netflix has 250 million subscribers worldwide</li>\n",
    "<li>To be 100% certain, test with ALL 250 million users</li>\n",
    "<li>Cost: $50 million+ in infrastructure</li>\n",
    "<li>Time: 6 months</li>\n",
    "<li>Problem: By then, competitors have already launched their features!</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>The Practical Approach:</strong></p>\n",
    "<ul>\n",
    "<li>Test with 10,000 randomly selected users</li>\n",
    "<li>Cost: $100,000</li>\n",
    "<li>Time: 2 weeks</li>\n",
    "<li>Magic: Get answers that are 95% as reliable as testing everyone!</li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"margin-top: 15px; padding: 10px; background-color: rgba(255, 193, 7, 0.1); border-left: 4px solid #ffc107;\">\n",
    "<strong>The Question:</strong> How can testing 10,000 users tell us about 250 million? This is the power of sampling!\n",
    "</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c094cda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo\n",
    "motivating_examples_visualization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa12c11",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4>Definitions: Population and Sample</h4>\n",
    "\n",
    "**Population** is the complete set of ALL individuals/items/observations we want to study. \n",
    "\n",
    "*Symbol:* Often denoted as $N$ (population size)\n",
    "\n",
    "*Key property:* Contains the TRUE parameters we want to know ($\\mu$, $\\sigma$, etc.) \n",
    "\n",
    "*Problem:* Usually impossible or impractical to measure entirely\n",
    "\n",
    "</br>\n",
    "\n",
    "**Sample** is a subset of the population that we actually observe/measure. \n",
    "\n",
    "*Symbol:* Often denoted as $n$ (sample size), where $n << N$\n",
    "\n",
    "*Key property:* Provides ESTIMATES of population parameters ($\\bar{x}$, $s$, etc.)\n",
    "\n",
    "*Goal:* Choose sample so it \"represents\" the population\n",
    "\n",
    "</br>\n",
    "\n",
    "**Random Sampling** is a process of selecting a subset of the population where each member of population has equal probability of being selected.\n",
    "\n",
    "*Why random?* Eliminates bias, allows mathematical theory to work\n",
    "\n",
    "*Result:* Sample statistics approximate population parameters\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef44759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation sampling process\n",
    "sampling_process_diagram()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bfd609",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4>Definition: Sample Mean</h4>\n",
    "\n",
    "Given a sample of $n$ observations: $X_1, X_2, ..., X_n$. The **sample mean** is defined as: \n",
    "$$\\bar{x} = \\frac{1}{n}\\sum_i^n X_i$$\n",
    "\n",
    "**Key properties:**\n",
    "\n",
    "1. Unbiased estimator $E[\\bar{x}] = \\mu$ where $\\mu$ is a population mean (usually unknown). \n",
    "\n",
    "*The expected value of the sample mean equals the population mean. \"On average, xÃÑ gives us the right answer\"*\n",
    "\n",
    "2. Consistency $\\bar{x} \\rightarrow \\mu$ as $n \\rightarrow \\infty$\n",
    "\n",
    "*As sample size increases, sample mean converges to population mean. This is the Law of Large Numbers*\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5302005f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4>Definition: Sample Variance and Sample Standard Deviation</h4>\n",
    "\n",
    "Given a sample of $n$ observations: $X_1, X_2, ..., X_n$ with sample mean $\\bar{x}$. The **sample variance** is defined as: \n",
    "$$s^2 = \\frac{1}{n-1} \\sum_i^n (X_i - \\bar{x})^2 = \\frac{1}{n-1} \\bigg(\\sum_i^n X_i^2 - \\frac{(\\sum_i^nX_i)^2}{n}\\bigg)$$\n",
    "\n",
    "The **sample standard deviation** is:\n",
    "$$s = \\sqrt{s^2}$$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8627d2b0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-example\">\n",
    "<h4>Example: Sample Mean, Sample Variance, and Sample Standard Deviation</h4>\n",
    "\n",
    "We observe the following data: 12, 15, 18, 21, 19, 22, 16, 14, 17, 20.\n",
    "\n",
    "</div>\n",
    "\n",
    "The sample size is $n=10$.\n",
    "\n",
    "1. Sample mean\n",
    "\n",
    "$$\\bar{x} = 1/n \\sum_i^n X_i = 1/10 \\times (12 + 15 + 18 + 21 + 21 + 19 + 22 + 16 + 14 + 17 + 20) = 174 / 10 = 17.4$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ef8402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with python\n",
    "data = np.array([12, 15, 18, 21, 19, 22, 16, 14, 17, 20])\n",
    "n = len(data)\n",
    "print(data.sum())\n",
    "sample_mean = np.mean(data)\n",
    "    \n",
    "print(f\"\\nSample data: {data}\")\n",
    "print(f\"Sample size: n = {n}\")\n",
    "print(f\"Sample mean: xÃÑ = {sample_mean}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f028d1c",
   "metadata": {},
   "source": [
    "2. Sample Variance: Method 1\n",
    "\n",
    "$$s^2 = \\frac{1}{n-1} \\sum_i^n (X_i - \\bar{x})^2$$\n",
    "\n",
    "| $i$ | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | Sum |\n",
    "| :--: |:--: |:--: |:--: |:--: |:--: |:--: |:--: |:--: |:--: |:--: |:--: |\n",
    "| $X_i$ | $12$ | $15$ | $18$ | $21$ | $19$ | $22$ | $16$ | $14$ | $17$ | $20$ | $174$ |\n",
    "| $X_i - \\bar{x}$ | $12 - 17.4 = -5.4$ | $15 - 17.4 = -2.4$ | $18 - 17.4 = 0.6$ | $21 - 17.4 = 3.6$ | $19 - 17.4 = 1.6$ | $22 - 17.4 = 4.6$ | $16 - 17.4 = -1.4$ | $14 - 17.4 = -3.4$ | $17 - 17.4 = -0.4$ | $20 - 17.4 = 2.6$ | $0$ |\n",
    "| $(X_i - \\bar{x})^2$ | $(-5.4)^2 = 29.16$ | $(-2.4)^2 = 5.76$ | $0.6^2 = 0.36$ | $3.6^2 = 12.96$ | $1.6^2 = 2.56$ | $4.6^2 = 21.16$ | $(-1.4)^2 = 1.96$ | $(-3.4)^2 = 11.56$ | $(-0.4)^2 = 0.16$ | $2.6^2 = 6.76$ | $92.40$ |\n",
    "\n",
    "Hence,\n",
    "\n",
    "$$s^2 = \\frac{1}{n-1} \\sum_i^n (X_i - \\bar{x})^2 = 1 / 9 \\times 92.40 = 10.267$$\n",
    "\n",
    "3. Standard Deviation\n",
    "\n",
    "$$s = \\sqrt{s^2} = \\sqrt{10.267} = 3.204$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22632001",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sample Variance')\n",
    "print(\"METHOD 1: DEFINITION FORMULA\")\n",
    "\n",
    "print(\"\\nStep 1: Compute deviations from mean (X·µ¢ - xÃÑ)\")\n",
    "print(f\"{'i':<5} {'X·µ¢':<8} {'xÃÑ':<8} {'(X·µ¢ - xÃÑ)':<15} {'(X·µ¢ - xÃÑ)¬≤':<15}\")\n",
    "    \n",
    "deviations = []\n",
    "squared_deviations = []\n",
    "    \n",
    "for i, x in enumerate(data, 1):\n",
    "    dev = x - sample_mean\n",
    "    sq_dev = dev ** 2\n",
    "    deviations.append(dev)\n",
    "    squared_deviations.append(sq_dev)\n",
    "        \n",
    "    print(f\"{i:<5} {x:<8} {sample_mean:<8} {dev:<15.2f} {sq_dev:<15.2f}\")\n",
    "    \n",
    "print(f\"{'Sum:':<22} {sum(deviations):<15.2f} {sum(squared_deviations):<15.2f}\")\n",
    "    \n",
    "print(\"\\n‚úì Note: Sum of deviations = 0 (always!)\")\n",
    "print(\"  This is because deviations cancel out by definition of mean\")\n",
    "    \n",
    "print(\"\\nStep 2: Sum the squared deviations\")\n",
    "sum_sq_dev = sum(squared_deviations)\n",
    "print(f\"  Œ£(X·µ¢ - xÃÑ)¬≤ = {sum_sq_dev}\")\n",
    "    \n",
    "print(\"\\nStep 3: Divide by (n-1)\")\n",
    "print(f\"  s¬≤ = Œ£(X·µ¢ - xÃÑ)¬≤ / (n-1)\")\n",
    "print(f\"     = {sum_sq_dev} / {n-1}\")\n",
    "    \n",
    "sample_variance = sum_sq_dev / (n - 1)\n",
    "print(f\"     = {sample_variance:.4f}\")\n",
    "    \n",
    "print(\"\\nStep 4: Take square root for standard deviation\")\n",
    "sample_std = np.sqrt(sample_variance)\n",
    "print(f\"  s = ‚àös¬≤\")\n",
    "print(f\"    = ‚àö{sample_variance:.4f}\")\n",
    "print(f\"    = {sample_std:.4f}\")\n",
    "\n",
    "print(f\"with numpy: {data.var(ddof=1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5546d196",
   "metadata": {},
   "source": [
    "3. Sample Variance: Method 2\n",
    "\n",
    "$$s^2 = \\frac{1}{n-1} \\bigg(\\sum_i^n X_i^2 - \\frac{(\\sum_i^nX_i)^2}{n}\\bigg)$$\n",
    "\n",
    "| $i$ | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | Sum |\n",
    "| :--: |:--: |:--: |:--: |:--: |:--: |:--: |:--: |:--: |:--: |:--: |:--: |\n",
    "| $X_i$ | $12$ | $15$ | $18$ | $21$ | $19$ | $22$ | $16$ | $14$ | $17$ | $20$ | $174$ |\n",
    "| $X_i^2$ | $12^2 = 144$ | $15^2 = 225$ | $18^2 = 324$ | $21^2 = 441$ | $19^2 = 361$ | $22^2 = 484$ | $16^2 = 256$ | $14^2 = 196$ | $17^2 = 289$ | $20^2 = 400$ | $3120$ |\n",
    "\n",
    "Hence:\n",
    "$$s^2 = \\frac{1}{n-1} \\bigg(\\sum_i^n X_i^2 - \\frac{(\\sum_i^nX_i)^2}{n}\\bigg) = \\frac{1}{10-1} \\bigg(3120 - \\frac{174^2}{10}\\bigg) = \\frac{1}{9} \\bigg(3120 - \\frac{30276}{10}\\bigg) = \\frac{1}{9} \\bigg(3120 - 3027.6\\bigg) = 92.4/9 = 10.2667$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec62443",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = data.shape[0]\n",
    "print(\"\\nMETHOD 2: COMPUTATIONAL FORMULA\")\n",
    "print(\"\\nStep 1: Compute Œ£ X·µ¢ and Œ£ X·µ¢¬≤\")\n",
    "x_squared = data ** 2\n",
    "print(f\"X·µ¢¬≤: {x_squared}\")\n",
    "sum_x = np.sum(data)\n",
    "sum_x_squared = np.sum(x_squared)\n",
    "    \n",
    "print(f\"  Œ£ X·µ¢ = {sum_x}\")\n",
    "print(f\"  Œ£ X·µ¢¬≤ = {sum_x_squared}\")\n",
    "    \n",
    "print(\"\\nStep 2: Apply formula\")\n",
    "print(f\"  s¬≤ = [Œ£ X·µ¢¬≤ - (Œ£ X·µ¢)¬≤/n] / (n-1)\")\n",
    "print(f\"     = [{sum_x_squared} - ({sum_x})¬≤/{n}] / {n-1}\")\n",
    "print(f\"     = [{sum_x_squared} - {sum_x**2/n:.2f}] / {n-1}\")\n",
    "print(f\"     = {sum_x_squared - sum_x**2/n:.2f} / {n-1}\")\n",
    "    \n",
    "variance_alt = (sum_x_squared - sum_x**2/n) / (n-1)\n",
    "print(f\"     = {variance_alt:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643f5b56",
   "metadata": {},
   "source": [
    "Let's also calculate biased sample variance: \n",
    "$$s^2 = \\frac{1}{\\mathbf{n}} \\sum_i^n (X_i - \\bar{x})^2 = \\frac{1}{10} 92.4 = 9.24$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47247da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biased version (using n)\n",
    "biased_var = sum_sq_dev / n\n",
    "    \n",
    "print(f\"\\nUsing n (BIASED):\")\n",
    "print(f\"  Biased variance = Œ£(X·µ¢ - xÃÑ)¬≤ / n\")\n",
    "print(f\"                  = {sum_sq_dev} / {n}\")\n",
    "print(f\"                  = {biased_var:.4f}\")\n",
    "\n",
    "print(f\"with numpy: {data.var(ddof=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02cd093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "# Plot 1: Visualize deviations\n",
    "ax1 = axes[0, 0]\n",
    "x_pos = range(1, n+1)\n",
    "ax1.bar(x_pos, data, alpha=0.6, edgecolor='black', color='skyblue')\n",
    "ax1.axhline(sample_mean, color='red', linewidth=3, linestyle='--',\n",
    "               label=f'Mean xÃÑ = {sample_mean}')\n",
    "    \n",
    "# Show deviations as arrows\n",
    "for i, (pos, val) in enumerate(zip(x_pos, data)):\n",
    "    if val > sample_mean:\n",
    "        ax1.annotate('', xy=(pos, sample_mean), xytext=(pos, val),\n",
    "                        arrowprops=dict(arrowstyle='<->', color='green', lw=2))\n",
    "        ax1.text(pos + 0.2, (val + sample_mean)/2, f'{val-sample_mean:.1f}',\n",
    "                    fontsize=8, color='green')\n",
    "    else:\n",
    "        ax1.annotate('', xy=(pos, val), xytext=(pos, sample_mean),\n",
    "                        arrowprops=dict(arrowstyle='<->', color='orange', lw=2))\n",
    "        ax1.text(pos + 0.2, (val + sample_mean)/2, f'{val-sample_mean:.1f}',\n",
    "                    fontsize=8, color='orange')\n",
    "    \n",
    "ax1.set_xlabel('Observation Index', fontsize=12)\n",
    "ax1.set_ylabel('Value', fontsize=12)\n",
    "ax1.set_title('Deviations from Mean', fontsize=13, fontweight='bold')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "ax1.set_xticks(x_pos)\n",
    "    \n",
    "# Plot 2: Distribution with std dev bands\n",
    "ax2 = axes[0, 1]\n",
    "ax2.hist(data, bins=7, alpha=0.7, edgecolor='black', color='skyblue', density=False)\n",
    "ax2.axvline(sample_mean, color='red', linewidth=3, linestyle='-',\n",
    "               label=f'Mean = {sample_mean:.1f}')\n",
    "ax2.axvline(sample_mean - sample_std, color='orange', linewidth=2, linestyle='--',\n",
    "               label=f'Mean ¬± 1 SD')\n",
    "ax2.axvline(sample_mean + sample_std, color='orange', linewidth=2, linestyle='--')\n",
    "ax2.axvspan(sample_mean - sample_std, sample_mean + sample_std, \n",
    "               alpha=0.2, color='orange')\n",
    "    \n",
    "ax2.set_xlabel('Value', fontsize=12)\n",
    "ax2.set_ylabel('Frequency', fontsize=12)\n",
    "ax2.set_title(f'Distribution with Standard Deviation\\ns = {sample_std:.2f}', \n",
    "                 fontsize=13, fontweight='bold')\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "# Plot 3: Effect of n vs (n-1)\n",
    "ax3 = axes[1, 0]\n",
    "    \n",
    "sample_sizes = range(2, 51)\n",
    "bias_factors = [n/(n-1) for n in sample_sizes]\n",
    "    \n",
    "ax3.plot(sample_sizes, bias_factors, linewidth=3, color='purple')\n",
    "ax3.axhline(1, color='red', linewidth=2, linestyle='--', alpha=0.7,\n",
    "               label='No correction (bias)')\n",
    "ax3.axhline(1.05, color='orange', linewidth=1, linestyle=':', alpha=0.7)\n",
    "ax3.axhline(1.10, color='orange', linewidth=1, linestyle=':', alpha=0.7)\n",
    "    \n",
    "ax3.fill_between(sample_sizes, 1, bias_factors, alpha=0.3, color='purple')\n",
    "    \n",
    "ax3.set_xlabel('Sample Size (n)', fontsize=12)\n",
    "ax3.set_ylabel('Correction Factor: n/(n-1)', fontsize=12)\n",
    "ax3.set_title('Impact of Bessel\\'s Correction', fontsize=13, fontweight='bold')\n",
    "ax3.legend(fontsize=11)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.set_ylim(0.98, 1.6)\n",
    "    \n",
    "# Annotate key points\n",
    "for n in [5, 10, 20, 50]:\n",
    "    if n <= max(sample_sizes):\n",
    "        idx = n - 2\n",
    "        factor = bias_factors[idx]\n",
    "        ax3.plot(n, factor, 'ro', markersize=8)\n",
    "        ax3.text(n, factor + 0.03, f'n={n}\\n{factor:.3f}√ó',\n",
    "                    ha='center', fontsize=8, fontweight='bold')\n",
    "    \n",
    "# Plot 4: Explanation box\n",
    "ax4 = axes[1, 1]\n",
    "ax4.axis('off')\n",
    "    \n",
    "explanation = f\"\"\"\n",
    "    UNDERSTANDING SAMPLE VARIANCE\n",
    "    {'='*50}\n",
    "    \n",
    "    Our Sample:\n",
    "    {'‚îÄ'*50}\n",
    "    Data: {data}\n",
    "    n = {n}\n",
    "    xÃÑ = {sample_mean}\n",
    "    s¬≤ = {sample_variance:.4f}\n",
    "    s = {sample_std:.4f}\n",
    "    \n",
    "    What does s¬≤ = {sample_variance:.2f} mean?\n",
    "    {'‚îÄ'*50}\n",
    "    ‚Ä¢ Average squared deviation from mean\n",
    "    ‚Ä¢ Measures spread/dispersion\n",
    "    ‚Ä¢ Units: (original units)¬≤\n",
    "    ‚Ä¢ s = {sample_std:.2f} is in original units\n",
    "    \n",
    "    Why (n-1) instead of n?\n",
    "    {'‚îÄ'*50}\n",
    "    ‚Ä¢ We estimated xÃÑ from the data\n",
    "    ‚Ä¢ This uses up 1 degree of freedom\n",
    "    ‚Ä¢ Makes s¬≤ an UNBIASED estimator of œÉ¬≤\n",
    "    ‚Ä¢ Critical for small samples!\n",
    "    \n",
    "    Impact for our data:\n",
    "    {'‚îÄ'*50}\n",
    "    ‚Ä¢ With n:   {biased_var:.4f} (underestimates!)\n",
    "    ‚Ä¢ With n-1: {sample_variance:.4f} (unbiased)\n",
    "    ‚Ä¢ Difference: {(sample_variance/biased_var - 1)*100:.1f}% larger\n",
    "    \n",
    "    In Monte Carlo Integration:\n",
    "    {'‚îÄ'*50}\n",
    "    ‚Ä¢ Standard Error = (b-a) √ó s/‚àön\n",
    "    ‚Ä¢ We MUST use s with (n-1)!\n",
    "    ‚Ä¢ Otherwise SE is underestimated\n",
    "    ‚Ä¢ Confidence intervals would be too narrow\n",
    "    \n",
    "    Rule of Thumb:\n",
    "    {'‚îÄ'*50}\n",
    "    ‚Ä¢ Small samples (n < 30): Use n-1\n",
    "    ‚Ä¢ Large samples (n > 100): Barely matters\n",
    "    ‚Ä¢ ALWAYS use n-1 to be safe!\n",
    "    \"\"\"\n",
    "    \n",
    "ax4.text(0.05, 0.95, explanation, transform=ax4.transAxes,\n",
    "            fontsize=8.5, verticalalignment='top', family='monospace',\n",
    "            bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03438bc6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4>Definition: Standard Error (SE)</h4>\n",
    "\n",
    "The **standard error** of the mean is the standard deviation of the sampling distribution of the sample mean $\\bar{x}$.\n",
    "    \n",
    "POPULATION STANDARD ERROR (if $\\sigma$ is known):\n",
    "    \n",
    "$$SE(\\bar{x}) = \\frac{\\sigma}{\\sqrt{n}}$$\n",
    "    \n",
    "ESTIMATED STANDARD ERROR (using sample):\n",
    "    \n",
    "$$SE(\\bar{x}) = \\frac{s}{\\sqrt{n}}$$\n",
    "    \n",
    "where:\n",
    "- $\\sigma$ = population standard deviation (usually unknown)\n",
    "- $s$ = sample standard deviation\n",
    "- $n$ = sample size\n",
    "    \n",
    "\n",
    "    \n",
    "**Critical distinction:**\n",
    "\n",
    "    \n",
    "1. Standard Deviation ($s$):\n",
    "- Measures variability of INDIVIDUAL observations\n",
    "- Answers: \"How spread out is my data?\"\n",
    "- Does NOT decrease with n\n",
    "- Units: same as data\n",
    "    \n",
    "2. Standard Error ($SE$):\n",
    "- Measures variability of the SAMPLE MEAN\n",
    "- Answers: \"How precisely do I know the mean?\"\n",
    "- Decreases as $1/\\sqrt{n}$ (more data = more precise)\n",
    "- Units: same as data\n",
    "    \n",
    "\n",
    "    \n",
    "**Key properties**:\n",
    "  \n",
    "1. Decreases with sample size: $SE \\propto 1/\\sqrt{n}$\n",
    "       \n",
    "    - Double $n$ ‚Üí SE decreases by factor of $\\sqrt{2} \\approx 1.41$\n",
    "    - 4√ó more data ‚Üí SE halves\n",
    "    - 100√ó more data ‚Üí SE decreases by 10√ó\n",
    "    \n",
    "2. Measures precision:\n",
    "    - Small SE ‚Üí precise estimate of mean\n",
    "    - Large SE ‚Üí imprecise estimate\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb64b6f",
   "metadata": {},
   "source": [
    "Let's calculate SE for our example with the following observed data: 12, 15, 18, 21, 19, 22, 16, 14, 17, 20.\n",
    "\n",
    "Recall: $s = 3.2042$ and $n = 10$.\n",
    "\n",
    "Hence: $$SE(\\bar{x}) = \\frac{s}{\\sqrt{n}} = \\frac{3.2041}{\\sqrt{10}} = 1.0132$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161aa189",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([12, 15, 18, 21, 19, 22, 16, 14, 17, 20])\n",
    "n = len(data)\n",
    "sample_mean = np.mean(data)\n",
    "sample_std = np.std(data, ddof=1)\n",
    "se = sample_std / np.sqrt(n)\n",
    "    \n",
    "print(f\"\\nSample data: {data}\")\n",
    "print(f\"Sample size: n = {n}\")\n",
    "print(f\"Sample mean: xÃÑ = {sample_mean}\")\n",
    "print(f\"Sample std dev: s = {sample_std:.4f}\")\n",
    "print(f\"SE = s/‚àön\")\n",
    "print(f\"     = {sample_std:.4f}/‚àö{n}\")\n",
    "print(f\"     = {sample_std:.4f}/{np.sqrt(n):.4f}\")\n",
    "print(f\"     = {se:.4f}\")\n",
    "    \n",
    "print(\"\\nINTERPRETATION:\")\n",
    "print(f\"  The sample mean xÃÑ = {sample_mean:.2f} has standard error {se:.4f}\")\n",
    "print(f\"  \")\n",
    "print(f\"  This means:\")\n",
    "print(f\"  ‚Ä¢ If we repeated this experiment many times,\")\n",
    "print(f\"  ‚Ä¢ Each time taking a sample of size {n},\")\n",
    "print(f\"  ‚Ä¢ The sample means would vary with SD ‚âà {se:.4f}\")\n",
    "print(f\"  ‚Ä¢ About 68% would fall within {sample_mean:.2f} ¬± {se:.4f}\")\n",
    "print(f\"  ‚Ä¢ About 95% would fall within {sample_mean:.2f} ¬± {1.96*se:.4f}\")\n",
    "print()\n",
    "\n",
    "# variation with sample size\n",
    "print(f\"{'Sample Size (n)':<20} {'SE = s/‚àön':<15} {'95% CI Width':<20}\")\n",
    "print(\"-\" * 60)\n",
    "for n_demo in [5, 10, 20, 50, 100, 500, 1000]:\n",
    "    se_demo = sample_std / np.sqrt(n_demo)\n",
    "    ci_width = 2 * 1.96 * se_demo\n",
    "    print(f\"{n_demo:<20} {se_demo:<15.4f} ¬±{ci_width:<19.4f}\")\n",
    "    \n",
    "print(\"\\nOBSERVATIONS HOW SE CHANGES WITH SAMPLE SIZE:\")\n",
    "print(\"  ‚úì SE decreases as n increases\")\n",
    "print(\"  ‚úì To halve SE, need 4√ó more data\")\n",
    "print(\"  ‚úì Diminishing returns: going from 100‚Üí1000 helps less than 10‚Üí100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c16464f",
   "metadata": {},
   "source": [
    "## Understanding Sampling from Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba73d22",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4>Definition: Sampling from a Distribution</h4>\n",
    "\n",
    "**Sampling** means generating random values that follow a specific probability distribution.</p>\n",
    "\n",
    "Intuition:\n",
    "\n",
    "- A distribution describes the \"recipe\" for how values should occur\n",
    "- Sampling is like following that recipe to create actual instances\n",
    "- Each sample is random, but collectively they follow the distribution's pattern \n",
    "\n",
    "\n",
    "**Mathematical notation**: $X \\sim p(x)$ means \"$X$ is sampled from distribution $p$\"\n",
    "\n",
    "Sampling from a Distribution means:\n",
    "\n",
    "1. Start with: A probability distribution $p(x)$ that describes the population\n",
    "2. Process: Generate random values $X_1, X_2, ..., X_n$ where each $X_i$ follows distribution $p(x)$\n",
    "3. Result: A sample of $n$ observations from that distribution\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e76843a",
   "metadata": {},
   "source": [
    "Let's consider several examples:\n",
    "\n",
    "1. Uniform Distribution\n",
    "\n",
    "Imagine a perfectly fair spinner that can land anywhere from 0 to 10 with equal probability.\n",
    "Let's spin it 5 times:\n",
    "  - Spin 1: 3.75\n",
    "  - Spin 2: 9.51\n",
    "  - Spin 3: 7.32\n",
    "  - Spin 4: 5.99\n",
    "  - Spin 5: 1.56 \n",
    "\n",
    "> What happens with many samples?\n",
    "\n",
    "With 1000 spins, the histogram matches the uniform shape.\n",
    "- Sample mean: 4.91 (expected: 5.00)\n",
    "- Sample std:  2.92 (expected: 2.89)\n",
    "\n",
    "2. Normal (Gaussian) Distribution\n",
    "\n",
    "Imagine measuring the heights of students (mean=170cm, std=10cm). Most students cluster around 170cm, extreme heights are rare.\n",
    "\n",
    "Let's measure heights of 5 random students:\n",
    "  - Student 1: 175.0 cm\n",
    "  - Student 2: 168.6 cm\n",
    "  - Student 3: 176.5 cm\n",
    "  - Student 4: 185.2 cm\n",
    "  - Student 5: 167.7 cm\n",
    "\n",
    "> What happens with many samples?\n",
    "\n",
    "With 1000 measurements, the histogram matches the bell curve!\n",
    "- Sample mean: 170.19cm (expected: 170cm)\n",
    "- Sample std:  9.79cm (expected: 10cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e289f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo\n",
    "demonstrate_sampling_concept()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb943c2b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Two Perspectives on Sampling:**\n",
    "\n",
    "<table style=\"width:100%; border-collapse: collapse; margin-top: 10px;\">\n",
    "<tr style=\"background-color: #f0f0f0;\">\n",
    "<th style=\"border: 1px solid #ddd; padding: 12px; text-align: left;\">Real-World Perspective</th>\n",
    "<th style=\"border: 1px solid #ddd; padding: 12px; text-align: left;\">Mathematical Perspective</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"border: 1px solid #ddd; padding: 10px; vertical-align: top;\">\n",
    "<strong>Sample from Population</strong><br>\n",
    "- Population has some distribution<br>\n",
    "- Randomly select individuals<br>\n",
    "- Measure their values<br>\n",
    "- Each measurement is a \"sample\"\n",
    "</td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 10px; vertical-align: top;\">\n",
    "<strong>Sample from Distribution</strong><br>\n",
    "- Distribution p(x) describes process<br>\n",
    "- Generate random values<br>\n",
    "- Each follows probability rules<br>\n",
    "- Each value is a \"sample\"\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"border: 1px solid #ddd; padding: 10px; vertical-align: top;\">\n",
    "<em>Example:</em> Measure heights of 100 random students ‚Üí sample of size n=100\n",
    "</td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 10px; vertical-align: top;\">\n",
    "<em>Example:</em> Generate 100 values from Normal(170, 10) ‚Üí sample of size n=100\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<p style=\"margin-top: 15px; padding: 10px; background-color: rgba(33, 150, 243, 0.1); border-left: 4px solid #2196f3;\">\n",
    "<strong>Key Connection:</strong> When we \"sample from a distribution\" computationally, we're simulating the process of randomly sampling from a population!\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c03b67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive demo \n",
    "try:\n",
    "    print(\"üéÆ INTERACTIVE DEMO: Try different sample sizes and distributions!\\n\")\n",
    "    interact(interactive_sampling_demo,\n",
    "             n_samples=IntSlider(min=10, max=10000, step=10, value=100, \n",
    "                                description='Samples:', continuous_update=False),\n",
    "             distribution=Dropdown(options=['Normal', 'Uniform', 'Exponential', 'Beta'],\n",
    "                                  value='Normal', description='Distribution:'))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"Note: ipywidgets not available. Install with: pip install ipywidgets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d1714e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<h4>üí° Key Insights About Sampling</h4>\n",
    "\n",
    "<p><strong>Observation 1: Randomness with Structure</strong></p>\n",
    "<ul>\n",
    "<li>Each individual sample is unpredictable (random)</li>\n",
    "<li>But the <em>pattern</em> of many samples is predictable (follows the distribution)</li>\n",
    "<li>It's like rolling a die: one roll is random, but after 1000 rolls you'll get ~167 sixes</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>Observation 2: More Samples = Better Picture</strong></p>\n",
    "<ul>\n",
    "<li>5 samples: Hard to see the distribution's shape</li>\n",
    "<li>100 samples: Pattern starts to emerge</li>\n",
    "<li>1000 samples: Clear picture of the distribution</li>\n",
    "<li>This is the foundation of Monte Carlo methods!</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>Observation 3: Sample Statistics ‚Üí Population Parameters</strong></p>\n",
    "<ul>\n",
    "<li>Sample mean approximates true mean</li>\n",
    "<li>Sample standard deviation approximates true standard deviation</li>\n",
    "<li>Larger samples ‚Üí better approximations</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6fbe50",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-primary\">\n",
    "<h4>ü§ñ ML Connection: Why Sampling Powers Modern AI</h4>\n",
    "\n",
    "<p><strong>Sampling enables three critical capabilities:</strong></p>\n",
    "\n",
    "<ol>\n",
    "<li><strong>Efficiency</strong>: Can't use all data at once? Sample a batch!\n",
    "   <ul>\n",
    "   <li>Mini-batch SGD: Sample 32 examples instead of using all 1M</li>\n",
    "   <li>Reduces memory usage by 31,250√ó</li>\n",
    "   </ul>\n",
    "</li>\n",
    "\n",
    "<li><strong>Exploration</strong>: Want to see different possibilities? Sample variations!\n",
    "   <ul>\n",
    "   <li>Dropout: Sample different sub-networks each iteration</li>\n",
    "   <li>Data augmentation: Sample different transformations</li>\n",
    "   <li>Prevents overfitting by showing the model diverse examples</li>\n",
    "   </ul>\n",
    "</li>\n",
    "\n",
    "<li><strong>Approximation</strong>: Can't compute exactly? Sample to approximate!\n",
    "   <ul>\n",
    "   <li>Monte Carlo methods (today's topic!)</li>\n",
    "   <li>Estimate complex integrals using random samples</li>\n",
    "   <li>Works even when math is impossible</li>\n",
    "   </ul>\n",
    "</li>\n",
    "</ol>\n",
    "\n",
    "<p><strong>Bottom line:</strong> Understanding sampling is understanding how ML actually works.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b802d691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some ML sampling examples\n",
    "ml_sampling_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cc928e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-exercise\">\n",
    "<h4>‚úèÔ∏è Quick Check: Do You Understand Sampling?</h4>\n",
    "\n",
    "<p><strong>Question 1:</strong> You sample 10 values from Normal(Œº=5, œÉ=2). Their mean is 5.3. Is something wrong?</p>\n",
    "<details>\n",
    "<summary>Click to reveal answer</summary>\n",
    "<p><strong>Answer:</strong> No! This is completely normal. The sample mean will vary around the true mean. With only 10 samples, seeing 5.3 instead of 5.0 is expected. The difference will decrease as you collect more samples.</p>\n",
    "</details>\n",
    "\n",
    "<p><strong>Question 2:</strong> What's the difference between sampling 1000 times from Normal(0,1) versus computing the normal distribution at 1000 points?</p>\n",
    "<details>\n",
    "<summary>Click to reveal answer</summary>\n",
    "<p><strong>Answer:</strong></p>\n",
    "<ul>\n",
    "<li><strong>Sampling:</strong> Get 1000 <em>random</em> values following the distribution (different each time)</li>\n",
    "<li><strong>Computing:</strong> Evaluate the probability density at 1000 <em>fixed</em> points (same each time)</li>\n",
    "<li>Sampling gives you <em>data</em>, computing gives you the <em>formula</em></li>\n",
    "</ul>\n",
    "</details>\n",
    "\n",
    "<p><strong>Question 3:</strong> In mini-batch training with batch_size=32, how many times do we sample per epoch (if dataset has 3200 samples)?</p>\n",
    "<details>\n",
    "<summary>Click to reveal answer</summary>\n",
    "<p><strong>Answer:</strong> 100 times (3200 / 32 = 100 batches per epoch)</p>\n",
    "</details>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de172a2",
   "metadata": {},
   "source": [
    "To generate a sample of size $n$ from a given distribution using python, you can use the method `rvs` from the corresponding `scipy.stats` distribution, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40c3acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 1: Standard Normal distribution\n",
    "X_norm = stats.norm(loc=0, scale=1)\n",
    "# generate 10 samples\n",
    "samples_norm = X_norm.rvs(size=10, random_state=42)\n",
    "print(f\"10 random draws from Standard Normal distribution: {samples_norm}\")\n",
    "\n",
    "# EXAMPLE 2: Bernoulli with p=0.3\n",
    "X_bern = stats.bernoulli(p=0.3)\n",
    "# generate 10 samples\n",
    "samples_bernoulli = X_bern.rvs(size=10, random_state=42)\n",
    "print(f\"10 random draws from Bernoulli distribution with p=0.3: {samples_bernoulli}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d1439e",
   "metadata": {},
   "source": [
    "For generating sample from uniform distribution, it is also common to use [`numpy.random.uniform`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.uniform.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba9e936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 3: Uniform distribution\n",
    "n_samples = 10\n",
    "samples_uniform = np.random.uniform(low=0, high=1, size=n_samples)\n",
    "print(f\"10 random draws from Uniform distribution on [0,1]: {samples_uniform}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6b42ee",
   "metadata": {},
   "source": [
    "## Monte Carlo Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10600cc2",
   "metadata": {},
   "source": [
    "How do you calculate the area of a lake with an irregular shape? Or the probability that your ML model fails in exactly 3 out of 10 edge cases?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b3ac03",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-example\">\n",
    "<h4>The Problem: Can We Estimate œÄ Without Using œÄ?</h4>\n",
    "\n",
    "What we know:\n",
    "\n",
    "- $\\pi ‚âà 3.14159...$ (but let's pretend we don't know this)\n",
    "- $\\pi$ is the ratio of a circle's circumference to its diameter\n",
    "- Calculating $\\pi$ analytically is complex (infinite series, etc.)\n",
    "\n",
    "\n",
    "What we want:\n",
    "\n",
    "- Estimate $\\pi$ using only random numbers and simple geometry\n",
    "- No calculus, no infinite series, no complex math\n",
    "- Just: throw darts randomly and count!\n",
    "\n",
    "\n",
    "<p style=\"margin-top: 15px; padding: 10px; background-color: rgba(255, 193, 7, 0.1); border-left: 4px solid #ffc107;\">\n",
    "<strong>The Monte Carlo Idea:</strong> Use randomness to approximate a deterministic constant!\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe42c83f",
   "metadata": {},
   "source": [
    "Let's consider the following setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223e2771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphical setup for pi calculation\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 7))\n",
    "    \n",
    "# Draw square\n",
    "square = Rectangle((-1, -1), 2, 2, fill=False, edgecolor='tab:blue', linewidth=3)\n",
    "ax.add_patch(square)\n",
    "    \n",
    "# Draw circle\n",
    "circle = Circle((0, 0), 1, fill=False, edgecolor='#EF9A9A', linewidth=3)\n",
    "ax.add_patch(circle)\n",
    "    \n",
    "# Add labels\n",
    "ax.plot([-1, 1], [0, 0], 'b--', alpha=0.5, linewidth=1)\n",
    "ax.plot([0, 0], [-1, 1], 'b--', alpha=0.5, linewidth=1)\n",
    "    \n",
    "# Annotations\n",
    "ax.annotate('', xy=(1, 0), xytext=(0, 0),\n",
    "                arrowprops=dict(arrowstyle='<->', color='#EF9A9A', lw=2))\n",
    "ax.text(0.5, -0.15, 'r = 1', fontsize=12, ha='center', color='#EF9A9A', fontweight='bold')\n",
    "    \n",
    "ax.annotate('', xy=(1, 1), xytext=(1, -1),\n",
    "                arrowprops=dict(arrowstyle='<->', color='tab:blue', lw=2))\n",
    "ax.text(1.2, 0, 'side = 2', fontsize=12, ha='left', color='tab:blue', fontweight='bold')\n",
    "   \n",
    "# Formulas\n",
    "formula_text = \"\"\"\n",
    "    Circle (red):\n",
    "    ‚Ä¢ Radius: r = 1\n",
    "    ‚Ä¢ Area: œÄr¬≤ = œÄ(1)¬≤ = œÄ\n",
    "    \n",
    "    Square (blue):\n",
    "    ‚Ä¢ Side length: 2\n",
    "    ‚Ä¢ Area: 2¬≤ = 4\n",
    "    \n",
    "    Ratio:\n",
    "    Area(circle)   œÄ\n",
    "    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ = ‚îÄ‚îÄ‚îÄ\n",
    "    Area(square)   4\n",
    "    \n",
    "    Solve for œÄ:\n",
    "        Area(circle)  \n",
    "    4 * ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ \n",
    "        Area(square)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "ax.text(-3.5, 0, formula_text, fontsize=11, verticalalignment='center',\n",
    "            family='monospace',\n",
    "            bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n",
    "    \n",
    "ax.set_xlim(-4, 2)\n",
    "ax.set_ylim(-1.5, 1.5)\n",
    "ax.set_aspect('equal')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_title('Geometric Setup', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('x', fontsize=12)\n",
    "ax.set_ylabel('y', fontsize=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796c65f1",
   "metadata": {},
   "source": [
    "**The main (Monte Carlo) idea:**\n",
    "\n",
    "1. Throw darts randomly (uniform in square)\n",
    "    \n",
    "2. Count how many land inside the circle, i.e. $x^2 + y^2 \\leq 1$\n",
    "\n",
    "3. Count results: number of points inside circle, outside circle\n",
    "\n",
    "4. Ratio of counts ‚âà Ratio of areas\n",
    "    \n",
    "5. Solve for $\\pi$\n",
    "\n",
    "$$\\pi = 4 \\times \\frac{\\text{Area circle}}{\\text{Area square}} = 4 \\times \\frac{\\text{\\# darts inside the circle}}{\\text{\\# darts total}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8c7a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "sample_sizes = [10, 100, 1000, 5000, 10000, 50000, 100000]\n",
    "for n in sample_sizes:\n",
    "    pi_est, fig = estimate_pi_visual(n, True)\n",
    "    print(f\"\\n{n} darts: {pi_est}\")\n",
    "    # calculate error\n",
    "    error = abs(pi_est - np.pi)\n",
    "    percent_error = error / np.pi * 100\n",
    "    results.append({\n",
    "        'n': n, \n",
    "        'pi_estimate': pi_est,\n",
    "        'error': error,\n",
    "        'percent_error': percent_error\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c86a2f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4>Definition: Monte Carlo Method</h4>\n",
    "\n",
    "A **Monte Carlo method** is any computational technique that relies on repeated random sampling to obtain numerical results for problems that are:\n",
    "\n",
    "- Analytically intractable (no closed-form solution)\n",
    "- Too complex for traditional numerical methods\n",
    "- High-dimensional\n",
    "\n",
    "**Core Principle:** Use randomness to solve deterministic problems.\n",
    "\n",
    "**Mathematical Foundation:** Law of Large Numbers - as $n \\rightarrow \\infty$, sample mean ‚Üí true mean\n",
    "\n",
    "**Formal Framework:**\n",
    "\n",
    "To estimate an expectation $E[f(X)]$ where $X \\sim p(x)$:\n",
    "\n",
    "1. Sample: Draw $X_1, X_2, ..., X_n \\sim p(x)$\n",
    "2. Evaluate: Compute $f(X_1), f(X_2), ..., f(X_n)$\n",
    "3. Average: $Estimate = (1/n) \\sum_{i=1}^n f(X_i)$\n",
    "\n",
    "Convergence Rate: Error decreases as $O(1/\\sqrt{n})$ regardless of dimensionality.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1494603b",
   "metadata": {},
   "source": [
    "Let's express it formally. \n",
    "\n",
    "Let $X_1, X_2, ... , X_n$ and $Y_1, Y_2, ..., Y_n$ be independent variables with distribution $\\mathcal{U}[-1; 1]$.\n",
    "Let's denote $R^2_i = X^2_i + Y^2_i$. \n",
    "\n",
    "Let $I$ be an indicator function: $I(x, y) = \\left\\{\\begin{array}{ll}1 & \\text{ if } x^2 + y^2 \\leq 1 \\\\ 0 & \\text{ otherwise} \\end{array}\\right.$ \n",
    "\n",
    "Recall our graphical setup. The probability $\\mathbb{P}(R^2_i \\leq 1)$ corresponds to the ratio of the area of the circle with radius 1 which is $pi$ to the area of the square (all points) which is 4. Thus, \n",
    "\n",
    "$$E[I(X, Y)] = \\mathbb{P}(R^2_i \\leq 1) = \\frac{\\text{Area circle}}{\\text{Area square}} = \\frac{\\pi}{4}$$\n",
    "\n",
    "By Monte Carlo estimation:\n",
    "\n",
    "$$E[I(X, Y)] \\approx 1/n \\sum_{i=1}^n I(X_i, Y_i) = \\frac{\\text{count inside}}{n}$$\n",
    "\n",
    "So, solving this for $\\pi$, we obtain:\n",
    "\n",
    "$$\\hat{\\pi} = 4\\times \\frac{\\text{count inside}}{n}$$\n",
    "\n",
    "Let's explore the convergence of this method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72362c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo convergence\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "# Plot 1: Estimates vs n\n",
    "ax1 = axes[0, 0]\n",
    "ns = [r['n'] for r in results]\n",
    "estimates = [r['pi_estimate'] for r in results]\n",
    "    \n",
    "ax1.semilogx(ns, estimates, 'bo-', linewidth=2, markersize=8, label='MC Estimate')\n",
    "ax1.axhline(np.pi, color='red', linewidth=2, linestyle='--', label=f'True œÄ = {np.pi:.6f}')\n",
    "ax1.fill_between(ns, np.pi - 0.1, np.pi + 0.1, alpha=0.2, color='red', \n",
    "                     label='¬±0.1 error band')\n",
    "ax1.set_xlabel('Number of Samples (n)', fontsize=12)\n",
    "ax1.set_ylabel('Estimate of œÄ', fontsize=12)\n",
    "ax1.set_title('Convergence of œÄ Estimate', fontsize=13, fontweight='bold')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(True, alpha=0.3, which='both')\n",
    "    \n",
    "# Plot 2: Error vs n (log-log)\n",
    "ax2 = axes[0, 1]\n",
    "errors = [r['error'] for r in results]\n",
    "    \n",
    "ax2.loglog(ns, errors, 'ro-', linewidth=2, markersize=8, label='Actual Error')\n",
    "    \n",
    "# Theoretical O(1/‚àön) line\n",
    "theoretical = errors[0] * np.sqrt(ns[0]) / np.sqrt(np.array(ns))\n",
    "ax2.loglog(ns, theoretical, 'b--', linewidth=2, label='O(1/‚àön) theoretical')\n",
    "    \n",
    "ax2.set_xlabel('Number of Samples (n)', fontsize=12)\n",
    "ax2.set_ylabel('Absolute Error', fontsize=12)\n",
    "ax2.set_title('Error Decay Rate', fontsize=13, fontweight='bold')\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3, which='both')\n",
    "    \n",
    "# Plot 3: Visualize for n=1000\n",
    "ax3 = axes[1, 0]\n",
    "n_viz = 1000\n",
    "x_viz = np.random.uniform(-1, 1, n_viz)\n",
    "y_viz = np.random.uniform(-1, 1, n_viz)\n",
    "inside_viz = (x_viz**2 + y_viz**2) <= 1\n",
    "    \n",
    "# Draw circle and square\n",
    "circle = Circle((0, 0), 1, fill=False, edgecolor='#EF9A9A', linewidth=2, alpha=0.3)\n",
    "ax3.add_patch(circle)\n",
    "square = Rectangle((-1, -1), 2, 2, fill=False, edgecolor='tab:blue', linewidth=2)\n",
    "ax3.add_patch(square)\n",
    "    \n",
    "# Plot points\n",
    "ax3.scatter(x_viz[inside_viz], y_viz[inside_viz], c='red', s=2, alpha=0.5, label='Inside')\n",
    "ax3.scatter(x_viz[~inside_viz], y_viz[~inside_viz], c='tab:blue', s=2, alpha=0.5, label='Outside')\n",
    "    \n",
    "inside_count_viz = np.sum(inside_viz)\n",
    "pi_viz = 4 * inside_count_viz / n_viz\n",
    "    \n",
    "ax3.set_xlim(-1.2, 1.2)\n",
    "ax3.set_ylim(-1.2, 1.2)\n",
    "ax3.set_aspect('equal')\n",
    "ax3.set_title(f'Visualization: n=1,000 points\\nœÄ ‚âà {pi_viz:.6f}', \n",
    "                  fontsize=13, fontweight='bold')\n",
    "ax3.legend(fontsize=10)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "# Plot 4: Distribution of estimates (run Monte Carlo multiple times)\n",
    "ax4 = axes[1, 1]\n",
    "    \n",
    "n_trials = 1000\n",
    "n_samples = 1000\n",
    "trial_estimates = []\n",
    "    \n",
    "for _ in range(n_trials):\n",
    "    x_trial = np.random.uniform(-1, 1, n_samples)\n",
    "    y_trial = np.random.uniform(-1, 1, n_samples)\n",
    "    inside_trial = np.sum((x_trial**2 + y_trial**2) <= 1)\n",
    "    pi_trial = 4 * inside_trial / n_samples\n",
    "    trial_estimates.append(pi_trial)\n",
    "    \n",
    "trial_estimates = np.array(trial_estimates)\n",
    "    \n",
    "ax4.hist(trial_estimates, bins=40, alpha=0.7, edgecolor='black', density=True, color='skyblue')\n",
    "ax4.axvline(np.pi, color='red', linewidth=2.5, linestyle='--', label=f'True œÄ = {np.pi:.6f}')\n",
    "ax4.axvline(np.mean(trial_estimates), color='green', linewidth=2, \n",
    "                label=f'Mean estimate = {np.mean(trial_estimates):.6f}')\n",
    "    \n",
    "# Show standard error\n",
    "se = np.std(trial_estimates)\n",
    "ax4.axvspan(np.pi - se, np.pi + se, alpha=0.2, color='orange', label=f'¬±1 SE = {se:.6f}')\n",
    "    \n",
    "ax4.set_xlabel('Estimate of œÄ', fontsize=12)\n",
    "ax4.set_ylabel('Density', fontsize=12)\n",
    "ax4.set_title(f'Distribution of Estimates\\n{n_trials} trials with n={n_samples} each', \n",
    "                  fontsize=13, fontweight='bold')\n",
    "ax4.legend(fontsize=10)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43db0302",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<h4>üí° Key Insight: The Curse of Dimensionality... Broken!</h4>\n",
    "\n",
    "Traditional numerical integration (like Simpson's rule) requires n^d evaluations for d dimensions. Monte Carlo needs only n samples regardless of d!\n",
    "\n",
    "This is why Monte Carlo dominates in ML where we routinely work in 1000+ dimensional spaces.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b8b2ae",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-primary\">\n",
    "<h4>ü§ñ ML Application: Dropout Training</h4>\n",
    "<p>Dropout in neural networks is a Monte Carlo method!</p>\n",
    "<ul>\n",
    "<li><strong>Each forward pass</strong> samples a different sub-network (random dropout mask)</li>\n",
    "<li><strong>Training</strong> approximates the expectation over all possible sub-networks</li>\n",
    "<li><strong>Prediction</strong> uses Monte Carlo dropout for uncertainty estimation</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5872ca54",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-primary\">\n",
    "<h4>ü§ñ Why This Foundation Matters for Machine Learning</h4>\n",
    "\n",
    "<p><strong>Every ML workflow follows this exact pattern:</strong></p>\n",
    "\n",
    "<ol>\n",
    "<li><strong>Population:</strong> All possible data points your model might see\n",
    "   <ul>\n",
    "   <li>Example: All possible images of cats</li>\n",
    "   <li>Size: Infinite!</li>\n",
    "   </ul>\n",
    "</li>\n",
    "\n",
    "<li><strong>Sample:</strong> Your training/test dataset\n",
    "   <ul>\n",
    "   <li>Example: ImageNet's 1M labeled images</li>\n",
    "   <li>Size: Finite, manageable</li>\n",
    "   </ul>\n",
    "</li>\n",
    "\n",
    "<li><strong>Distribution:</strong> The learned model\n",
    "   <ul>\n",
    "   <li>Example: Neural network learns P(cat|image)</li>\n",
    "   <li>This is your estimate of the population distribution</li>\n",
    "   </ul>\n",
    "</li>\n",
    "\n",
    "<li><strong>Sampling from Distribution:</strong> Generate synthetic data or make predictions\n",
    "   <ul>\n",
    "   <li>Example: GANs generate new images by sampling from learned distribution</li>\n",
    "   <li>Example: Language models sample next words from P(word|context)</li>\n",
    "   </ul>\n",
    "</li>\n",
    "\n",
    "<li><strong>Monte Carlo:</strong> Estimate model performance, uncertainty\n",
    "   <ul>\n",
    "   <li>Example: Dropout during inference (sample different sub-networks)</li>\n",
    "   <li>Example: Bootstrap to estimate confidence intervals on accuracy</li>\n",
    "   </ul>\n",
    "</li>\n",
    "</ol>\n",
    "\n",
    "<p style=\"margin-top: 15px; padding: 12px; background-color: rgba(103, 58, 183, 0.1); border-left: 4px solid #673ab7;\">\n",
    "<strong>Bottom Line:</strong> Understanding sampling is understanding how ML learns from finite data and makes predictions about infinite possibilities!\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63655a28",
   "metadata": {},
   "source": [
    "## Numerical Integration using Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbd1824",
   "metadata": {},
   "source": [
    "Consider the following **challenge**:\n",
    "\n",
    "$$\\int_a^b f(x)dx$$\n",
    "\n",
    "becomes impossible when:\n",
    "- No closed form exists\n",
    "- High dimensional ($\\int\\int\\int...\\int$)\n",
    "- Complex boundaries\n",
    "\n",
    "> How to calculate it? \n",
    "\n",
    "We can use **Monte Carlo simulation** for that.\n",
    "\n",
    "Let $X\\sim U([a;b])$. Therefore, $X$ has the following probability density: $f_X(x) = \\left\\{\\begin{array}{ll}\\frac{1}{b-a} & \\text{ if } a\\leq x \\leq b\\\\ 0 & \\text{ otherwise} \\end{array}\\right.$\n",
    "\n",
    "1. We can transform our integral of $h(x)$ to expectation:\n",
    "$$\\int_a^b h(x)dx = \\int_a^b h(x) \\cdot 1\\ dx = \\int_a^b h(x) \\cdot \\frac{b-a}{b-a} dx = (b-a)\\int_a^b h(x) \\cdot \\frac{1}{b-a} =\\bigg[\\text{since }f_X(x) = \\frac{1}{b-a}\\bigg]= (b-a)\\int_a^b h(x) \\cdot f_X(x) =[\\text{def. of expectation}]= (b-a) E[h(x)]$$\n",
    "\n",
    "**KEY INSIGHT**: The integral of $h(X)$ equals $(b-a)$ times the expected value of $h(X)$.\n",
    "\n",
    "2. Using Monte Carlo method, we estimate $E[h(x)]$ by sampling:\n",
    "\n",
    "$$E[h(x)] \\approx (1/n) \\sum_{i}^n h(X_i) \\text{ where } X_i \\sim Uniform([a;b])$$\n",
    "\n",
    "Hence:\n",
    "$$\\int_a^b h(x)dx = (b-a) \\cdot (1/n)\\sum_i^n h(X_i)$$\n",
    "\n",
    "**Intuition**: $E[h(X)]$ tells us the AVERAGE HEIGHT of the function, $(b-a)$ is the WIDTH of the interval. Hence, $\\text{Integral} = \\text{WIDTH} \\times \\text{AVERAGE HEIGHT} = (b-a) E[h(X)]$\n",
    "\n",
    "3. Variance and Standard Error\n",
    "\n",
    "Let $Y = h(X)$, so we are estimating $E[Y]$. The sample mean $\\bar{Y} = \\frac{1}{n}\\sum_i^nY_i$ has variance $Var(\\bar{Y}) = Var(Y)/n = \\frac{\\sigma_Y^2}{n}$ where $\\sigma_Y^2 = Var(h(X))$. \n",
    "\n",
    "Our estimator for the integral is $\\hat{I} = (b-a)\\bar{Y}$. \n",
    "\n",
    "Therefore: \n",
    "\n",
    "$$Var(\\hat{I}) = Var((b-a)\\bar{Y}) = [\\text{variance of scaled r.v.}] = (b-a)^2 Var(\\bar{Y}) = (b-a)^2 \\frac{\\sigma_Y^2}{n}$$\n",
    "\n",
    "The standard error is:\n",
    "\n",
    "$$SE(\\hat{I}) = \\sqrt{Var(\\hat{I})} = \\sqrt{(b-a)^2 \\frac{\\sigma_Y^2}{n}} = (b-a) \\frac{\\sigma_Y}{\\sqrt{n}}$$\n",
    "\n",
    "In practice, we estimate $\\sigma_Y$ with the sample standard deviation $s$: $SE(\\hat{I}) = (b-a) \\cdot s/\\sqrt{n}$ where $s = \\sqrt{(1/n)\\sum_i^n(f(X_i) - \\bar{f})^2}$\n",
    "\n",
    "**Intuition**: if you double the interval width, the uncertainty also doubles (more area to estimate). Hence, SE scales with $(b-a)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05df3d0",
   "metadata": {},
   "source": [
    "<div class=\"alert-exercise\">\n",
    "<h5> QUESTION:</h5> \n",
    "\n",
    "Write a function that estimates integral of f using Monte Carlo method. Test it on $f(x) = x^2$ from 0 to 1. Compare the result with the same function from 0 to 2.\n",
    "\n",
    "```\n",
    "def combinations_with_repetition_count(n: int, k: int) -> int:\n",
    "    \"\"\"Calculates and returns the number of combinations with repetition: C(n+k-1, k) \n",
    "\n",
    "    Args:\n",
    "        n (int): number of types of elements\n",
    "        k (int): number of elements taken\n",
    "\n",
    "    Returns:\n",
    "        int: number of combinations with repetitions\n",
    "    \"\"\"\n",
    "```\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec4dd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "def monte_carlo_integrate(f, a:float=0, b:float=1, n_samples:int=10000) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Estimate integral of f from a to b using Monte Carlo\n",
    "    \n",
    "    Theory: ‚à´f(x)dx ‚âà (b-a) * E[f(X)] where X ~ Uniform(a,b)\n",
    "    \n",
    "\n",
    "    Args:\n",
    "        f (function): function to be integrated\n",
    "        a (float): min boundary of integration. Defaults to 0.\n",
    "        b (float): max boundary of integration. Defaults to 1.\n",
    "        n_samples (int, optional): Number of samples to consider. Defaults to 10000.\n",
    "\n",
    "    Returns:\n",
    "        integral estimate and standard error.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb7eee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36dfa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3983f19b",
   "metadata": {},
   "source": [
    "<div class=\"alert example\">\n",
    "<h4>Calculated Example</h4>\n",
    "\n",
    "Compute $I = \\int_{0}^1 e^{-x^2} dx$ using Monte-Carlo method.\n",
    "\n",
    "Note that this integral has NO closed-form solution. True value: $I \\approx 0.746824132812427$ (computed numerically to high precision).\n",
    "\n",
    "Consider the following 10 samples: 0.69646919, 0.28613933, 0.22685145, 0.55131477, 0.71946897, 0.42310646, 0.9807642,  0.68482974, 0.4809319,  0.39211752 (obtained using `numpy.random.uniform` with random seed 123). Perform manual calculation of the value of the integral.\n",
    "\n",
    "Perform calculation using python.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69467e4",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Reveal solution</summary>\n",
    "\n",
    "1. Transform integral to expectation:\n",
    "\n",
    "$$I = \\int_{a}^b f(x) dx = (b-a) E_X[f(X)] \\text{ where } X\\sim Uniform([a,b])$$\n",
    "\n",
    "In our case: $a = 0, b = 1, f(x) = e^{-x^2}$, $X\\sim Uniform([0,1])$\n",
    "$$I = \\int_{0}^1 e^{-x^2} dx = (1-0) E_X[e^{-X^2}] \\text{ where } X\\sim Uniform([0,1]) = E_X[e^{-X^2}]$$\n",
    "\n",
    "2. Monte Carlo Estimator:\n",
    "    \n",
    "$$\\hat{I_n} = (1/n) \\sum_i^n f(X_i) \\text{  where } X_i \\sim Uniform([0,1]) = (1/n) \\sum_i^n e^{-X_i^2}$$\n",
    "    \n",
    "3. Use samples\n",
    "\n",
    "| $i$ | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | Sum | \n",
    "|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n",
    "| $X_i$ | 0.69646919 | 0.28613933 | 0.22685145 | 0.55131477 | 0.71946897 | 0.42310646 | 0.9807642 |  0.68482974 | 0.4809319|  0.39211752 | 5.44199352975335 |\n",
    "| $e^{-X_i^2}$ | 0.61565 | 0.92139 | 0.94984 | 0.73790 | 0.59593 | 0.83609 | 0.38217 | 0.62563 | 0.79350 | 0.85748 | 7.3155836853 |\n",
    "\n",
    "Hence: $\\hat{I_n} = (1/n) \\sum_i^n f(X_i) \\text{  where } X_i \\sim Uniform([0,1]) = (1/n) \\sum_i^n e^{-X_i^2} = 1/10 \\times 7.31558 = 0.731558$\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568503c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function\n",
    "def f(x):\n",
    "    return np.exp(-x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4b2ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True value (computed with high precision)\n",
    "from scipy.integrate import quad\n",
    "true_value, _ = quad(f, 0, 1)\n",
    "    \n",
    "print(f\"\\nTrue value (high precision): I = {true_value:.15f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cdffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 10 random samples\n",
    "np.random.seed(123)\n",
    "n = 10\n",
    "samples = np.random.uniform(0, 1, n)\n",
    "    \n",
    "print(\"Generated samples X·µ¢ ~ Uniform(0,1):\")\n",
    "print(samples)\n",
    "print(samples.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951b052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed calculation for each sample\n",
    "results = []\n",
    "sum_f = 0\n",
    "sum_f_squared = 0\n",
    "    \n",
    "print(f\"{'i':<5} {'X·µ¢':<12} {'f(X·µ¢)=e^(-X·µ¢¬≤)':<18} {'Running Sum':<15} {'Running Avg':<15}\")\n",
    "\n",
    "    \n",
    "for i, x in enumerate(samples, 1):\n",
    "    f_x = f(x)\n",
    "    sum_f += f_x\n",
    "    sum_f_squared += f_x**2\n",
    "    running_avg = sum_f / i\n",
    "        \n",
    "    results.append({\n",
    "            'i': i,\n",
    "            'x': x,\n",
    "            'f_x': f_x,\n",
    "            'sum': sum_f,\n",
    "            'avg': running_avg\n",
    "        })\n",
    "        \n",
    "    print(f\"{i:<5} {x:<12.8f} {f_x:<18.10f} {sum_f:<15.10f} {running_avg:<15.10f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f030b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute sample mean and the estimate\n",
    "mean_f = sum_f / n\n",
    "    \n",
    "print(f\"\\nSample mean:\")\n",
    "print(f\"  fÃÑ = (1/n) Œ£·µ¢ f(X·µ¢)\")\n",
    "print(f\"    = (1/{n}) √ó {sum_f:.10f}\")\n",
    "print(f\"    = {mean_f:.10f}\")\n",
    "\n",
    "integral_estimate = mean_f  # Since (b-a) = 1\n",
    "\n",
    "print(f\"\\nMonte Carlo estimate of integral:\")\n",
    "print(f\"  √é = (b-a) √ó fÃÑ\")\n",
    "print(f\"    = (1-0) √ó {integral_estimate:.10f}\")\n",
    "print(f\"    = {integral_estimate:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2511ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "error = abs(integral_estimate - true_value)\n",
    "relative_error = error / true_value * 100\n",
    "    \n",
    "print(f\"\\nTrue value:        I = {true_value:.15f}\")\n",
    "print(f\"Estimated value:   √é = {integral_estimate:.15f}\")\n",
    "print(f\"Absolute error:    |√é - I| = {error:.15f}\")\n",
    "print(f\"Relative error:    {relative_error:.10f}%\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97273577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute variance\n",
    "variance = (sum_f_squared / n) - mean_f**2\n",
    "std_dev = np.sqrt(variance)\n",
    "se = std_dev / np.sqrt(n)\n",
    "    \n",
    "print(f\"\\nSample variance:\")\n",
    "print(f\"  s¬≤ = (1/n)Œ£·µ¢ f(X·µ¢)¬≤ - fÃÑ¬≤\")\n",
    "print(f\"     = (1/{n}) √ó {sum_f_squared:.10f} - ({mean_f:.10f})¬≤\")\n",
    "print(f\"     = {sum_f_squared/n:.10f} - {mean_f**2:.10f}\")\n",
    "print(f\"     = {variance:.10f}\")\n",
    "    \n",
    "print(f\"\\nSample standard deviation:\")\n",
    "print(f\"  s = ‚àös¬≤\")\n",
    "print(f\"    = ‚àö{variance:.10f}\")\n",
    "print(f\"    = {std_dev:.10f}\")\n",
    "    \n",
    "print(f\"\\nStandard error:\")\n",
    "print(f\"  SE = (b-a) √ó s/‚àön\")\n",
    "print(f\"     = (1-0) √ó {std_dev:.10f}/‚àö{n}\")\n",
    "print(f\"     = {std_dev:.10f}/{np.sqrt(n):.10f}\")\n",
    "print(f\"     = {se:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db460e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 95% CI using normal approximation\n",
    "z_95 = 1.96\n",
    "ci_lower = integral_estimate - z_95 * se\n",
    "ci_upper = integral_estimate + z_95 * se\n",
    "# Check if true value is in CI\n",
    "in_ci = ci_lower <= true_value <= ci_upper\n",
    "print(f\"\\nIs true value in 95% CI? {in_ci}\")\n",
    "if in_ci:\n",
    "    print(f\"  ‚úì YES: {ci_lower:.6f} ‚â§ {true_value:.6f} ‚â§ {ci_upper:.6f}\")\n",
    "else:\n",
    "    print(f\"  ‚úó NO: True value outside [{ci_lower:.6f}, {ci_upper:.6f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dde52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "# Plot 1: Function and sample points\n",
    "ax1 = axes[0, 0]\n",
    "x_plot = np.linspace(0, 1, 1000)\n",
    "y_plot = f(x_plot)\n",
    "    \n",
    "ax1.fill_between(x_plot, 0, y_plot, alpha=0.3, color='blue', label='Area = integral')\n",
    "ax1.plot(x_plot, y_plot, 'b-', linewidth=2, label='f(x) = e^(-x¬≤)')\n",
    "    \n",
    "# Plot sample points\n",
    "for i, r in enumerate(results):\n",
    "    ax1.plot([r['x'], r['x']], [0, r['f_x']], 'r--', alpha=0.5, linewidth=1)\n",
    "    ax1.scatter([r['x']], [r['f_x']], c='red', s=100, zorder=5, edgecolor='black', linewidth=1.5)\n",
    "    ax1.text(r['x'], r['f_x'] + 0.05, f\"{i+1}\", ha='center', fontsize=9, fontweight='bold')\n",
    "    \n",
    "# Show mean height\n",
    "ax1.axhline(mean_f, color='green', linewidth=2, linestyle='--',\n",
    "                label=f'Mean height: {mean_f:.4f}')\n",
    "ax1.fill_between([0, 1], 0, mean_f, alpha=0.15, color='green')\n",
    "    \n",
    "ax1.set_xlabel('x', fontsize=12)\n",
    "ax1.set_ylabel('f(x)', fontsize=12)\n",
    "ax1.set_title(f'Function and Sample Points\\n'\n",
    "                  f'Integral ‚âà 1 √ó {mean_f:.4f} = {integral_estimate:.4f}',\n",
    "                  fontsize=12, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xlim(-0.05, 1.05)\n",
    "ax1.set_ylim(0, 1.1)\n",
    "    \n",
    "# Plot 2: Convergence of estimate\n",
    "ax2 = axes[0, 1]\n",
    "running_avgs = [r['avg'] for r in results]\n",
    "ax2.plot(range(1, n+1), running_avgs, 'bo-', linewidth=2, markersize=8)\n",
    "ax2.axhline(true_value, color='red', linewidth=2, linestyle='--',\n",
    "                label=f'True value: {true_value:.6f}')\n",
    "ax2.axhline(integral_estimate, color='green', linewidth=2, linestyle=':',\n",
    "                label=f'Final estimate: {integral_estimate:.6f}')\n",
    "    \n",
    "ax2.set_xlabel('Number of samples (i)', fontsize=12)\n",
    "ax2.set_ylabel('Running average', fontsize=12)\n",
    "ax2.set_title('Convergence of Estimate', fontsize=12, fontweight='bold')\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "# Plot 3: Distribution of f(Xi) values\n",
    "ax3 = axes[1, 0]\n",
    "f_vals = [r['f_x'] for r in results]\n",
    "ax3.hist(f_vals, bins=7, alpha=0.7, edgecolor='black', color='skyblue')\n",
    "ax3.axvline(mean_f, color='red', linewidth=2.5, linestyle='--',\n",
    "                label=f'Mean: {mean_f:.4f}')\n",
    "ax3.axvline(mean_f - std_dev, color='orange', linewidth=1.5, linestyle=':')\n",
    "ax3.axvline(mean_f + std_dev, color='orange', linewidth=1.5, linestyle=':',\n",
    "                label=f'¬±1 SD: {std_dev:.4f}')\n",
    "    \n",
    "ax3.set_xlabel('f(X·µ¢) values', fontsize=12)\n",
    "ax3.set_ylabel('Frequency', fontsize=12)\n",
    "ax3.set_title('Distribution of Sample Values', fontsize=12, fontweight='bold')\n",
    "ax3.legend(fontsize=10)\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "# Plot 4: Summary box\n",
    "ax4 = axes[1, 1]\n",
    "ax4.axis('off')\n",
    "    \n",
    "summary_text = f\"\"\"\n",
    "    SUMMARY OF MONTE CARLO INTEGRATION\n",
    "    {'='*50}\n",
    "    \n",
    "    Problem: ‚à´‚ÇÄ¬π e^(-x¬≤) dx\n",
    "    \n",
    "    Method: Monte Carlo with n = {n} samples\n",
    "    \n",
    "    Results:\n",
    "    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    Sample mean (fÃÑ):        {mean_f:.10f}\n",
    "    Sample std dev (s):      {std_dev:.10f}\n",
    "    Standard error (SE):     {se:.10f}\n",
    "    \n",
    "    Integral estimate (√é):   {integral_estimate:.10f}\n",
    "    95% Confidence Interval: [{ci_lower:.6f}, {ci_upper:.6f}]\n",
    "    \n",
    "    True value (I):          {true_value:.10f}\n",
    "    Absolute error:          {error:.10f}\n",
    "    Relative error:          {relative_error:.4f}%\n",
    "    \n",
    "    True value in CI?        {'‚úì YES' if in_ci else '‚úó NO'}\n",
    "    \n",
    "    {'='*50}\n",
    "    \n",
    "    Interpretation:\n",
    "    ‚Ä¢ With just {n} samples, we estimated the integral\n",
    "      to within {relative_error:.2f}% of the true value\n",
    "    ‚Ä¢ Standard error of {se:.4f} tells us the\n",
    "      typical error we expect\n",
    "    ‚Ä¢ 95% CI means: if we repeated this {n}-sample\n",
    "      experiment many times, ~95% of intervals\n",
    "      would contain the true value\n",
    "    ‚Ä¢ More samples would reduce SE by O(1/‚àön)\n",
    "    \"\"\"\n",
    "    \n",
    "ax4.text(0.05, 0.95, summary_text, transform=ax4.transAxes,\n",
    "            fontsize=9, verticalalignment='top', family='monospace',\n",
    "            bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7f6f87",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-summary\">\n",
    "\n",
    "<h4>Monte Carlo vs Traditional Numerical Integration Methods</h4>\n",
    "\n",
    "<table style=\"width:100%; border-collapse: collapse; margin: 10px 0; font-size: 0.9em;\">\n",
    "<tr style=\"background-color: #f0f0f0;\">\n",
    "<th style=\"border: 1px solid #ddd; padding: 6px;\">Method</th>\n",
    "<th style=\"border: 1px solid #ddd; padding: 6px;\">Convergence</th>\n",
    "<th style=\"border: 1px solid #ddd; padding: 6px;\">1D</th>\n",
    "<th style=\"border: 1px solid #ddd; padding: 6px;\">High-D</th>\n",
    "<th style=\"border: 1px solid #ddd; padding: 6px;\">Deterministic?</th>\n",
    "<th style=\"border: 1px solid #ddd; padding: 6px;\">Uncertainty Estimate?</th>\n",
    "<th style=\"border: 1px solid #ddd; padding: 6px;\">Best For</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"border: 1px solid #ddd; padding: 6px;\">Rectangle</td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 6px;\">O(1/n)</td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 6px;\">Poor</td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 6px;\">Infeasible</td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 8px;\">‚úÖ Yes</td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 8px;\">‚ùå No</td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 6px;\">Teaching</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"border: 1px solid #ddd; padding: 6px;\">Trapezoidal</td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 6px;\">O(1/n¬≤)</td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 6px;\">Good</td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 6px;\">Infeasible</td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 8px;\">‚úÖ Yes</td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 8px;\">‚ùå No</td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 6px;\">1D smooth</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"border: 1px solid #ddd; padding: 6px;\">Simpson</td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 6px;\">O(1/n‚Å¥)</td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 6px;\">Excellent</td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 6px;\">Infeasible</td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 8px;\">‚úÖ Yes</td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 8px;\">‚ùå No</td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 6px;\">1D very smooth</td>\n",
    "</tr>\n",
    "<tr style=\"background-color: #e8f5e9;\">\n",
    "<td style=\"border: 1px solid #ddd; padding: 6px;\"><strong>Monte Carlo</strong></td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 6px;\"><strong>O(1/‚àön)</strong></td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 6px;\"><strong>Moderate</strong></td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 6px;\"><strong>‚úÖ Feasible</strong></td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 8px;\">‚ùå No (random)</td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 8px;\">‚úÖ Yes (SE)</td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 6px;\"><strong>High-D / ML</strong></td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "**Monte Carlo and the Curse of Dimensionality:**\n",
    "\n",
    "- Dimension 1-3:</br>\n",
    "    ‚úì Traditional methods (Simpson) are faster and more accurate</br>\n",
    "    ‚úì Use them if you can!\n",
    "    \n",
    "- Dimension 4-5:</br>\n",
    "    ~ Traditional methods still feasible but getting expensive</br>\n",
    "    ~ Monte Carlo becomes competitive\n",
    "    \n",
    "- Dimension 10+:</br>\n",
    "    ‚úó Traditional methods INFEASIBLE</br>\n",
    "    ‚úì Monte Carlo is the ONLY practical option\n",
    "    \n",
    "- Dimension 100 (typical in ML):</br>\n",
    "    ‚Ä¢ Simpson would need 10^100 evaluations</br>\n",
    "    ‚Ä¢ Monte Carlo still needs only 10,000 evaluations\n",
    "\n",
    "<p><strong>Key Insight:</strong></p>\n",
    "<ul>\n",
    "<li>Traditional methods: O(10^d) evaluations in d dimensions ‚Üí exponential curse</li>\n",
    "<li>Monte Carlo: O(n) evaluations regardless of d ‚Üí dimension-free!</li>\n",
    "<li>In ML (d=100+), Monte Carlo is literally the only option</li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"margin-top: 15px; padding: 12px; background-color: rgba(33, 150, 243, 0.1); border-left: 4px solid #2196f3; font-weight: bold;\">\n",
    "This is why every modern ML algorithm fundamentally relies on Monte Carlo methods!\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad09cbd",
   "metadata": {},
   "source": [
    "## Bootstrapping or Bootstrap Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8183ae1c",
   "metadata": {},
   "source": [
    "You trained a model on 1000 samples. How do you estimate how much your model's accuracy would vary if you collected the data again?\n",
    "\n",
    "This is what we mean by **uncertainty**.\n",
    "\n",
    "- ‚úì Low uncertainty ‚Üí Different samples give similar estimates (stable)\n",
    "- ‚úó High uncertainty ‚Üí Different samples give very different estimates (unstable)\n",
    "\n",
    "**The Dilemma:**\n",
    "\n",
    "- Collecting new data: $$$, slow, sometimes impossible\n",
    "- Mathematical formulas: Often don't exist for complex statistics\n",
    "- **Bootstrap**: Treat your sample as the population, i.e. simulate \"new samples\" by resampling from what we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afcc640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo uncertainty\n",
    "std_means = visualize_uncertainty_concept()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd6650b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4>Definition: Bootstrap Sampling</h4>\n",
    "\n",
    "**Bootstrap** is a resampling method that estimates the sampling distribution of a statistic by:\n",
    "\n",
    "\n",
    "- Sampling <em>with replacement</em> from your original data\n",
    "- Computing the statistic on each resample\n",
    "- Using the distribution of these statistics to estimate uncertainty\n",
    "\n",
    "\n",
    "**Key Idea:** The relationship between sample and population is similar to the relationship between bootstrap samples and original sample.\n",
    "\n",
    "Invented by: [Bradley Efron](https://en.wikipedia.org/wiki/Bradley_Efron) (1979)\n",
    "\n",
    "**Procedure:**\n",
    "\n",
    "Step 1: Start with our ONE sample\n",
    "    \n",
    "Step 2: Create a \"new sample\" by:\n",
    "- Randomly selecting n values FROM our sample\n",
    "- Sampling WITH REPLACEMENT\n",
    "- This gives us a \"bootstrap sample\"\n",
    "    \n",
    "Step 3: Compute the statistic on this bootstrap sample (e.g., mean, median, whatever we're estimating)\n",
    "    \n",
    "Step 4: Repeat steps 2-3 many times (e.g., 1000 times)\n",
    "    \n",
    "Step 5: Look at the DISTRIBUTION of bootstrap estimates\n",
    "- The spread of this distribution = UNCERTAINTY\n",
    "- Shows how much estimate varies across \"fake samples\"\n",
    "\n",
    "*Interpretation*: If we COULD collect new samples of size $n$, our estimates would typically vary by about $\\pm$ STD of bootstrap distribution around the value of bootstrap estimate (mean). \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf96cb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo\n",
    "np.random.seed(42)\n",
    "sample_data = np.random.exponential(scale=2, size=100)\n",
    "bootstrap_stats, ci = bootstrap_demo(sample_data, np.mean, n_bootstrap=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98186fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo explaining uncertainty\n",
    "bootstrap_means, bootstrap_std = bootstrap_uncertainty_explanation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab6aed6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Bootstrap gives us a DISTRIBUTION of estimates.\n",
    "\n",
    "The SPREAD of this distribution tells us: \"How different would my estimate be with a different sample?\"\n",
    "\n",
    "<h4>üí° Key Insight: Why Sampling WITH Replacement?</h4>\n",
    "\n",
    "<p>Without replacement ‚Üí you get the same sample every time (useless!)</p>\n",
    "<p>With replacement ‚Üí each bootstrap sample is different, mimicking the variability of collecting new data</p>\n",
    "<p>On average, each bootstrap sample contains ~63.2% unique observations from the original sample (some appear multiple times, some don't appear at all).</p>\n",
    "</div>    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f5ccc2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-primary\">\n",
    "<h4>ü§ñ ML Application: Model Performance Uncertainty</h4>\n",
    "<p><strong>Scenario:</strong> You have 1000 test samples with 87% accuracy.</p>\n",
    "<p><strong>Bootstrap Approach:</strong></p>\n",
    "<ol>\n",
    "<li>Resample your test set 1000 times (with replacement)</li>\n",
    "<li>Compute accuracy on each bootstrap sample</li>\n",
    "<li>Get distribution of accuracy ‚Üí confidence interval</li>\n",
    "</ol>\n",
    "<p><strong>Used by:</strong> scikit-learn's cross-validation, Kaggle competitions, production ML monitoring</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccbf7b9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-summary\">\n",
    "<h4>üèÜ Production Best Practices</h4>\n",
    "<ol>\n",
    "<li><strong>Always report confidence intervals</strong> alongside point estimates</li>\n",
    "<li><strong>Use bootstrap for model comparison</strong> before deployment</li>\n",
    "<li><strong>Monitor CI width</strong> as a model health metric (widening = degradation)</li>\n",
    "<li><strong>Combine methods:</strong> Bootstrap for data uncertainty + MC Dropout for model uncertainty</li>\n",
    "<li><strong>Cache bootstrap samples</strong> for faster re-evaluation</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b502017",
   "metadata": {},
   "source": [
    "## Return to the Opening Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0b58fb",
   "metadata": {},
   "source": [
    "The question we are about to ask is:\n",
    "\n",
    "> Can we trust the 87% accuracy for a $50M decision?\n",
    "</br>\n",
    "\n",
    "Let's generate the data to simulate the scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5771599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_test=1000, observed_accuracy=0.87):\n",
    "    # Simulate the scenario\n",
    "    np.random.seed(42)\n",
    "    n_correct = int(observed_accuracy * n_test)\n",
    "    # Calculate how many predictions should be incorrect\n",
    "    n_incorrect = n_test - n_correct\n",
    "\n",
    "    \n",
    "    # Create synthetic data matching the scenario\n",
    "    y_true = np.random.randint(0, 2, size=n_test)\n",
    "    y_pred = y_true.copy()  # Perfect on this split\n",
    "    # Randomly select indices to flip\n",
    "    incorrect_indices = np.random.choice(n_test, size=n_incorrect, replace=False)\n",
    "    # Adjust to get exactly 87% \n",
    "    # Flip the predictions at those indices\n",
    "    y_pred[incorrect_indices] = 1 - y_pred[incorrect_indices]\n",
    "    # calculate accuracy\n",
    "    actual_acc = accuracy_score(y_true, y_pred)\n",
    "        \n",
    "    print(f\"\"\"\n",
    "    Test set size: {n_test} samples\n",
    "    Correct predictions: {n_correct}\n",
    "    Observed accuracy: {actual_acc:.1%}\n",
    "    \n",
    "    But this is just ONE test set!\n",
    "    Question: Would we get similar accuracy with DIFFERENT test data?\n",
    "    \"\"\")\n",
    "    \n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967f3a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate the scenario\n",
    "n_test = 1000\n",
    "observed_accuracy=0.87\n",
    "n_correct =int(observed_accuracy * n_test)\n",
    "y_true, y_pred = generate_data(n_test=n_test, observed_accuracy=observed_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d00c3e",
   "metadata": {},
   "source": [
    "METHOD 1: Standard Error (Quick Assessment)\n",
    "\n",
    "- For accuracy, we can think of each prediction as $Bernoulli(p)$. \n",
    "- For binary classification (correct/incorrect), we can use the formula of Standard error of a proportion: $SE = \\sqrt{p(1-p)/n}$ where $p$ = observed accuracy and $n$ = test set size.\n",
    "\n",
    "$$SE = \\sqrt{p(1-p)/n} = \\sqrt{0.87 (1 - 0.87) / 1000} = \\sqrt{0.87 \\times 0.13 / 1000} = \\sqrt{0.1131 / 1000} \\approx 0.01063$$\n",
    "\n",
    "*Interpretation*:\n",
    "- Our estimate: 87% accuracy\n",
    "- Typical variation: $\\pm SE = \\pm 1.06\\% \\approx \\pm 1.1\\%$\n",
    "- Range of typical accuracy: $[\\text{Observed accuracy} - SE, \\text{Observed accuracy} + SE] = [87 - 1.1, 87 + 1.1] = [85.9\\%, 88.1\\%]$\n",
    "- Compared to 85% accuracy threshold from the problem statement, even our lower end 85.9% is above it $\\Rightarrow$ green light\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8524ba6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "se_formula = np.sqrt(observed_accuracy * (1 - observed_accuracy) / n_test)\n",
    "    \n",
    "print(f\"\"\"\n",
    "    For binary classification (correct/incorrect), we can use the formula:\n",
    "    \n",
    "        SE = ‚àö[p(1-p)/n]\n",
    "        \n",
    "    where p = observed accuracy = {observed_accuracy}\n",
    "          n = test set size = {n_test}\n",
    "    \n",
    "    Calculation:\n",
    "        SE = ‚àö[{observed_accuracy} √ó {1-observed_accuracy} / {n_test}]\n",
    "           = ‚àö[{observed_accuracy * (1-observed_accuracy)} / {n_test}]\n",
    "           = ‚àö{observed_accuracy * (1-observed_accuracy) / n_test:.6f}\n",
    "           = {se_formula:.4f}\n",
    "    \n",
    "    INTERPRETATION:\n",
    "    {'‚îÄ'*70}\n",
    "    ‚Ä¢ Our estimate: 87% accuracy\n",
    "    ‚Ä¢ Typical variation: ¬±{se_formula:.1%} (that's ¬±{se_formula*100:.1f} percentage points)\n",
    "    \n",
    "    ‚Ä¢ If you tested on DIFFERENT data samples:\n",
    "      - We'd typically get accuracy between:\n",
    "        {observed_accuracy - se_formula:.1%} and {observed_accuracy + se_formula:.1%}\n",
    "      - That's roughly {(observed_accuracy - se_formula)*100:.1f}% to {(observed_accuracy + se_formula)*100:.1f}%\n",
    "    \n",
    "    First concern: Even the lower end ({(observed_accuracy - se_formula)*100:.1f}%) \n",
    "                   is above our 85% threshold! ‚úì\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d5f501",
   "metadata": {},
   "source": [
    "METHOD 2: Bootstrap (Detailed Assessment)\n",
    "\n",
    "Let's use bootstrap to really understand the variability:\n",
    "    \n",
    "1. We have 1,000 test predictions (correct/incorrect for each)\n",
    "2. Resample these 1,000 predictions WITH replacement\n",
    "3. Compute accuracy on each bootstrap sample\n",
    "4. Repeat 10,000 times to see the full \n",
    "5. Analyse the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c87b12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap analysis\n",
    "n_bootstrap = 10000\n",
    "bootstrap_accuracies = []\n",
    "    \n",
    "for _ in range(n_bootstrap):\n",
    "    # Resample indices with replacement\n",
    "    indices = np.random.choice(n_test, size=n_test, replace=True)\n",
    "    # calculate accuracy score\n",
    "    boot_acc = accuracy_score(y_true[indices], y_pred[indices])\n",
    "    bootstrap_accuracies.append(boot_acc)\n",
    "    \n",
    "bootstrap_accuracies = np.array(bootstrap_accuracies)\n",
    "\n",
    "# Analyze results\n",
    "bootstrap_mean = np.mean(bootstrap_accuracies)\n",
    "bootstrap_std = np.std(bootstrap_accuracies)\n",
    "bootstrap_min = np.min(bootstrap_accuracies)\n",
    "bootstrap_max = np.max(bootstrap_accuracies)\n",
    "    \n",
    "# Key percentiles\n",
    "p05 = np.percentile(bootstrap_accuracies, 5)\n",
    "p25 = np.percentile(bootstrap_accuracies, 25)\n",
    "p75 = np.percentile(bootstrap_accuracies, 75)\n",
    "p95 = np.percentile(bootstrap_accuracies, 95)\n",
    "\n",
    "# How many bootstrap samples are above 85%?\n",
    "above_85 = np.mean(bootstrap_accuracies >= 0.85) * 100\n",
    "    \n",
    "print(f\"\"\"\n",
    "    Distribution of Bootstrap Accuracies:\n",
    "    {'‚îÄ'*70}\n",
    "    \n",
    "    Original accuracy:           {observed_accuracy:.1%}\n",
    "    \n",
    "    Bootstrap statistics:\n",
    "    ‚Ä¢ Average:                   {bootstrap_mean:.1%}\n",
    "    ‚Ä¢ Standard deviation:        {bootstrap_std:.2%} (this is the uncertainty!)\n",
    "    ‚Ä¢ Minimum seen:              {bootstrap_min:.1%}\n",
    "    ‚Ä¢ Maximum seen:              {bootstrap_max:.1%}\n",
    "    \n",
    "    Percentiles (how values are spread):\n",
    "    ‚Ä¢ Bottom 5%:                 {p05:.1%}\n",
    "    ‚Ä¢ Bottom 25%:                {p25:.1%}\n",
    "    ‚Ä¢ Top 25%:                   {p75:.1%}\n",
    "    ‚Ä¢ Top 95%:                   {p95:.1%}\n",
    "    \n",
    "    Middle 50% of estimates:     [{p25:.1%}, {p75:.1%}]\n",
    "    Middle 90% of estimates:     [{p05:.1%}, {p95:.1%}]\n",
    "    \n",
    "    KEY FINDING:\n",
    "    {'‚îÄ'*70}\n",
    "    ‚Ä¢ {above_85:.1f}% of bootstrap samples had accuracy ‚â• 85%\n",
    "    ‚Ä¢ Only {100-above_85:.1f}% were below 85%\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5a522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "# Plot 1: Bootstrap distribution\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "    \n",
    "ax1.hist(bootstrap_accuracies, bins=50, alpha=0.7, edgecolor='black', \n",
    "             color='skyblue', density=False)\n",
    "    \n",
    "ax1.axvline(observed_accuracy, color='red', linewidth=3, linestyle='-',\n",
    "               label=f'Our accuracy: {observed_accuracy:.1%}', zorder=5)\n",
    "ax1.axvline(0.85, color='orange', linewidth=3, linestyle='--',\n",
    "               label=f'Threshold: 85%', zorder=5)\n",
    "    \n",
    "# Shade regions\n",
    "ax1.axvspan(bootstrap_min, 0.85, alpha=0.15, color='red', \n",
    "               label=f'Below 85%: {100-above_85:.1f}%')\n",
    "ax1.axvspan(0.85, bootstrap_max, alpha=0.15, color='green',\n",
    "               label=f'Above 85%: {above_85:.1f}%')\n",
    "    \n",
    "# Mark percentiles\n",
    "ax1.axvline(p05, color='purple', linewidth=1.5, linestyle=':', alpha=0.7)\n",
    "ax1.axvline(p95, color='purple', linewidth=1.5, linestyle=':', alpha=0.7)\n",
    "ax1.text(p05, ax1.get_ylim()[1]*0.9, f'5th: {p05:.1%}', \n",
    "            ha='right', fontsize=9, rotation=90)\n",
    "ax1.text(p95, ax1.get_ylim()[1]*0.9, f'95th: {p95:.1%}', \n",
    "            ha='left', fontsize=9, rotation=90)\n",
    "    \n",
    "ax1.set_xlabel('Accuracy', fontsize=12)\n",
    "ax1.set_ylabel('Frequency (out of 10,000 bootstrap samples)', fontsize=12)\n",
    "ax1.set_title(f'Bootstrap Distribution: \"How much does accuracy vary?\"\\n'\n",
    "                 f'Standard deviation: {bootstrap_std:.2%} (the uncertainty measure)',\n",
    "                 fontsize=13, fontweight='bold')\n",
    "ax1.legend(fontsize=11, loc='upper left')\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "# Plot 2: Cumulative distribution\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "    \n",
    "sorted_accs = np.sort(bootstrap_accuracies)\n",
    "cumulative = np.arange(1, len(sorted_accs) + 1) / len(sorted_accs) * 100\n",
    "    \n",
    "ax2.plot(sorted_accs, cumulative, linewidth=2.5, color='blue')\n",
    "ax2.axvline(0.85, color='orange', linewidth=3, linestyle='--', \n",
    "               label=f'85% threshold')\n",
    "ax2.axhline(50, color='gray', linewidth=1, linestyle=':', alpha=0.5)\n",
    "    \n",
    "# Mark the 85% line\n",
    "pct_below_85 = 100 - above_85\n",
    "ax2.plot([0.85, 0.85], [0, pct_below_85], 'r--', linewidth=2, alpha=0.5)\n",
    "ax2.plot([0.82, 0.85], [pct_below_85, pct_below_85], 'r--', linewidth=2, alpha=0.5)\n",
    "ax2.text(0.848, pct_below_85/2, f'{pct_below_85:.1f}%\\nbelow', \n",
    "            fontsize=10, ha='right', color='red', fontweight='bold')\n",
    "    \n",
    "ax2.set_xlabel('Accuracy', fontsize=12)\n",
    "ax2.set_ylabel('Cumulative Percentage', fontsize=12)\n",
    "ax2.set_title(f'Cumulative Distribution\\n'\n",
    "                 f'{above_85:.1f}% of estimates are ‚â• 85%',\n",
    "                 fontsize=12, fontweight='bold')\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_xlim(0.82, 0.92)\n",
    "    \n",
    "# Plot 3: Comparison of methods\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "ax3.axis('off')\n",
    "    \n",
    "comparison_text = f\"\"\"\n",
    "    COMPARING THE TWO METHODS\n",
    "    {'='*50}\n",
    "    \n",
    "    Standard Error Method:\n",
    "    {'‚îÄ'*50}\n",
    "    ‚Ä¢ SE = {se_formula:.4f} ({se_formula*100:.2f} percentage points)\n",
    "    ‚Ä¢ Typical range: {observed_accuracy - se_formula:.1%} to {observed_accuracy + se_formula:.1%}\n",
    "    ‚Ä¢ Quick, formula-based\n",
    "    \n",
    "    Bootstrap Method:\n",
    "    {'‚îÄ'*50}\n",
    "    ‚Ä¢ SD = {bootstrap_std:.4f} ({bootstrap_std*100:.2f} percentage points)\n",
    "    ‚Ä¢ Typical range: {p05:.1%} to {p95:.1%}\n",
    "    ‚Ä¢ Full distribution, no assumptions\n",
    "    \n",
    "    Agreement:\n",
    "    {'‚îÄ'*50}\n",
    "    SE ‚âà {se_formula*100:.2f} pp vs Bootstrap SD ‚âà {bootstrap_std*100:.2f} pp\n",
    "    \n",
    "    Difference: {abs(se_formula - bootstrap_std)*100:.2f} pp\n",
    "    \n",
    "    ‚úì Very similar! Both methods agree on \n",
    "      the uncertainty level.\n",
    "    \n",
    "    {'='*50}\n",
    "    \n",
    "    What This Tells Us:\n",
    "    {'‚îÄ'*50}\n",
    "    \n",
    "    1. Our 87% estimate is STABLE\n",
    "       (standard deviation ~{bootstrap_std*100:.1f} pp)\n",
    "    \n",
    "    2. With different test data, we'd \n",
    "       typically get accuracy between\n",
    "       {observed_accuracy - bootstrap_std:.1%} and {observed_accuracy + bootstrap_std:.1%}\n",
    "    \n",
    "    3. {above_85:.1f}% of possible outcomes are \n",
    "       above our 85% threshold\n",
    "    \n",
    "    4. The risk of being below 85% is \n",
    "       only {100-above_85:.1f}%\n",
    "    \"\"\"\n",
    "    \n",
    "ax3.text(0.05, 0.95, comparison_text, transform=ax3.transAxes,\n",
    "            fontsize=9, verticalalignment='top', family='monospace',\n",
    "            bbox=dict(boxstyle='round', facecolor='lightcyan', alpha=0.8))\n",
    "    \n",
    "# Plot 4: Decision framework\n",
    "ax4 = fig.add_subplot(gs[2, :])\n",
    "ax4.axis('off')\n",
    "    \n",
    "# Decision\n",
    "decision_color = 'lightgreen' if above_85 > 95 else 'lightyellow' if above_85 > 90 else 'lightcoral'\n",
    "    \n",
    "if above_85 > 95:\n",
    "    decision = \"GREEN LIGHT - PROCEED\"\n",
    "    reasoning = f\"Very high confidence ({above_85:.1f}% of estimates ‚â• 85%)\"\n",
    "    risk = \"Low\"\n",
    "    recommendation = \"Safe to deploy with $50M investment\"\n",
    "elif above_85 > 90:\n",
    "    decision = \"YELLOW LIGHT - PROCEED WITH CAUTION\"\n",
    "    reasoning = f\"Good confidence ({above_85:.1f}% of estimates ‚â• 85%)\"\n",
    "    risk = \"Moderate\"\n",
    "    recommendation = \"Proceed but with monitoring and contingency plan\"\n",
    "else:\n",
    "    decision = \"RED LIGHT - DO NOT PROCEED\"\n",
    "    reasoning = f\"Insufficient confidence (only {above_85:.1f}% of estimates ‚â• 85%)\"\n",
    "    risk = \"High\"\n",
    "    recommendation = f\"Need ~{int((0.85/observed_accuracy)**2 * n_test - n_test)} more test samples\"\n",
    "    \n",
    "decision_text = f\"\"\"\n",
    "    \n",
    "    EXECUTIVE DECISION FRAMEWORK\n",
    "    {'‚ïê'*80}\n",
    "    \n",
    "    INVESTMENT: $50 Million deployment\n",
    "    REQUIREMENT: Accuracy must be ‚â• 85% to justify investment\n",
    "    \n",
    "    {'‚ïê'*80}\n",
    "    YOUR DATA:\n",
    "    {'‚îÄ'*80}\n",
    "    ‚Ä¢ Test set size: {n_test:,} samples\n",
    "    ‚Ä¢ Observed accuracy: {observed_accuracy:.1%}\n",
    "    ‚Ä¢ Uncertainty (SD): ¬±{bootstrap_std:.2%}\n",
    "    ‚Ä¢ Estimates ‚â• 85%: {above_85:.1f}%\n",
    "    \n",
    "    {'‚ïê'*80}\n",
    "    UNCERTAINTY ANALYSIS:\n",
    "    {'‚îÄ'*80}\n",
    "    \n",
    "    Best case scenario (95th percentile):    {p95:.1%}\n",
    "    Typical high estimate:                   {p75:.1%}\n",
    "    Your observed accuracy:                  {observed_accuracy:.1%}\n",
    "    Typical low estimate:                    {p25:.1%}\n",
    "    Worst case scenario (5th percentile):    {p05:.1%}\n",
    "    \n",
    "    Critical threshold:                      85.0%\n",
    "    \n",
    "    Probability accuracy ‚â• 85%:              {above_85:.1f}%\n",
    "    Probability accuracy < 85%:              {100-above_85:.1f}%\n",
    "    \n",
    "    {'‚ïê'*80}\n",
    "    DECISION: {decision}\n",
    "    {'‚îÄ'*80}\n",
    "    \n",
    "    Risk Level: {risk}\n",
    "    Reasoning: {reasoning}\n",
    "    \n",
    "    Recommendation:\n",
    "    {recommendation}\n",
    "    \n",
    "    {'‚îÄ'*80}\n",
    "    \n",
    "    Why this decision?\n",
    "    \n",
    "    ‚Ä¢ The uncertainty analysis shows that {above_85:.1f}% of bootstrap samples \n",
    "      (representing possible outcomes with different test data) achieve ‚â• 85% accuracy\n",
    "    \n",
    "    ‚Ä¢ Your estimate of {observed_accuracy:.1%} would typically vary by ¬±{bootstrap_std*100:.1f} percentage points\n",
    "      if you tested on different data\n",
    "    \n",
    "    ‚Ä¢ The 5th percentile ({p05:.1%}) {\"is above\" if p05 >= 0.85 else \"is close to but below\"} your 85% threshold\n",
    "    \n",
    "    ‚Ä¢ With {n_test:,} test samples, you have {\"sufficient\" if above_85 > 95 else \"moderate\" if above_85 > 90 else \"insufficient\"} \n",
    "      evidence to support the $50M investment\n",
    "    \"\"\"\n",
    "    \n",
    "ax4.text(0.02, 0.98, decision_text, transform=ax4.transAxes,\n",
    "            fontsize=9, verticalalignment='top', family='monospace',\n",
    "            bbox=dict(boxstyle='round', facecolor=decision_color, alpha=0.7))\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a001e2",
   "metadata": {},
   "source": [
    "So, the answer:  GREEN LIGHT - PROCEED\n",
    "    - Even in bad scenarios, we're above the threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bac8a73",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<h4>üí° What Your Intuition Missed</h4>\n",
    "<p><strong>Initial Guess:</strong> Most people say \"87% ¬± 2%\" or just trust the 87%</p>\n",
    "<p><strong>Reality:</strong> With 1000 samples and 87% observed accuracy:</p>\n",
    "\n",
    "1. Uncertainty (how much it would vary): ¬±1.1%\n",
    "    - This means with different test data, we'd typically get accuracy between 85.9% and 88.1%\n",
    "2. Risk assessment: 96.9% probability of meeting 85% threshold\n",
    "    - Only 3.1% chance of falling short\n",
    "3. Worst-case scenario: 85.2% (5th percentile)\n",
    "\n",
    "<p><strong>Lesson:</strong> Sample size and uncertainty quantification are crucial for business decisions</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cf1075",
   "metadata": {},
   "source": [
    "## Common Mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6451ba2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "\n",
    "<h4>‚ö†Ô∏è Common Pitfalls</h4>\n",
    "<ul>\n",
    "<li><strong>Bootstrap without replacement:</strong> Gives same sample every time - useless!</li>\n",
    "<li><strong>Too few iterations:</strong> Need 1000+ for stable CI estimates</li>\n",
    "<li><strong>Ignoring dependence:</strong> Bootstrap assumes independent samples</li>\n",
    "<li><strong>Confusing SE with CI:</strong> SE is standard deviation, CI is interval</li>\n",
    "<li><strong>MC without convergence check:</strong> Always verify error is acceptable</li>\n",
    "</ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34ddfd3",
   "metadata": {},
   "source": [
    "## ML Application Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9344ae85",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-summary\">\n",
    "<h4>ü§ñ ML Applications Summary</h4>\n",
    "\n",
    "<table style=\"width:100%; border-collapse: collapse;\">\n",
    "<tr style=\"background-color: #f0f0f0;\">\n",
    "<th style=\"border: 1px solid #ddd; padding: 8px;\">Method</th>\n",
    "<th style=\"border: 1px solid #ddd; padding: 8px;\">ML Application</th>\n",
    "<th style=\"border: 1px solid #ddd; padding: 8px;\">When to Use</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"border: 1px solid #ddd; padding: 8px;\">Monte Carlo</td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 8px;\">Policy gradients, dropout, Bayesian inference</td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 8px;\">Computing expectations, high-dim integrals</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"border: 1px solid #ddd; padding: 8px;\">Bootstrap</td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 8px;\">Model evaluation, CI for metrics, A/B testing</td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 8px;\">Estimating uncertainty without assumptions</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"border: 1px solid #ddd; padding: 8px;\">MC + Bootstrap</td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 8px;\">Complete uncertainty quantification</td>\n",
    "<td style=\"border: 1px solid #ddd; padding: 8px;\">Production deployment decisions</td>\n",
    "</tr>\n",
    "</table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00af8165",
   "metadata": {},
   "source": [
    "## Key Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a5e541",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-summary\">\n",
    "<h4>üéì Key Takeaways</h4>\n",
    "<ol>\n",
    "<li><strong>Monte Carlo Methods:</strong> Use randomness to solve deterministic problems\n",
    "   - Error: O(1/‚àön) regardless of dimensionality\n",
    "   - Essential for high-dimensional integration\n",
    "</li>\n",
    "<li><strong>Numerical Integration:</strong> E[f(X)] ‚âà (1/n)Œ£f(X·µ¢)\n",
    "   - Works when analytical integration is impossible\n",
    "   - Convergence guaranteed by Law of Large Numbers\n",
    "</li>\n",
    "<li><strong>Bootstrap:</strong> Resample with replacement to estimate uncertainty\n",
    "   - Treats sample as population\n",
    "   - No assumptions about distribution needed\n",
    "   - 95% CI: [2.5th percentile, 97.5th percentile]\n",
    "</li>\n",
    "<li><strong>Production ML:</strong> Always quantify uncertainty\n",
    "   - Bootstrap CI for performance metrics\n",
    "   - MC dropout for neural network uncertainty\n",
    "   - Statistical tests for model comparison\n",
    "</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6aedbae",
   "metadata": {},
   "source": [
    "## Useful Links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff418cc4",
   "metadata": {},
   "source": [
    "1. [Sampling from a Statistical Distribution, Clearly Explained!! by StatQuest](https://www.youtube.com/watch?v=XLCWeSVzHUU)\n",
    "2. [Sample Size and Effective Sample Size, Clearly Explained!! by StatQuest](https://www.youtube.com/watch?v=67zCIqdeXpo)\n",
    "3. [Bootstrapping Main Ideas!! by StatQuest](https://www.youtube.com/watch?v=Xz0x-8-cgaQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12575a49",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
