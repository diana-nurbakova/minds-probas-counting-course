{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd0db355",
   "metadata": {},
   "source": [
    "# Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf2cf00",
   "metadata": {},
   "source": [
    "Author & Instructor: Diana NURBAKOVA, PhD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aa01e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"../styles/styles.css\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774078c3",
   "metadata": {},
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147421c1",
   "metadata": {},
   "source": [
    "By the end of this lesson, you will be able to:\n",
    "- Define confidence intervals\n",
    "- Interpret confidence intervals\n",
    "- Calculate CI for mean, proportion, variance\n",
    "- Calculate bootstrap CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f727682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better-looking plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_style(\"whitegrid\")\n",
    "#sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feea76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, IntSlider, FloatSlider, Dropdown\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98e3f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = ['DejaVu Sans', 'Segoe UI Emoji']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ae0413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the \"resources\" directory to the path\n",
    "project_root = Path().resolve().parent\n",
    "resources_path = project_root / 'resources'\n",
    "sys.path.insert(0, str(resources_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b93cc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confidence_intervals import (demonstrate_the_crisis, visualize_ci_interpretation, t_distribution_viz, dissect_confidence_interval, chi_2_distribution_viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e46213",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h4>ðŸŽ¯ Today's Challenge: The AI Product Launch Crisis</h4>\n",
    "\n",
    "**The Scenario:**\n",
    "You're the lead ML engineer at a startup. Your image classification model is ready for production. \n",
    "\n",
    "Your boss asks: *\"What's the accuracy?\"*</br>\n",
    "You answer: *\"94.2% on our test set of 500 images.\"*</br>\n",
    "Your boss: *\"Great! I'm telling investors we have 94% accuracy.\"* \n",
    "\n",
    "But then... After deployment, real-world accuracy is only 92.5%: \n",
    "\n",
    "- Investors are upset: \"You promised 94%, we're only seeing 92.5%!\"\n",
    "- Your reputation takes a hit\n",
    "- The product launch credibility is damaged\n",
    "\n",
    "The autopsy meeting:\n",
    "\n",
    "Boss: \"You said 94.2%! What happened? Why are we seeing 92.5%?\"</br>\n",
    "You realize: You gave a POINT ESTIMATE without uncertainty quantification.\n",
    "\n",
    "What you should have said: *\"Our accuracy is 94.2%, but with 95% confidence, the true accuracy is between 92.2% and 96.2%. We might see values as low as 92.2% in production.\"*\n",
    "\n",
    "**The lesson:**\n",
    "- The 92.5% we're seeing IS within the expected range\n",
    "- Nothing went \"wrong\" - this is normal sampling variability\n",
    "- But communicating only the point estimate set wrong expectations\n",
    "\n",
    "**Today's mission**: Learn to ALWAYS quantify uncertainty\n",
    "</div>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9440242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation\n",
    "demonstrate_the_crisis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5312342c",
   "metadata": {},
   "source": [
    "## What is a Confidence Interval?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924759f5",
   "metadata": {},
   "source": [
    "Point estimation can be a good starting point for estimating a population parameter. \n",
    "\n",
    "Let's consider $\\bar{X}$ as a point estimator of the population expected value $m$ which is unknown.\n",
    "\n",
    "<center>\n",
    "<img src=\"img/point-estimate-0.png\" width=\"300px\" alt=\"Point estimate of an unknown population parameter\">\n",
    "</center>\n",
    "\n",
    "As the true value of $m$ is unknown, it can be smaller or greater or equal to $\\bar{X}$:\n",
    "\n",
    "<center>\n",
    "<img src=\"img/point-estimate-1.png\" width=\"300px\" alt=\"Point estimate vs a true population parameter value\">\n",
    "</center>\n",
    "\n",
    "> What is the error of this estimate, i.e. *how far an estimate might be from the true value*? </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aabb039",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4>Definition: Margin of Error</h4>\n",
    "\n",
    "**Margin of error** (ME), $\\epsilon$, is an error associated with the estimation of the parameter under study. It can be considered as the largest distance between the point estimate and the bounds of the interval that includes the value of the population parameter with a high probability.\n",
    "\n",
    "<center>\n",
    "<img src=\"img/point-estimate-2.png\" alt=\"Margin of error\" width=\"300px\">\n",
    "</center>\n",
    "\n",
    "Two components:\n",
    "1. The first reflects desired confidence level\n",
    "2. The second measures precision (sampling variability)\n",
    "\n",
    "**Key Properties:**\n",
    "- Is symmetric: the interval extends equally in both directions (i.e. $\\text{Estimate} - \\epsilon$ and $\\text{Estimate} + \\epsilon$)\n",
    "\n",
    "<center>\n",
    "<img src=\"img/point-estimate-3.png\" alt=\"Symmetry of the margin of error\" width=\"300px\">\n",
    "</center>\n",
    "\n",
    "- Depends on confidence level: More confidence â†’ Wider interval â†’ Less precise\n",
    "- Decreases with sample size $ME \\propto \\frac{1}{\\sqrt{n}}$ (i.e. to cut ME in half, need 4Ã— the sample size)\n",
    "- Has same units as estimate \n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de0e694",
   "metadata": {},
   "source": [
    "| Correct Interpretations | Incorrect Interpretations|\n",
    "|---|---|\n",
    "|\"Our estimate could be off by about Â±ME\"| \"ME tells us if our estimate is biased\" (NO - ME is about precision, not bias)|\n",
    "| \"The true value is likely within ME of our estimate\"|\"ME is the maximum possible error\" (NO - it's tied to confidence level)\n",
    "| \"ME quantifies the precision of our estimate\"||\n",
    "|\"Smaller ME = more precise estimate\"||"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d23cb01",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4> Definition: Confidence Interval</h4>\n",
    "\n",
    "A **confidence interval (CI)** is a range of plausible values for an unknown parameter.\n",
    "\n",
    "Let $\\beta$ be a **level of confidence** (LC), i.e. a value that reflects the certainty that the interval estimate contains the value of the population parameter, e.g. 95% ($\\beta = 0.95$), 99% ($\\beta = 0.99$).\n",
    "\n",
    "**Notation:**\n",
    "- $\\theta$ = unknown parameter (e.g., true accuracy, true mean)\n",
    "- $[L, U]$ = confidence interval ($L$ = Lower, $U$ = Upper bounds)\n",
    "- $1 - \\alpha$ = confidence level (typically 0.95 for 95%)\n",
    "\n",
    "**Formal Definition:**\n",
    "A $(1-\\alpha) \\times 100\\%$ confidence interval satisfies:\n",
    "$$P(L \\leq \\theta \\leq U) = 1 - \\alpha$$\n",
    "\n",
    "or in other words:\n",
    "$$P(\\theta \\in [L, U]) = \\beta$$\n",
    "\n",
    "This is a random interval because $L$ and $U$ are random variables.\n",
    "\n",
    "The values $L$ and $U$ are called **critical values**, i.e. the number of standard errors we need to go out from our estimate to capture the desired confidence level. Critical values mark the boundaries of the middle $(1-\\alpha)$ region in distribution.\n",
    "\n",
    "**Key components:**\n",
    "- **Point estimate** $\\hat{\\theta}$: our best guess\n",
    "- **Margin of error** $\\epsilon$: how far we might be off\n",
    "- **Interval**: $[\\hat{\\theta} - \\epsilon, \\hat{\\theta} + \\epsilon]$\n",
    "\n",
    "**Common confidence levels:**\n",
    "- 90% confidence: $\\alpha = 0.10$\n",
    "- 95% confidence: $\\alpha = 0.05$ (most common)\n",
    "- 99% confidence: $\\alpha = 0.01$\n",
    "\n",
    "</div>\n",
    "\n",
    "<center>\n",
    "<img src=\"img/ci.png\" alt=\"Confidence Interval\" width=\"800px\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80804bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_ci_interpretation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8fc2e7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<h4>CI Interpretation: What CI Really Means</h4>\n",
    "\n",
    "**WRONG interpretation (don't say this!):**</br>\n",
    "\"There's a 95% probability that $\\theta$ is in [L, U]\"\n",
    "\n",
    "**CORRECT interpretation:**</br>\n",
    "\"If we repeated this procedure many times, 95% of the intervals would contain $\\theta$\"\n",
    "\n",
    "**Why the difference matters:**\n",
    "- $\\theta$ is FIXED (not random) - it's the true value\n",
    "- The INTERVAL is random (depends on random data)\n",
    "- Confidence is about the PROCEDURE, not about $\\theta$\n",
    "\n",
    "**Analogy:** \n",
    "Think of a fishing net with 95% catch rate. Each time you cast:\n",
    "- The fish location ($\\theta$) is fixed\n",
    "- Your net location (CI) varies\n",
    "- 95% of casts will catch the fish\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8f13b7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<h4>ðŸ’¡ Why This Interpretation Matters in ML</h4>\n",
    "\n",
    "*Example*: Model Deployment Decision\n",
    "\n",
    "You report: \"Accuracy = 94% Â± 2% (95% CI)\"</br>\n",
    "Boss asks: \"So there's a 95% chance accuracy is between 92-96%?\"</br>\n",
    "You (**now**): \"Not quite. It means: if we tested the model on many different test sets and computed a CI each time, 95% of those intervals would contain the true accuracy. For THIS specific test set, the true accuracy is either in [92%, 96%] or it isn't - but our methodology is reliable 95% of the time.\"\n",
    "\n",
    "*Practical implication*: You can't say \"probably between 92-96%\". You say \"I'm confident it's between 92-96%, based on a method that's right 95% of the time.\"\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ff24ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dissect_confidence_interval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec59505",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-example\">\n",
    "<h4>Calculated Example: CI</h4>\n",
    "\n",
    "According to a survey of 600 individuals, people sleep an average of 10.5 hours per night. Construct a 98% confidence interval with a margin of error of 1.3 hours. \n",
    "\n",
    "<h5>Solution:</h5>\n",
    "\n",
    "Let $n = 600$, $\\bar{X} = 10.5$, $\\epsilon = 1.3$, $\\beta = 0.98$, $\\alpha = 1 - \\beta = 1 - 0.98 = 0.02$. \n",
    "\n",
    "$$\\begin{array}{l}\\bar{X} + \\epsilon = 10.5 + 1.3 = 11.8 \\\\ \\bar{X} - \\epsilon = 10.5 - 1.3 = 9.2 \\end{array}$$\n",
    "\n",
    "A 98% confidence interval is: $9.2 \\leq \\mu \\leq 11.8$ or $\\mu \\in [9.2, 11.8]$\n",
    "\n",
    "<center>\n",
    "<img src=\"img/ci-ex0.png\" width=\"300px\" alt=\"CI of the mean: 9.2 <= mu <= 11.8\">\n",
    "</center>\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339998f4",
   "metadata": {},
   "source": [
    "## Confidence Interval for the Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d55628",
   "metadata": {},
   "source": [
    "**Setup:**\n",
    "- Sample: $X_1, X_2, ..., X_n$\n",
    "- Sample mean: $\\bar{X}$\n",
    "- Population variance $\\sigma^2$ is unknown\n",
    "- Sample standard deviation: $s$\n",
    "- Population mean estimator: $\\hat{\\mu} = \\bar{X}$\n",
    "\n",
    "**Want**: CI for population mean $\\mu$\n",
    "\n",
    "Here's a workflow to find a confidence interval for population mean:\n",
    "\n",
    "<center>\n",
    "<img src=\"img/ci-mean-workflow.png\" width=\"800px\" alt=\"Workflow for finding CI for population mean\">\n",
    "</center>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<h4>Formula: CI for Mean</h4>\n",
    "\n",
    "$$\\bar{X} - t_{\\nu; \\alpha/2} \\leq \\mu \\leq \\bar{X} + t_{\\nu; \\alpha/2}$$\n",
    "\n",
    "</div>\n",
    "\n",
    "> What is $t_{\\nu; \\alpha/2}$? </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273b5b86",
   "metadata": {},
   "source": [
    "### $t$-Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547c1cd9",
   "metadata": {},
   "source": [
    "In practice, we usually don't know $\\sigma$ (population standard deviation), but we have a sample. So, we can compute sample mean $\\bar{X}$ and sample std $s$. \n",
    "\n",
    "When we replace $\\sigma$ with $s$, the statistic $$t = \\frac{\\bar{X} - \\mu}{s/\\sqrt{n}}$$ does NOT follow a normal distribution. Instead, it follows a **$t$-distribution** with $(n-1)$ degrees of freedom, where $n$ is the sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ff18af",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4>Definition: Student's t-distribution</h4>\n",
    "\n",
    "**Student's $t$-distribution** $t_\\nu$ is a continuous probability distribution that generalises the standard normal distribution. But $t_\\nu$ has heavier tails, and the amount of probability mass in the tails is controlled by the parameter $\\nu$.\n",
    "\n",
    "$$f(t) = \\frac{\\Gamma\\bigg(\\frac{\\nu + 1}{2}\\bigg)}{\\sqrt{\\pi\\nu}\\Gamma\\bigg(\\frac{\\nu}{2}\\bigg)}\\bigg(1 + \\frac{t^2}{\\nu}\\bigg)^{-(\\nu + 1)/2}$$\n",
    "\n",
    "where $\\nu$ is the number of degrees of freedom, and $\\Gamma$ is the gamma function.\n",
    "\n",
    "**Key properties:**\n",
    "- Symmetric around 0 (like standard normal distribution)\n",
    "- Bell-shaped (like standard normal distribution)\n",
    "- Heavier tails than normal (more probability in extremes)\n",
    "- As degrees of freedom $\\nu \\rightarrow \\infty$, t-distribution â†’ standard normal\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c686d800",
   "metadata": {},
   "source": [
    "> Why heavier tails? </br>\n",
    "\n",
    "- Using $s$ instead of $\\sigma$ adds extra uncertainty\n",
    "- Small samples: $s$ can vary a lot from $\\sigma$\n",
    "- Need wider intervals to maintain confidence level\n",
    "\n",
    "> Degrees of Freedom: Why $\\nu = (n-1)$? </br>\n",
    "\n",
    "- We use sample mean $\\bar{X}$ to compute $s$ -> This 'uses up' one degree of freedom\n",
    "- Only $(n-1)$ values are 'free' to vary\n",
    "\n",
    "> What effect of degrees of freedom? </br>\n",
    "\n",
    "1. Small df (e.g. $df = 2$):\n",
    "\n",
    "- Very heavy tails\n",
    "- Much wider than normal\n",
    "- Large uncertainty\n",
    "\n",
    "2. Medium df (e.g. $df = 10$):\n",
    "\n",
    "- Moderate tails\n",
    "- Noticeably wider than normal\n",
    "- Moderate uncertainty\n",
    "\n",
    "3. Large df (e.g. $df = 30+$)\n",
    "\n",
    "- Close to normal\n",
    "- Nearly identical to $z$-distribution\n",
    "- Uncertainty dominated by sample size, not estimation\n",
    "\n",
    "<center>\n",
    "<img src=\"img/t-dist.png\" width=\"600px\" alt=\"t-distribution\">\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d475591",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_distribution_viz()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66320a0e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<h4>ðŸ’¡ Key Insight: t-distribution</h4>\n",
    "\n",
    "1. Use t-distribution when Ïƒ is unknown (almost always)\n",
    "2. $t$ has heavier tails than normal (accounts for extra uncertainty)\n",
    "3. Degrees of freedom = $n - 1$ for single sample mean\n",
    "4. As sample size increases, t â†’ normal\n",
    "5. Rule of thumb: $df \\geq 30$ means t â‰ˆ normal\n",
    "6. Always safer to use $t$ than $z$ in practice\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1951ded4",
   "metadata": {},
   "source": [
    "You can use [`scipy.stats.t`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.t.html) implementation of this distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341aa8bc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-exercise\">\n",
    "<h4>Calculated Example: Finding Critical <em>t</em> Value</h4>\n",
    "\n",
    "Find $t_{\\nu;\\alpha/2}$ if the sample size is $n=13$ and the confidence level is $\\beta = 95\\%$. \n",
    "\n",
    "<h5>Solution:</h5>\n",
    "\n",
    "Degrees of freedom: $$\\nu = n - 1 = 13 - 1 = 12$$\n",
    "\n",
    "$$\\alpha = 1 - \\beta = 1 - 0.95 = 0.05 \\Rightarrow \\alpha/2 = 0.025$$\n",
    "\n",
    "<center>\n",
    "<img src=\"img/ci-t-mean-1.png\" width=\"600px\" alt=\"Critical values of t-distribution\">\n",
    "</center>\n",
    "\n",
    "$$t_{\\nu=12, \\alpha/2 = 0.025} = 2.179$$\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b344b141",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 13 # sample size\n",
    "df = n - 1 # df = 12\n",
    "# OPTION 1\n",
    "# critical values\n",
    "stats.t.interval(confidence=0.95, df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496b2012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 2\n",
    "conf = 0.95 \n",
    "alpha = 1 - conf \n",
    "t_critical = stats.t.ppf(1 - alpha/2, df=df)\n",
    "print(t_critical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a4264c",
   "metadata": {},
   "source": [
    "### Finding CI for Mean using $t$-distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5b653e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-exercise\">\n",
    "<h4>Calculated Exercise: Build a CI for Expectation</h4>\n",
    "\n",
    "A machine learning engineer is monitoring the inference latency of a deployed recommendation model. From a sample of 4 peak-hour batches, the average response time is 49 milliseconds with a standard deviation of s'â‚™ = 15 ms. Find the 99% confidence interval for the true mean inference latency across all peak-hour periods.\n",
    "\n",
    "<h5>Solution:</h5>\n",
    "\n",
    "What is known: $n = 4$, $\\beta = 0.99$, $\\bar{X} = 49$, $s' = 15$\n",
    "\n",
    "Hence:\n",
    "\n",
    "$$\\nu = n - 1 = 4 - 1 = 3$$\n",
    "$$\\alpha = 1 - \\beta = 1 - 0.99 = 0.01 \\Rightarrow \\alpha/2 = 0.005$$\n",
    "\n",
    "$$t_{\\nu=3; \\alpha/2 = 0.005} = 5.841$$\n",
    "\n",
    "$$\\epsilon = t_{\\nu=3; \\alpha/2 = 0.005} \\times \\frac{s'}{\\sqrt{n}} = 5.841\\times \\frac{15}{\\sqrt{4}} \\approx 43.80$$\n",
    "\n",
    "$$\\begin{array}{l}\\bar{X} - \\epsilon = 49 - 43.80 = 5.20\\\\\\bar{X} + \\epsilon = 49 + 43.80 = 92.80\\end{array}$$\n",
    "\n",
    "$$5.20 \\leq \\mu \\leq 92.80$$\n",
    "\n",
    "The interval is very wide. One might question its usefulness. Perhaps it would be worth adding more data to reduce the interval.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3a0202",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "df = n - 1\n",
    "conf = 0.99\n",
    "stats.t.interval(confidence=conf, df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12245571",
   "metadata": {},
   "source": [
    "## Confidence Interval for the Proportion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c55e804",
   "metadata": {},
   "source": [
    "Recall that **proportion** is a fraction of the population / sample that has a certain characteristic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ba1cba",
   "metadata": {},
   "source": [
    "**Setup:**\n",
    "- Sample: $X_1, X_2, ..., X_n$\n",
    "- Sample proportion: $\\hat{p}$\n",
    "- Sample size $n$\n",
    "- Population variance $\\sigma^2$ is unknown\n",
    "- Sample standard deviation: $s$\n",
    "- Population proportion estimator: $\\hat{p}$\n",
    "\n",
    "**Want**: CI for population proportion $p$\n",
    "\n",
    "**Conditions for normal approximation** (i.e. large samples where CLT applies):\n",
    "- $n\\times \\hat{p} \\geq 10$\n",
    "- $n\\times (1 - \\hat{p}) \\geq 10$\n",
    "\n",
    "Here's a workflow to find a confidence interval for population proportion:\n",
    "\n",
    "<center>\n",
    "<img src=\"img/ci-proportion-workflow.png\" width=\"800px\" alt=\"Workflow for CI for proportion\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1871332",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4>Formula: CI for Proportion</h4>\n",
    "\n",
    "$$\\hat{p} - z_{\\alpha/2}\\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}} \\leq p \\leq \\hat{p} + z_{\\alpha/2}\\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}}$$\n",
    "\n",
    "</div>\n",
    "\n",
    "> What is $z_{\\alpha/2}$? </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d382cdf2",
   "metadata": {},
   "source": [
    "$z_{\\alpha/2}$ is a critical value of $z$. To find it, we use the Standard Normal distribution $\\mathcal{N}(0,1)$.\n",
    "\n",
    "Let's consider the Standard Normal distribution. The shaded region between $-z_\\beta$ and $z_\\beta$ corresponds to the confidence level $\\beta$:\n",
    "\n",
    "<center>\n",
    "<img src=\"img/ci-prop-z-score.png\" width=\"600px\" alt=\"Normal Distribution with critical values of $z_\\beta$ and $-z_\\beta$\">\n",
    "</center>\n",
    "\n",
    "The remaining area under the curve corresponds to $\\alpha = 1 - \\beta$, therefore, the area under the curve of each part (1) to the left to $-z_\\beta$ and (2) to the right to $z_\\beta$ is equal to $\\frac{1 - \\beta}{2} = \\alpha/2$:\n",
    "\n",
    "<center>\n",
    "<img src=\"img/ci-prop-z-score-2.png\" width=\"600px\" alt=\"Normal Distribution with shaded area $-z_\\beta$ and $>z_\\beta$\">\n",
    "</center>\n",
    "\n",
    "Putting all together:\n",
    "\n",
    "<center>\n",
    "<img src=\"img/ci-prop-z-score-3.png\" width=\"600px\" alt=\"Normal Distribution with critical values $z_\\beta$ and $-z_\\beta$\">\n",
    "</center>\n",
    "\n",
    "To find the value of $z_{\\alpha/2}$, we can use [`scipy.stats.norm`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3de83e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# option 1\n",
    "conf = 0.95 # confidence level\n",
    "stats.norm.interval(confidence=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b10ced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# option 2\n",
    "beta = 0.95\n",
    "alpha = 1 - beta\n",
    "z_critical = stats.norm.ppf(1 - alpha/2)\n",
    "print(z_critical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cbd790",
   "metadata": {},
   "source": [
    "Note that the values of $z_{\\alpha/2}$ are dependent only on the confidence level and are independent of the problem. The most common values:\n",
    "\n",
    "|Level of Confidence, $\\beta$| $z_\\beta$ |\n",
    "|:---:|:----|\n",
    "|0.80|1.2816|\n",
    "|0.85|1.4395|\n",
    "|0.90|1.6449|\n",
    "|0.95|1.9600|\n",
    "|0.98|2.3263|\n",
    "|0.99|2.5758|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aadfc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "confs = [0.8, 0.85, 0.9, 0.95, 0.98, 0.99]\n",
    "\n",
    "print(\"| Level of Confidence | z_beta |\")\n",
    "print(\"_\"*32)\n",
    "for c in confs:\n",
    "    z_c = stats.norm.interval(confidence=c)[1]\n",
    "    print(f\"|{c:19.2f}  | {z_c:.4f} |\")\n",
    "print(\"_\"*32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdad1ea8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-exercise\">\n",
    "<h4>Calculated Exercise: Build a CI for Proportion</h4>\n",
    "\n",
    "A spam classifier was tested on 200 emails and correctly classified 174.\n",
    "\n",
    "Tasks:\n",
    "\n",
    "1. Compute the point estimate for accuracy\n",
    "2. Compute the standard error\n",
    "3. Find the 95% critical value\n",
    "4. Construct a 95% confidence interval\n",
    "5. Interpret the result\n",
    "6. How would the CI change if:\n",
    "    - You tested on 2000 emails instead? (10x more data)\n",
    "    - You wanted 99% confidence instead?\n",
    "7. If your company requires 85% accuracy, can we deploy this model?\n",
    "\n",
    "</div>\n",
    "\n",
    "<h5>Solution:</h5>\n",
    "\n",
    "1. Compute the point estimate for accuracy\n",
    "\n",
    "Here, we are dealing with proportion of correctly classified emails:\n",
    "\n",
    "$$\\hat{p} = 174 / 200 = 0.87$$\n",
    "\n",
    "Check the conditions for normal approximation:\n",
    "\n",
    "- $n\\times \\hat{p} = 200 \\times 0.87 = 174 \\geq 10$\n",
    "- $n\\times (1 - \\hat{p}) = 200 \\times 0.13 = 26 \\geq 10$\n",
    "\n",
    "Both conditions are satisfied, so the normal approximation is valid.\n",
    "\n",
    "2. Compute the standard error \n",
    "\n",
    "$$SE = \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}} = \\sqrt{\\frac{0.87 \\times (1 - 0.87)}{200}} = 0.238$$\n",
    "\n",
    "3. Find the 95% critical value\n",
    "\n",
    "For 95% confidence level $z_\\beta = 1.96$\n",
    "\n",
    "4. Construct a 95% confidence interval\n",
    "\n",
    "$$\\begin{array}{l}\\hat{p} - z_{\\alpha/2}\\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}} = 0.87 - 1.96 \\times 0.238 = 0.823\\\\ \\hat{p} + z_{\\alpha/2}\\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}} =  0.87 + 1.96 \\times 0.238 = 0.917\\end{array}$$\n",
    "\n",
    "5. Interpret the result\n",
    "\n",
    "*We are 95% confident that the true spam detection accuracy is between 82.3% and 91.7%. In production, we should expect accuracy in this range.*\n",
    "\n",
    "6. How would the CI change if you tested on 2000 emails instead? (10x more data)\n",
    "\n",
    "The estimate will be modified: $\\hat{p} = 1740 / 2000 = 0.87$\n",
    "\n",
    "SE will also be affected: $SE = \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}} = \\sqrt{\\frac{0.87 \\times (1 - 0.87)}{2000}} = 0.0238$\n",
    "\n",
    "The critical value remains the same, i.e. $z_{0.95} = 1.96$.\n",
    "\n",
    "Margin of error: $\\epsilon = z_{0.95}\\times \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}} = 1.96\\times 0.0238 = 0.0147$\n",
    "\n",
    "Hence, CI of 95% for accuracy:\n",
    "$$\\begin{array}{l}\\hat{p} - z_{\\alpha/2}\\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}} = 0.87 - 0.0147 = 0.855\\\\ \\hat{p} + z_{\\alpha/2}\\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}} =  0.87 + 0.0147 = 0.885\\end{array}$$\n",
    "\n",
    "\n",
    "*Observation*: Larger sample â†’ Smaller SE â†’ Smaller margin â†’ Narrower CI\n",
    "\n",
    "7. How would the CI change if you wanted 99% confidence instead?\n",
    "\n",
    "We need to update the critical value:\n",
    "\n",
    "$$z_{0.99} = 2.5758$$\n",
    "\n",
    "The margin of error is then given by:\n",
    "\n",
    "$$\\epsilon = z_{0.99} \\times SE = 0.0613$$\n",
    "\n",
    "CI of 99% for accuracy:\n",
    "$$\\begin{array}{l}\\hat{p} - z_{\\alpha/2}\\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}} = 0.87 - 0.0613 = 0.809\\\\ \\hat{p} + z_{\\alpha/2}\\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}} =  0.87 + 0.0613 = 0.931\\end{array}$$\n",
    "\n",
    "*Observation:*  Higher confidence â†’ Larger critical value â†’ Wider interval\n",
    "\n",
    "8. Decision making\n",
    "\n",
    "- Lower bound of 95% CI: 82.3% \n",
    "- Required accuracy: 85%\n",
    "    \n",
    "As the lower bound is below the required accuracy, the deployment is risky. The model doesn't meet the requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502a80d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200\n",
    "success = 174\n",
    "conf = 0.95\n",
    "\n",
    "p_hat = success/n\n",
    "print(f\"Estimator: {p_hat}\")\n",
    "se = np.sqrt(p_hat * (1 - p_hat) / n)\n",
    "print(f\"Standard error: {se}\")\n",
    "z_c = stats.norm.interval(confidence=conf)[1]\n",
    "print(f\"Critical value (95%): {z_c}\")\n",
    "margin_error = z_c * se\n",
    "print(f\"Margin of error: {margin_error}\")\n",
    "lower = p_hat - margin_error\n",
    "upper = p_hat + margin_error  \n",
    "print(f\"95% CI for accuracy: [{lower:.3f}; {upper:.3f}]\")\n",
    "\n",
    "print(\"\\nn=200 -> n=2000\")\n",
    "n_2000 = 2000\n",
    "p_hat_2000 = success*10/n_2000\n",
    "print(f\"Estimator: {p_hat_2000}\")\n",
    "se_2000 = np.sqrt(p_hat_2000 * (1 - p_hat_2000) / n_2000)\n",
    "print(f\"Standard error: {se}\")\n",
    "z_c = stats.norm.interval(confidence=conf)[1]\n",
    "print(f\"Critical value (95%): {z_c}\")\n",
    "margin_error_2000 = z_c * se_2000\n",
    "print(f\"Margin of error: {margin_error_2000}\")\n",
    "lower_2000 = p_hat_2000 - margin_error_2000\n",
    "upper_2000 = p_hat_2000 + margin_error_2000  \n",
    "print(f\"95% CI for accuracy: [{lower_2000:.3f}; {upper_2000:.3f}]\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n95% -> 99%\")\n",
    "z_99 = stats.norm.interval(confidence=0.99)[1]\n",
    "print(f\"Critical value (99%): {z_99}\")\n",
    "margin_error_99 = z_99 * se\n",
    "print(f\"Margin of error: {margin_error_99}\")\n",
    "lower_99 = p_hat - margin_error_99\n",
    "upper_99 = p_hat + margin_error_99  \n",
    "print(f\"95% CI for accuracy: [{lower_99:.3f}; {upper_99:.3f}]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3938cef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_ci_spam_detection():\n",
    "    \"\"\"Visualisation for spam detection CI exercise\"\"\"\n",
    "        \n",
    "    # Given data\n",
    "    n = 200\n",
    "    n_correct = 174\n",
    "    p_hat = n_correct / n\n",
    "    confidence_level = 0.95\n",
    "    alpha = 1 - confidence_level\n",
    "    \n",
    "    # standard error\n",
    "    se = np.sqrt(p_hat * (1 - p_hat) / n)\n",
    "    # critical value\n",
    "    z_critical = stats.norm.ppf(1 - alpha/2)\n",
    "    # margin of error\n",
    "    margin = z_critical * se\n",
    "    # confidence interval \n",
    "    ci_lower = p_hat - margin\n",
    "    ci_upper = p_hat + margin\n",
    "    \n",
    "    # required accuracy for decision making    \n",
    "    required_accuracy = 0.85\n",
    "    \n",
    "    if ci_lower >= required_accuracy:\n",
    "        decision = \"YES âœ“\"\n",
    "        reason = f\"Even at the lower bound ({ci_lower:.1%}), we meet requirements\"\n",
    "    else:\n",
    "        decision = \"RISKY\"\n",
    "        reason = f\"Lower bound ({ci_lower:.1%}) is below requirement ({required_accuracy:.0%})\"\n",
    "    \n",
    "    # What sample size would we need?\n",
    "    # ME = z * sqrt(p(1-p)/n)\n",
    "    # We want: p - ME >= required_accuracy\n",
    "    # ME <= p - required_accuracy\n",
    "    # z * sqrt(p(1-p)/n) <= p - required_accuracy\n",
    "    # n >= z^2 * p(1-p) / (p - required_accuracy)^2\n",
    "    \n",
    "    desired_margin = p_hat - required_accuracy\n",
    "    n_needed = (z_critical**2 * p_hat * (1-p_hat)) / (desired_margin**2)\n",
    "        \n",
    "    # Visualization\n",
    "    fig = plt.figure(figsize=(18, 12))\n",
    "    gs = fig.add_gridspec(3, 2, hspace=0.4, wspace=0.3)\n",
    "    \n",
    "    # Plot 1: Sampling distribution with CI\n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    \n",
    "    p_range = np.linspace(p_hat - 4*se, p_hat + 4*se, 500)\n",
    "    sampling_dist = stats.norm.pdf(p_range, p_hat, se)\n",
    "    \n",
    "    ax1.plot(p_range, sampling_dist, 'b-', linewidth=3, label='Sampling distribution')\n",
    "    \n",
    "    # Shade CI\n",
    "    ci_range = p_range[(p_range >= ci_lower) & (p_range <= ci_upper)]\n",
    "    ci_density = stats.norm.pdf(ci_range, p_hat, se)\n",
    "    ax1.fill_between(ci_range, 0, ci_density, alpha=0.3, color='green',\n",
    "                     label='95% CI region')\n",
    "    \n",
    "    # Mark important values\n",
    "    ax1.axvline(p_hat, color='blue', linewidth=3, linestyle='-',\n",
    "               label=f'Sample accuracy: {p_hat:.1%}')\n",
    "    ax1.axvline(ci_lower, color='red', linewidth=2, linestyle='--',\n",
    "               label=f'Lower bound: {ci_lower:.1%}')\n",
    "    ax1.axvline(ci_upper, color='red', linewidth=2, linestyle='--',\n",
    "               label=f'Upper bound: {ci_upper:.1%}')\n",
    "    \n",
    "    if required_accuracy > 0:\n",
    "        ax1.axvline(required_accuracy, color='purple', linewidth=3, linestyle=':',\n",
    "                   label=f'Required: {required_accuracy:.0%}')\n",
    "    \n",
    "    ax1.set_xlabel('Accuracy', fontsize=12)\n",
    "    ax1.set_ylabel('Density', fontsize=12)\n",
    "    ax1.set_title(f'95% Confidence Interval for Spam Detection Accuracy\\n' +\n",
    "                  f'Sample: {n} emails, {n_correct} correct, Accuracy: {p_hat:.1%} Â± {margin:.1%}',\n",
    "                  fontsize=14, fontweight='bold')\n",
    "    ax1.legend(fontsize=11, loc='upper right')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Different confidence levels\n",
    "    ax2 = fig.add_subplot(gs[1, 0])\n",
    "    \n",
    "    for conf, color in zip([0.90, 0.95, 0.99], ['blue', 'green', 'red']):\n",
    "        alpha_temp = 1 - conf\n",
    "        z_temp = stats.norm.ppf(1 - alpha_temp/2)\n",
    "        me_temp = z_temp * se\n",
    "        lower_temp = p_hat - me_temp\n",
    "        upper_temp = p_hat + me_temp\n",
    "        \n",
    "        ax2.barh([conf], [upper_temp - lower_temp], left=[lower_temp],\n",
    "                height=0.02, alpha=0.6, color=color,\n",
    "                label=f'{conf:.0%} CI: [{lower_temp:.3f}, {upper_temp:.3f}]')\n",
    "    \n",
    "    ax2.axvline(p_hat, color='black', linewidth=3, linestyle='-',\n",
    "               label=f'Sample: {p_hat:.3f}')\n",
    "    \n",
    "    ax2.set_xlabel('Accuracy', fontsize=12)\n",
    "    ax2.set_ylabel('Confidence Level', fontsize=12)\n",
    "    ax2.set_title('CIs for Different Confidence Levels\\n(Higher confidence â†’ wider interval)',\n",
    "                 fontsize=13, fontweight='bold')\n",
    "    ax2.legend(fontsize=10)\n",
    "    ax2.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Plot 3: Sample size effect\n",
    "    ax3 = fig.add_subplot(gs[1, 1])\n",
    "    \n",
    "    n_range = np.arange(50, 2501, 50)\n",
    "    margins = [z_critical * np.sqrt(p_hat * (1-p_hat) / n_val) for n_val in n_range]\n",
    "    \n",
    "    ax3.plot(n_range, margins, 'g-', linewidth=3)\n",
    "    ax3.scatter([n], [margin], s=300, color='red', marker='*',\n",
    "               edgecolors='darkred', linewidths=2, zorder=5,\n",
    "               label=f'Current: n={n}')\n",
    "    \n",
    "    ax3.set_xlabel('Sample Size (n)', fontsize=12)\n",
    "    ax3.set_ylabel('Margin of Error', fontsize=12)\n",
    "    ax3.set_title('Effect of Sample Size on Precision\\n(Margin decreases as âˆšn)',\n",
    "                 fontsize=13, fontweight='bold')\n",
    "    ax3.legend(fontsize=11)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Decision framework\n",
    "    ax4 = fig.add_subplot(gs[2, :])\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    decision_text = f\"\"\"\n",
    "    DECISION FRAMEWORK\n",
    "    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•    \n",
    "    TEST RESULTS:\n",
    "    â€¢ Sample size: n = {n} emails\n",
    "    â€¢ Correct classifications: {n_correct}\n",
    "    â€¢ Sample accuracy: {p_hat:.1%}\n",
    "    â€¢ 95% CI: [{ci_lower:.1%}, {ci_upper:.1%}]\n",
    "    â€¢ Margin of error: Â±{margin:.1%}    \n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    \n",
    "    BUSINESS REQUIREMENT:\n",
    "    â€¢ Minimum accuracy: {required_accuracy:.0%}    \n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    ANALYSIS:\n",
    "    â€¢ Point estimate ({p_hat:.1%}) exceeds requirement âœ“\n",
    "    â€¢ Lower CI bound ({ci_lower:.1%}) {'â‰¥' if ci_lower >= required_accuracy else '<'} requirement {'âœ“' if ci_lower >= required_accuracy else 'âœ—'}\n",
    "    \n",
    "    DECISION: {decision}\n",
    "    \n",
    "    REASONING: {reason}    \n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    \n",
    "    RECOMMENDATIONS:\n",
    "    \n",
    "    1. CONSERVATIVE APPROACH (Recommended):\n",
    "       Use lower bound of CI for decisions\n",
    "       â†’ Protects against worst-case (with 95% confidence)\n",
    "    \n",
    "    2. IF DEPLOYING:\n",
    "       â€¢ Set monitoring alerts at {ci_lower:.1%}\n",
    "       â€¢ Expect performance in range [{ci_lower:.1%}, {ci_upper:.1%}]\n",
    "       â€¢ Re-evaluate if accuracy drops below {ci_lower:.1%}\n",
    "    \n",
    "    3. TO INCREASE CONFIDENCE:\n",
    "       â€¢ Collect more data (target: n â‰¥ {np.ceil(n_needed):.0f})\n",
    "       â€¢ This will narrow CI and reduce uncertainty    \n",
    "    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    \"\"\"\n",
    "    \n",
    "    ax4.text(0.5, 0.1, decision_text, fontsize=9, family='monospace',\n",
    "            verticalalignment='center', horizontalalignment='center',\n",
    "            bbox=dict(boxstyle='round', facecolor='lightcyan', alpha=0.4))\n",
    "    \n",
    "    plt.suptitle('Spam Detection: Complete CI Analysis & Decision Framework',\n",
    "                fontsize=16, fontweight='bold')\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'n': n,\n",
    "        'p_hat': p_hat,\n",
    "        'ci_lower': ci_lower,\n",
    "        'ci_upper': ci_upper,\n",
    "        'margin': margin,\n",
    "        'meets_requirement': ci_lower >= required_accuracy\n",
    "    }\n",
    "\n",
    "# Run solution\n",
    "results = viz_ci_spam_detection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a598487",
   "metadata": {},
   "source": [
    "## Confidence Interval for the Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5134dd6e",
   "metadata": {},
   "source": [
    "What about variance?\n",
    "- How much variability is in our data?\n",
    "- Is our model's performance consistent?\n",
    "- What's the uncertainty in our variance estimate?\n",
    "\n",
    "**Setup:**\n",
    "- Sample: $X_1, X_2, ..., X_n$\n",
    "- Sample proportion: $\\hat{p}$\n",
    "- Sample size $n$\n",
    "- Population variance $\\sigma^2$ is unknown\n",
    "- Sample standard deviation: $s$\n",
    "- Population variance estimator: $\\hat{\\sigma}^2 = s^2$\n",
    "\n",
    "**Want**: CI for population variance $\\sigma^2$\n",
    "\n",
    "\n",
    "Here's a workflow to find a confidence interval for population variance:\n",
    "\n",
    "<center>\n",
    "<img  src=\"img/ci-variance-workflow.png\" width=\"800px\" alt=\"Workflow for CI for Variance\">\n",
    "</center>\n",
    "</br>\n",
    "\n",
    "The shaded region corresponds to the confidence level $\\beta$:\n",
    "\n",
    "<center>\n",
    "<img src=\"img/chi2-0.png\" width=\"600px\" alt=\"Asymmetric intervals\">\n",
    "</center>\n",
    "\n",
    "**Note: ASYMMETRIC interval**\n",
    "- Lower bound uses UPPER chi-square critical value\n",
    "- Upper bound uses LOWER chi-square critical value\n",
    "\n",
    "<center>\n",
    "<img src=\"img/chi2-1.png\" width=\"600px\" alt=\"Asymmetric intervals\">\n",
    "</center>\n",
    "\n",
    "<center>\n",
    "<img src=\"img/chi2-2.png\" width=\"600px\" alt=\"Asymmetric intervals\">\n",
    "</center>\n",
    "\n",
    "Upper critical value $\\chi_{\\nu; \\alpha/2}^2$:\n",
    "<center>\n",
    "<img src=\"img/chi2-3.png\" width=\"600px\" alt=\"Asymmetric intervals\">\n",
    "</center>\n",
    "\n",
    "Lower critical value $\\chi_{\\nu;1-\\alpha/2}^2$:\n",
    "<center>\n",
    "<img src=\"img/chi2-4.png\" width=\"600px\" alt=\"Asymmetric intervals\">\n",
    "</center>\n",
    "\n",
    "This is because:\n",
    "- Variance can't be negative\n",
    "- Large values are more likely than small values\n",
    "- $\\chi^2$ is right-skewed\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb375a5e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4>Formula: CI for Variance</h4>\n",
    "\n",
    "$$\\frac{\\nu s^2}{\\chi_{\\nu; \\alpha/2}^2}\\leq \\sigma^2 \\leq \\frac{\\nu s^2}{\\chi_{\\nu; 1-\\alpha/2}^2}$$\n",
    "\n",
    "</div>\n",
    "\n",
    "> What is $\\chi_{\\nu; \\alpha/2}$ and $\\chi_{\\nu; 1-\\alpha/2}$?</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b42743b",
   "metadata": {},
   "source": [
    "### $\\chi^2$ Distribution "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa84aa60",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4>Definition: Chi-Squared Distribution</h4>\n",
    "\n",
    "**$\\chi^2$-distribution** with $k$ degrees of freedom is the distribution of a sum of the squares of $k$ independent standard normal random variables.\n",
    "\n",
    "If $Z_1, Z_2, ..., Z_k$ are independent, standard normal random variables, then the sum of their squares $$X = \\sum_{i=1}^k Z_i^2 \\sim \\chi_{\\nu=k}^2$$\n",
    "\n",
    "Its PDF is given by:\n",
    "\n",
    "$$f(x, k) = \\left\\{ \\begin{array}{ll} \\frac{x^{k/2 - 1} e^{-x/2}}{2^{k/2}\\Gamma(\\frac{k}{2})}, & x > 0\\\\ 0, & otherwise \\end{array} \\right.$$\n",
    "\n",
    "where $\\Gamma\\bigg(\\frac{k}{2}\\bigg)$ is the gamma function.\n",
    "\n",
    "\n",
    "*Intuition:*\n",
    "- Sum of squared normal variables\n",
    "- Always positive (squares are always â‰¥ 0)\n",
    "- Right-skewed (can't be negative, but can be large)\n",
    "\n",
    "For a sample from $N(\\mu, \\sigma^2)$:\n",
    "the statistic $\\frac{(n - 1)s^2}{\\sigma^2} \\sim \\chi_{\\nu=(n-1)}^2$, where $n$ is the sample size, $s^2$ is sample variance, $\\sigma^2$ is true population variance. This is why we use $\\chi^2$ for inference about variance.\n",
    "\n",
    "**Key properties:**\n",
    "1. Shape:\n",
    "   - Right-skewed (**not symmetric**)\n",
    "   - Always positive (domain: $[0, \\infty)$)\n",
    "   - Approaches normal as df increases\n",
    "\n",
    "2. Parameters:\n",
    "   - Only ONE parameter: degrees of freedom ($df$ or $k$)\n",
    "   - Denoted: $\\chi^2(k)$ or $\\chi^2_k$\n",
    "\n",
    "3. Mean and Variance:\n",
    "   - $Mean = k$ (degrees of freedom)\n",
    "   - $Variance = 2k$\n",
    "   - Standard deviation = $\\sqrt{2k}$\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd3c086",
   "metadata": {},
   "source": [
    "> Degrees of Freedom: What Effect? </br>\n",
    "\n",
    "- Small $df$: Very skewed, peak near 0\n",
    "- Medium $df$: Moderately skewed\n",
    "- Large $df$: Nearly symmetric (approaches normal)\n",
    "\n",
    "<center>\n",
    "<img src=\"img/chi-2.png\" width=\"600px\" alt=\"Chi-squared distribution\">\n",
    "</center>\n",
    "\n",
    "> Degrees of Freedom: Why $\\nu = n - 1$? </br>\n",
    "\n",
    "For sample variance $s^2$: $df = n - 1$:\n",
    "- We use $\\bar{X}$ to compute $s^2$\n",
    "- This 'uses up' one degree of freedom\"\n",
    "- Same reason as for $t$-distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702a4bf0",
   "metadata": {},
   "source": [
    "| Property | Normal | $t$ | $\\chi^2$ |\n",
    "|---:|:---:|:---:|:---:|\n",
    "| **Symmetry**    | Symmetric    | Symmetric    | Right-skewed |\n",
    "| **Domain**      | $(-\\infty, \\infty)$      | $(-\\infty, \\infty)$      | $[0, \\infty)$       |\n",
    "| **Parameters**  | $\\mu$, $\\sigma$         | $df$           | $df$           |\n",
    "| **Used for**    | Mean ($\\sigma$ known) and Proportion | Mean ($\\sigma$ unknown) | Variance     |\n",
    "| **Shape vs df** | N/A          | Converges    | Converges |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9267b1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation\n",
    "chi_2_distribution_viz()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1bc644",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d0674fc",
   "metadata": {},
   "source": [
    "You can use [`scipy.stats.chi2`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e9a188",
   "metadata": {},
   "source": [
    "## Finding CI for Variance using $\\chi^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3f1efc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-exercise\">\n",
    "<h4>Calculated Example: CI for Variance</h4>\n",
    "\n",
    "A data scientist is evaluating the consistency of a neural network's confidence scores for spam detection. From 15 test batches, the variance in predicted probabilities for legitimate emails is $s^2 = 3.4$. Find the 95% confidence interval for the true variance in confidence scores across all legitimate emails.\n",
    "\n",
    "<h5>Solution:</h5>\n",
    "\n",
    "What is known: $n = 15$, $\\beta = 0.95$, $s^2 = 3.4$.\n",
    "\n",
    "Hence:\n",
    "\n",
    "$$\\nu = n - 1 = 15 - 1 = 14$$\n",
    "\n",
    "$$\\alpha = 1 - \\beta = 1 - 0.95 = 0.05 \\Rightarrow \\begin{array}{l}\\alpha/2 = 0.025\\\\1 - \\alpha/2 = 1 - 0.025 = 0.975\\end{array}$$\n",
    "\n",
    "$$\\begin{array}{l}\\chi_{\\nu; \\alpha/2}^2 = \\chi_{14; 0.025}^2 = 26.12 \\\\\\chi_{\\nu; 1-\\alpha/2}^2 = \\chi_{14; 0.975}^2 = 5.63\\end{array}$$\n",
    "\n",
    "Therefore, the 95% confidence CI is given by:\n",
    "\n",
    "$$\\frac{\\nu s^2}{\\chi_{\\nu; \\alpha/2}^2}\\leq \\sigma^2 \\leq \\frac{\\nu s^2}{\\chi_{\\nu; 1-\\alpha/2}^2}$$\n",
    "\n",
    "$$\\frac{14\\times 3.4}{26.12}\\leq \\sigma^2 \\leq \\frac{14 \\times 3.4}{5.63}$$\n",
    "\n",
    "$$1.82 \\leq \\sigma^2 \\leq 8.46$$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feac8d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 15 \n",
    "df = n - 1\n",
    "conf = 0.95\n",
    "# OPTION 1\n",
    "stats.chi2.interval(confidence=conf, df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba0c690",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1 - conf\n",
    "# OPTION 2\n",
    "chi2_lower = stats.chi2.ppf(alpha/2, df=df)\n",
    "chi2_upper = stats.chi2.ppf(1 - alpha/2, df=df)\n",
    "print(f\"Chi-2 lower: {chi2_lower}\")\n",
    "print(f\"Chi-2 upper: {chi2_upper}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d3e884",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-primary\">\n",
    "<h4>ðŸ¤– ML Applications</h4>\n",
    "\n",
    "- Model stability assessment\n",
    "- Risk quantification\n",
    "- Quality control (performance variability)\n",
    "- Outlier detection thresholds\n",
    "- Uncertainty estimation\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c8b33b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-exercise\">\n",
    "<h4>QUESTION: Finding Sample Size</h4>\n",
    "\n",
    "A product team is evaluating whether to deploy a new recommendation algorithm to production. Initial testing shows that approximately 78% of users click on at least one recommended item. To build a 98% confidence interval with a margin of error of 5% for the true click-through rate, how many user sessions should be included in the A/B test?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bd8534",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50fd97c7",
   "metadata": {},
   "source": [
    "## Constructing Confidence Intervals: The Pivot Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837a22c3",
   "metadata": {},
   "source": [
    "All the CIs we've seen follow the same general approach called the **pivot method**:\n",
    "\n",
    "1. Find a **pivot**: a function of data and parameter with known distribution\n",
    "2. Use the pivot to \"invert\" and isolate the parameter\n",
    "\n",
    "**Examples:**\n",
    "\n",
    "- **For mean** ($t$-distribution): $Pivot = (\\bar{X} - \\mu)/(s/\\sqrt{n}) \\sim t(n-1)$\n",
    "  â†’ Leads to: $CI = \\bar{X} \\pm t(\\alpha/2) \\times s/\\sqrt{n}$\n",
    "\n",
    "- **For proportion** (normal distribution): $Pivot = (\\hat{p} - p)/SE \\approx N(0,1)$ \n",
    "  â†’ Leads to: $CI = \\hat{p} \\pm z(\\alpha/2) \\times SE$\n",
    "\n",
    "- **For variance** ($\\chi^2-distribution$): $Pivot = (n-1)s^2/\\sigma^2 \\sim \\chi^2(n-1)$\n",
    "  â†’ Leads to: $CI = [(n-1)s^2/\\chi^2_{\\alpha/2}, (n-1)s^2/\\chi^2_{1-\\alpha/2}]$\n",
    "\n",
    "**Key insight:** The pivot's distribution doesn't depend on the unknown parameter - that's what makes this work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87084ae",
   "metadata": {},
   "source": [
    "## Bootstrap CI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdf08b5",
   "metadata": {},
   "source": [
    "What if:\n",
    "\n",
    "- You don't know the distribution?\n",
    "- No closed-form formula exists?\n",
    "- Sample size is too small for CLT?\n",
    "- You're estimating a complex statistic (median, 90th percentile, etc.)?\n",
    "\n",
    "**Solution: BOOTSTRAP**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fea1286",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4>Definition: CI using Bootstrap</h4>\n",
    "\n",
    "**Core idea**: \"The sample approximates the population\"\n",
    "\n",
    "1. Resample from your data (with replacement) using bootstrap\n",
    "2. Compute statistic $\\hat{\\theta}^*$ on each resample\n",
    "3. Repeat a certain number of times (e.g. $n_{boot} = 10,000$). Recommendation: $n_{boot} \\geq 5,000$ for percentile method and $n_{boot} \\geq 1,000$ for normal bootstrap\n",
    "3. Use distribution of resampled statistics to build CI:\n",
    "    - *Percentile method*:\n",
    "        * Core idea: \"If I have 10,000 bootstrap estimates, the middle 95% of those values form my 95% CI\" \n",
    "        * Sort all bootstrap statistics\n",
    "        * For (1-Î±)% CI, take the Î±/2 and (1-Î±/2) percentiles\n",
    "        $$CI = [\\hat{\\theta}^*_{\\alpha/2}, \\hat{\\theta}^*_{1 - \\alpha/2}]$$\n",
    "        where $\\hat{\\theta}^*_{\\alpha/2} = (\\alpha/2)\\times 100th$ percentile of bootstrap distribution\n",
    "    - *Normal approximation to bootstrap* (assumes the bootstrap distribution is approximately normal, i.e. $(\\hat{\\theta} - \\theta) / SE_{boot} \\sim \\mathcal{N}(0,1)$ ):\n",
    "        * Core idea: \"Use bootstrap to estimate standard error, then construct CI using normal critical values (like traditional parametric CI)\"\n",
    "        * Estimate standard error from bootstrap distribution: $SE_{boot} = SD(\\hat{\\theta}^*)$\n",
    "        * Use original sample statistic $\\hat{\\theta}$ and normal critical values\n",
    "        $$CI = \\hat{\\theta} \\pm z(\\alpha/2) \\times SE_{boot}$$\n",
    "        where: $\\hat{\\theta}$ = statistic from original sample, $z(\\alpha/2)$ = normal critical value (e.g., 1.96 for 95%), $SE_{boot} = \\sqrt{\\sum_{i}^{n_{boot}}(\\hat{\\theta}^*_i - mean(\\hat{\\theta}^*))^2 / (n_{boot}-1)}$ = standard deviation of bootstrap statistics\n",
    "\n",
    "</div>\n",
    "\n",
    "| | Percentile method | Normal approximation |\n",
    "|---|---|---|\n",
    "|Advantages| - Simple and intuitive - no complicated formulas </br> - Distribution-free - no normality assumption </br> - Automatically handles skewness - CI can be asymmetric </br> - Works for any statistic - median, percentiles, etc. </br> - Captures the actual bootstrap distribution shape | - Requires fewer bootstrap samples ($n_{boot} = 1,000$ often sufficient) </br> - Familiar form - looks like traditional CI </br> - Theoretically justified when CLT applies </br> - Computationally efficient - only need to estimate SE </br> - More stable for small $n_{boot}$ than percentile method |\n",
    "|Disadvantages| - Requires many bootstrap samples ($n_{boot} \\geq 5,000$ recommended) </br> - Can be unstable for small $n_{boot}$ or extreme percentiles </br> - May be too liberal (under-cover) for small samples </br> - Sensitive to outliers in original data | - Assumes normality - may be inappropriate for skewed distributions </br> - Always symmetric - can't capture asymmetry </br> - May perform poorly for highly skewed statistics </br> - Ignores shape of bootstrap distribution </br> - Can give impossible values (e.g., negative variance)|\n",
    "|When to Use| - Your statistic's distribution is unknown or complex </br> - You expect the distribution to be skewed or asymmetric </br> - You have sufficient bootstrap samples ($n_{boot} \\geq 5,000$) </br> - Default choice for most applications | - You believe the statistic is approximately normally distributed</br> - The sample size is large (CLT applies) </br> - You want computational efficiency (smaller $n_{boot}$) </br> - The bootstrap distribution appears roughly symmetric </br> - You're working with means or sums (CLT applies) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff81c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_percentile_ci(data, statistic_func, n_bootstrap=10000, confidence=0.95):\n",
    "    \"\"\"\n",
    "    Calculate bootstrap CI using percentile method\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : array-like\n",
    "        Original data sample\n",
    "    statistic_func : function\n",
    "        Function to compute statistic (e.g., np.mean, np.median)\n",
    "    n_bootstrap : int\n",
    "        Number of bootstrap samples\n",
    "    confidence : float\n",
    "        Confidence level (e.g., 0.95 for 95% CI)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    ci_lower, ci_upper : float\n",
    "        Lower and upper confidence bounds\n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "    bootstrap_statistics = []\n",
    "    \n",
    "    # Generate bootstrap samples\n",
    "    for _ in range(n_bootstrap):\n",
    "        # Resample with replacement\n",
    "        bootstrap_sample = np.random.choice(data, size=n, replace=True)\n",
    "        # Calculate statistic on this bootstrap sample\n",
    "        bootstrap_stat = statistic_func(bootstrap_sample)\n",
    "        bootstrap_statistics.append(bootstrap_stat)\n",
    "    \n",
    "    # Convert to array\n",
    "    bootstrap_statistics = np.array(bootstrap_statistics)\n",
    "    \n",
    "    # Calculate percentiles\n",
    "    alpha = 1 - confidence\n",
    "    ci_lower = np.percentile(bootstrap_statistics, 100 * alpha/2)\n",
    "    ci_upper = np.percentile(bootstrap_statistics, 100 * (1 - alpha/2))\n",
    "    \n",
    "    return ci_lower, ci_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b541b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_normal_ci(data, statistic_func, n_bootstrap=1000, confidence=0.95):\n",
    "    \"\"\"\n",
    "    Calculate bootstrap CI using normal approximation method\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : array-like\n",
    "        Original data sample\n",
    "    statistic_func : function\n",
    "        Function to compute statistic (e.g., np.mean, np.median)\n",
    "    n_bootstrap : int\n",
    "        Number of bootstrap samples\n",
    "    confidence : float\n",
    "        Confidence level (e.g., 0.95 for 95% CI)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    ci_lower, ci_upper : float\n",
    "        Lower and upper confidence bounds\n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "    \n",
    "    # Calculate statistic on original sample\n",
    "    original_stat = statistic_func(data)\n",
    "    \n",
    "    # Generate bootstrap samples\n",
    "    bootstrap_statistics = []\n",
    "    for _ in range(n_bootstrap):\n",
    "        bootstrap_sample = np.random.choice(data, size=n, replace=True)\n",
    "        bootstrap_stat = statistic_func(bootstrap_sample)\n",
    "        bootstrap_statistics.append(bootstrap_stat)\n",
    "    \n",
    "    # Convert to array\n",
    "    bootstrap_statistics = np.array(bootstrap_statistics)\n",
    "    \n",
    "    # Estimate standard error from bootstrap distribution\n",
    "    se_boot = np.std(bootstrap_statistics, ddof=1)\n",
    "    \n",
    "    # Get normal critical value\n",
    "    from scipy import stats\n",
    "    alpha = 1 - confidence\n",
    "    z_critical = stats.norm.ppf(1 - alpha/2)\n",
    "    \n",
    "    # Construct symmetric CI\n",
    "    ci_lower = original_stat - z_critical * se_boot\n",
    "    ci_upper = original_stat + z_critical * se_boot\n",
    "    \n",
    "    return ci_lower, ci_upper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd4e800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "data = np.array([45.2, 48.1, 43.8, 46.5, 44.9, 47.3, 45.8])\n",
    "\n",
    "# CI for mean\n",
    "mean_lower_perc, mean_upper_perc = bootstrap_percentile_ci(data, np.mean, n_bootstrap=10000, confidence=0.95)\n",
    "print(f\"95% CI for mean (percentile): [{mean_lower_perc:.2f}, {mean_upper_perc:.2f}]\")\n",
    "\n",
    "mean_lower_norm, mean_upper_norm = bootstrap_normal_ci(data, np.mean, n_bootstrap=1000, confidence=0.95)\n",
    "print(f\"95% CI for mean (normal): [{mean_lower_norm:.2f}, {mean_upper_norm:.2f}]\")\n",
    "\n",
    "# CI for median\n",
    "median_lower_perc, median_upper_perc = bootstrap_percentile_ci(data, np.median, n_bootstrap=10000, confidence=0.95)\n",
    "print(f\"95% CI for median (percentile): [{median_lower_perc:.2f}, {median_upper_perc:.2f}]\")\n",
    "\n",
    "median_lower_norm, median_upper_norm = bootstrap_normal_ci(data, np.median, n_bootstrap=1000, confidence=0.95)\n",
    "print(f\"95% CI for median (normal): [{median_lower_norm:.2f}, {median_upper_norm:.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92617988",
   "metadata": {},
   "source": [
    "Let's consider the following scenario on **Prediction Errors from a Model**: \n",
    "\n",
    "We analyse the data coming from a skewed distribution. We have a sample of 50 measures with the following statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917fc455",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Original data (e.g., model errors)\n",
    "# Skewed distribution - not normal\n",
    "true_data = np.concatenate([\n",
    "        np.random.exponential(2, 70),  # Most errors small\n",
    "        np.random.exponential(10, 30)   # Some errors large\n",
    "    ])\n",
    "\n",
    "n = 50 # sample size\n",
    "\n",
    "original_sample = np.random.choice(true_data, size=n, replace=False)\n",
    "\n",
    "print(f\"Sample size: n = {len(original_sample)}\")\n",
    "print(f\"Sample median error: {np.median(original_sample):.2f}\")\n",
    "print(f\"Sample mean error: {np.mean(original_sample):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0899e5",
   "metadata": {},
   "source": [
    "We would like to create a CI for the MEDIAN. There is no predefined formula. Moreover, the distribution is skewed (not normal). Standard methods don't apply. \n",
    "\n",
    "*Solution*: bootstrap\n",
    "\n",
    "STEPS:\n",
    "\n",
    "1. Resample n=50 original values WITH replacement from original sample\n",
    "2. Compute median of resample\n",
    "3. Repeat large number of times\n",
    "4. Use distribution of bootstrap medians to build CI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6c0074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_bootstrap_ci():\n",
    "    \"\"\"Complete bootstrap demonstration\"\"\"\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Original data (e.g., model errors)\n",
    "    # Skewed distribution - not normal!\n",
    "    true_data = np.concatenate([\n",
    "        np.random.exponential(2, 70),  # Most errors small\n",
    "        np.random.exponential(10, 30)   # Some errors large\n",
    "    ])\n",
    "\n",
    "    original_sample = np.random.choice(true_data, size=50, replace=False)\n",
    "\n",
    "    # Bootstrap procedure\n",
    "    n_bootstrap = 10000\n",
    "    bootstrap_medians = []\n",
    "    bootstrap_means = []\n",
    "\n",
    "    # Perform bootstrap\n",
    "    for _ in range(n_bootstrap):\n",
    "        bootstrap_sample = np.random.choice(original_sample, size=len(original_sample), replace=True)\n",
    "        bootstrap_medians.append(np.median(bootstrap_sample))\n",
    "        bootstrap_means.append(np.mean(bootstrap_sample))\n",
    "\n",
    "    bootstrap_medians = np.array(bootstrap_medians)\n",
    "    bootstrap_means = np.array(bootstrap_means)\n",
    "\n",
    "    # Compute CIs using different methods\n",
    "    conf = 0.95 # confidence level\n",
    "    alpha = 1 - conf\n",
    "    alpha_05 = alpha / 2\n",
    "    \n",
    "    # Method 1: Percentile method (most common)\n",
    "    ci_median_percentile = np.percentile(bootstrap_medians, [alpha_05*100, (1 - alpha_05)*100])\n",
    "    ci_mean_percentile = np.percentile(bootstrap_means, [alpha_05*100, (1 - alpha_05)*100])\n",
    "\n",
    "    # Method 2: Normal approximation to bootstrap\n",
    "    median_estimate = np.median(original_sample)\n",
    "    mean_estimate = np.mean(original_sample)\n",
    "    se_median_boot = np.std(bootstrap_medians)\n",
    "    se_mean_boot = np.std(bootstrap_means)\n",
    "    z_crit = stats.norm.ppf(1 - alpha_05)\n",
    "\n",
    "    ci_median_normal = [median_estimate - z_crit * se_median_boot,\n",
    "                        median_estimate + z_crit * se_median_boot]\n",
    "    ci_mean_normal = [mean_estimate - z_crit * se_mean_boot,\n",
    "                    mean_estimate + z_crit * se_mean_boot]\n",
    "\n",
    "    print(\"RESULTS:\")\n",
    "    print(\"-\" * 80)\n",
    "    print()\n",
    "    print(\"FOR MEDIAN:\")\n",
    "    print(f\"  Original estimate:        {median_estimate:.2f}\")\n",
    "    print(f\"  Bootstrap SE:             {se_median_boot:.2f}\")\n",
    "    print(f\"  95% CI (percentile):      [{ci_median_percentile[0]:.2f}, {ci_median_percentile[1]:.2f}]\")\n",
    "    print(f\"  95% CI (normal approx):   [{ci_median_normal[0]:.2f}, {ci_median_normal[1]:.2f}]\")\n",
    "    print()\n",
    "    print(\"FOR MEAN (for comparison):\")\n",
    "    print(f\"  Original estimate:        {mean_estimate:.2f}\")\n",
    "    print(f\"  Bootstrap SE:             {se_mean_boot:.2f}\")\n",
    "    print(f\"  95% CI (percentile):      [{ci_mean_percentile[0]:.2f}, {ci_mean_percentile[1]:.2f}]\")\n",
    "    print(f\"  95% CI (normal approx):      [{ci_mean_normal[0]:.2f}, {ci_mean_normal[1]:.2f}]\")\n",
    "    print()\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Visualization\n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)\n",
    "\n",
    "    # Plot 1: Original data\n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    ax1.hist(original_sample, bins=20, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "    ax1.axvline(np.median(original_sample), color='red', linewidth=3, \n",
    "            label=f'Median = {np.median(original_sample):.2f}')\n",
    "    ax1.axvline(np.mean(original_sample), color='green', linewidth=3, linestyle='--',\n",
    "            label=f'Mean = {np.mean(original_sample):.2f}')\n",
    "    ax1.set_xlabel('Prediction Error', fontsize=12)\n",
    "    ax1.set_ylabel('Frequency', fontsize=12)\n",
    "    ax1.set_title('Original Sample (n=50)\\nSkewed distribution - not normal', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax1.legend(fontsize=11)\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "    # Plot 2: Bootstrap distribution for median\n",
    "    ax2 = fig.add_subplot(gs[1, 0])\n",
    "    ax2.hist(bootstrap_medians, bins=50, density=True, alpha=0.7, \n",
    "            color='orange', edgecolor='black')\n",
    "\n",
    "    # Add CI\n",
    "    ax2.axvline(ci_median_percentile[0], color='red', linewidth=3, linestyle='--',\n",
    "            label=f'95% CI: [{ci_median_percentile[0]:.2f}, {ci_median_percentile[1]:.2f}]')\n",
    "    ax2.axvline(ci_median_percentile[1], color='red', linewidth=3, linestyle='--')\n",
    "    ax2.axvline(median_estimate, color='darkred', linewidth=3,\n",
    "            label=f'Original median = {median_estimate:.2f}')\n",
    "\n",
    "    # Shade CI\n",
    "    ax2.axvspan(ci_median_percentile[0], ci_median_percentile[1], \n",
    "            alpha=0.2, color='green')\n",
    "\n",
    "    ax2.set_xlabel('Bootstrap Median', fontsize=12)\n",
    "    ax2.set_ylabel('Density', fontsize=12)\n",
    "    ax2.set_title(f'Bootstrap Distribution of MEDIAN\\n({n_bootstrap:,} resamples)', \n",
    "                fontsize=13, fontweight='bold')\n",
    "    ax2.legend(fontsize=10)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot 3: Bootstrap distribution for mean\n",
    "    ax3 = fig.add_subplot(gs[1, 1])\n",
    "    ax3.hist(bootstrap_means, bins=50, density=True, alpha=0.7, \n",
    "            color='green', edgecolor='black')\n",
    "\n",
    "    ax3.axvline(ci_mean_percentile[0], color='red', linewidth=3, linestyle='--',\n",
    "            label=f'95% CI: [{ci_mean_percentile[0]:.2f}, {ci_mean_percentile[1]:.2f}]')\n",
    "    ax3.axvline(ci_mean_percentile[1], color='red', linewidth=3, linestyle='--')\n",
    "    ax3.axvline(mean_estimate, color='darkgreen', linewidth=3,\n",
    "            label=f'Original mean = {mean_estimate:.2f}')\n",
    "\n",
    "    ax3.axvspan(ci_mean_percentile[0], ci_mean_percentile[1], \n",
    "            alpha=0.2, color='green')\n",
    "\n",
    "    ax3.set_xlabel('Bootstrap Mean', fontsize=12)\n",
    "    ax3.set_ylabel('Density', fontsize=12)\n",
    "    ax3.set_title(f'Bootstrap Distribution of MEAN\\n({n_bootstrap:,} resamples)', \n",
    "                fontsize=13, fontweight='bold')\n",
    "    ax3.legend(fontsize=10)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.suptitle('Bootstrap Confidence Intervals', fontsize=16, fontweight='bold', y=0.98)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9217e279",
   "metadata": {},
   "outputs": [],
   "source": [
    "demonstrate_bootstrap_ci()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0d4eec",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<h4>ðŸ’¡ Key Insight: Bootstrap for CI: Advantages, Limitations, When to Use</h4>\n",
    "\n",
    "<h5>Bootstrap Method Advantages:</h5>\n",
    "\n",
    "1. Works for any statistic:\n",
    "- No formula needed\n",
    "- Median, percentiles, ratios, correlations, etc.\n",
    "- Even complex ML metrics (F1-score, AUC, etc.)\n",
    "\n",
    "2. No distribution assumptions:\n",
    "- Doesn't require normality\n",
    "- Works with skewed, multimodal data\n",
    "- Robust to outliers (if statistic is robust)\n",
    "\n",
    "3. Flexible:\n",
    "- Different CI methods available\n",
    "- Can adjust for bias\n",
    "- Easy to implement\n",
    "\n",
    "\n",
    "<h5>When to Use Bootstrap:</h5>\n",
    "\n",
    "- Estimating CI for complex statistics (median, 90th percentile, etc.)\n",
    "- Small samples where CLT doesn't apply\n",
    "- Non-normal data\n",
    "- When you don't know the theoretical distribution\n",
    "- Cross-validation error estimates\n",
    "- Ensemble model performance\n",
    "\n",
    "<h5>Limitations:</h5>\n",
    "\n",
    "- Computationally intensive (need many resamples)\n",
    "- Assumes sample represents population well\n",
    "- May underestimate CI width for very small $n$\n",
    "- Not a magic fix for bad data\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb646bb",
   "metadata": {},
   "source": [
    "## ML Pipeline with CIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecb3ea0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-problem\">\n",
    "<h4>Real-World Application: Production Model Deployment Decision</h4>\n",
    "\n",
    "**Business Context:**\n",
    "You're deploying a ML model to detect fraudulent transactions. The business requires:\n",
    "- Rigorous performance guarantees\n",
    "- Regulatory requirements for uncertainty quantification\n",
    "- High cost of false positives (customer friction) -> False Alarm Rate\n",
    "- High cost of false negatives (fraud losses)\n",
    "- Min recall 70% (Must detect at least 70% of fraud)\n",
    "- Maximum 10% false alarm rate 10%\n",
    "- At least, 30% precision \n",
    "    \n",
    "Business Metrics:\n",
    "- Fraud Detection Rate (*sensitivity*, fraction of relevant instances that were retrieved): $recall = \\frac{TP}{TP + FN}$\n",
    "- False Alarm Rate: $\\frac{FP}{FP + TN}$\n",
    "\n",
    "**Your Task:**\n",
    "1. Train a model ([`RandomForestClassifier`][https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html]) and evaluate on test set\n",
    "2. Compute CIs for precision and recall\n",
    "3. Use CIs to make deployment decision\n",
    "4. Create executive report with uncertainty quantification\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Apply CIs to real ML metrics\n",
    "- Make data-driven decisions with uncertainty\n",
    "- Communicate results to non-technical stakeholders\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5086332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(pos_class_rate=0.05, n_samples=5000):\n",
    "    \"\"\"\n",
    "    Generates data for fraud detection with 20 features. Two possible classes: fraud transaction and normal transaction.\n",
    "\n",
    "    Args:\n",
    "        pos_class_rate (float, optional): Positive class rate for binary classification. Defaults to 0.05.\n",
    "        n_samples (int, optional): Number of samples in the generated dataset\n",
    "\n",
    "    Returns:\n",
    "        X, y - feature values and target class\n",
    "    \"\"\"\n",
    "    from sklearn.datasets import make_classification\n",
    "    \n",
    "    # Generate synthetic fraud detection dataset\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Imbalanced dataset (fraud is rare)\n",
    "    X, y = make_classification(\n",
    "        n_samples=n_samples,\n",
    "        n_features=20,\n",
    "        n_informative=15,\n",
    "        n_redundant=5,\n",
    "        n_classes=2,\n",
    "        weights=[1-pos_class_rate, pos_class_rate],  \n",
    "        flip_y=0.01,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e687496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_val_split(train_size=0.7, test_size=0.5):\n",
    "    \"\"\"\n",
    "    Generates data for fraud detection. Performs train, val, test split. \n",
    "\n",
    "    Args:\n",
    "        train_size (float, optional): Train set size rate. Defaults to 0.7.\n",
    "        test_size (float, optional): Test set size rate from the remaining data after train split. Defaults to 0.5.\n",
    "\n",
    "    Returns:\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test\n",
    "    \"\"\"\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    # Imbalanced dataset (fraud is rare)\n",
    "    X, y = generate_data(pos_class_rate=0.05, n_samples=5000)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, test_size=1-train_size, random_state=42, stratify=y\n",
    "    )\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=test_size, random_state=42, stratify=y_temp\n",
    "    )\n",
    "    \n",
    "    print(f\"Dataset sizes:\")\n",
    "    print(f\"  Training:   {len(X_train):,} samples\")\n",
    "    print(f\"  Validation: {len(X_val):,} samples\")\n",
    "    print(f\"  Test:       {len(X_test):,} samples\")\n",
    "    print()\n",
    "    \n",
    "    print(f\"Class distribution (test set):\")\n",
    "    print(f\"  Legitimate: {np.sum(y_test == 0):,} ({np.mean(y_test == 0):.1%})\")\n",
    "    print(f\"  Fraud:      {np.sum(y_test == 1):,} ({np.mean(y_test == 1):.1%})\")\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ae4f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = train_test_val_split(train_size=0.7, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2020e481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_get_pred(X_train, y_train, X_val, y_val, X_test):\n",
    "    \"\"\"Trains RandomForestClassifier on the provided data and makes prediction for X_test.\n",
    "\n",
    "    Args:\n",
    "        X_train (_type_): X_train feature set used for training\n",
    "        y_train (_type_): y_train targets set used for training\n",
    "        X_val (_type_): validation feature set\n",
    "        y_val (_type_): validation target set\n",
    "        X_test (_type_): X test set used for prediction\n",
    "\n",
    "    Returns:\n",
    "        y_pred: class predictions for X_test\n",
    "        y_pred_proba: class probabilities for X_test\n",
    "    \"\"\"\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    # Train model\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        random_state=42,\n",
    "        class_weight='balanced'  # Handle imbalance\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "        \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    return model, y_pred, y_pred_proba\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177887f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_test, y_pred, y_pred_proba):\n",
    "    \"\"\"\n",
    "    Calculates accuracy-based metrics given y_test (true target values) and predicted values.\n",
    "    \"\"\"\n",
    "    \n",
    "    from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                                 f1_score, roc_auc_score, confusion_matrix,\n",
    "                                 classification_report, roc_curve)\n",
    "    \n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    print(\"Point Estimates (Test Set):\")\n",
    "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall:    {recall:.4f}\")\n",
    "    print(f\"  F1-Score:  {f1:.4f}\")\n",
    "    print(f\"  AUC-ROC:   {auc:.4f}\")\n",
    "    print()\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(f\"                 Predicted\")\n",
    "    print(f\"                 Legit    Fraud\")\n",
    "    print(f\"Actual Legit     {tn:<8d} {fp:<8d}\")\n",
    "    print(f\"Actual Fraud     {fn:<8d} {tp:<8d}\")\n",
    "    print()\n",
    "    \n",
    "    # Business metrics\n",
    "    fraud_detection_rate = recall\n",
    "    false_alarm_rate = fp / (fp + tn)\n",
    "    \n",
    "    print(\"Business Metrics:\")\n",
    "    print(f\"  Fraud Detection Rate: {fraud_detection_rate:.1%}\")\n",
    "    print(f\"  False Alarm Rate:     {false_alarm_rate:.1%}\")\n",
    "    \n",
    "    return accuracy, precision, recall, f1, auc, cm, fraud_detection_rate, false_alarm_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138fe28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model and get predictions \n",
    "model, y_pred, y_pred_proba = train_model_get_pred(X_train, y_train, X_val, y_val, X_test)    \n",
    "    \n",
    "    \n",
    "# Calculate metrics\n",
    "accuracy, precision, recall, f1, auc, cm, fraud_detection_rate, false_alarm_rate = calculate_metrics(y_test, y_pred, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a315f6b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-exercise\">\n",
    "<h4>QUESTION: Calculate Bootstrap Metrics</h4>\n",
    "\n",
    "Right a python function that calculates accuracy-based metrics in a bootstrap procedure. \n",
    "\n",
    "```\n",
    "def calculate_bootstrap_metrics(y_test, y_pred, y_pred_proba, n_bootstrap=5000):\n",
    "    \"\"\"\n",
    "    Calculates bootstrap metrics and returns a dictionary of values.\n",
    "    \n",
    "    Args:\n",
    "        y_test (np.array): true targets for test data\n",
    "        y_pred (np.array): predicted targets for test data\n",
    "        y_pred_proba (np.array): predicted class probabilities for test data\n",
    "        n_bootstrap (int, optional): number of bootstraps to perform. Defaults to 5000.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing the bootstrap values for accuracy, precision, recall, f1, auc, \n",
    "        fraud_detection_rate, false_alarm_rate\n",
    "    \"\"\"    \n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e356f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "def calculate_bootstrap_metrics(y_test, y_pred, y_pred_proba, n_bootstrap=5000):\n",
    "    \"\"\"\n",
    "    Calculates bootstrap metrics and returns a dictionary of values.\n",
    "    \n",
    "    Args:\n",
    "        y_test (np.array): true targets for test data\n",
    "        y_pred (np.array): predicted targets for test data\n",
    "        y_pred_proba (np.array): predicted class probabilities for test data\n",
    "        n_bootstrap (int, optional): number of bootstraps to perform. Defaults to 5000.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing the bootstrap values for accuracy, precision, recall, f1, auc, \n",
    "        fraud_detection_rate, false_alarm_rate\n",
    "    \"\"\"    \n",
    "    \n",
    "    from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                                 f1_score, roc_auc_score, confusion_matrix)\n",
    "    \n",
    "    \n",
    "    # Storage\n",
    "    bootstrap_metrics = {\n",
    "        'accuracy': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1': [],\n",
    "        'auc': [],\n",
    "        'fraud_detection_rate': [],\n",
    "        'false_alarm_rate': []\n",
    "    }\n",
    "    \n",
    "    # YOU CODE HERE\n",
    "        \n",
    "    return bootstrap_metrics\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb58eef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bootstrap = 5000\n",
    "confidence_level = 0.95\n",
    "    \n",
    "print(f\"Bootstrap parameters:\")\n",
    "print(f\"  Samples: n_boot = {n_bootstrap:,}\")\n",
    "print(f\"  Confidence: {confidence_level:.0%}\")\n",
    "    \n",
    "    \n",
    "# calculate bootstrap metrics\n",
    "bootstrap_metrics = calculate_bootstrap_metrics(y_test, y_pred, y_pred_proba, n_bootstrap=n_bootstrap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aac1ffe",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-exercise\">\n",
    "<h4>QUESTION: Calculate Bootstrap CI</h4>\n",
    "\n",
    "Write a python function that calculates bootstrap CI for accuracy metrics using percentile method.\n",
    "\n",
    "```\n",
    "def bootstrap_ci(data, confidence=0.95):\n",
    "    \"\"\"\n",
    "    Calculates bootstrap CI using percentile method.\n",
    "\n",
    "    Args:\n",
    "        data (np.array): sample data\n",
    "        confidence (float, optional): confidence level. Defaults to 0.95.\n",
    "\n",
    "    Returns:\n",
    "        lower and upper bounds of CI\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d405f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "def bootstrap_ci(data, confidence=0.95):\n",
    "    \"\"\"\n",
    "    Calculates bootstrap CI using percentile method.\n",
    "\n",
    "    Args:\n",
    "        data (np.array): sample data\n",
    "        confidence (float, optional): confidence level. Defaults to 0.95.\n",
    "\n",
    "    Returns:\n",
    "        lower and upper bounds of CI\n",
    "    \"\"\"\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593488ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate CIs    \n",
    "cis = {metric: bootstrap_ci(values) for metric, values in bootstrap_metrics.items()}\n",
    "    \n",
    "print(f\"{'Metric':<25s} {'Estimate':<12s} {'95% CI Lower':<15s} {'95% CI Upper':<15s} {'Width':<12s}\")\n",
    "print(\"-\" * 90)\n",
    "    \n",
    "metrics_display = [\n",
    "        ('accuracy', 'Accuracy', accuracy),\n",
    "        ('precision', 'Precision', precision),\n",
    "        ('recall', 'Recall', recall),\n",
    "        ('f1', 'F1-Score', f1),\n",
    "        ('auc', 'AUC-ROC', auc),\n",
    "        ('fraud_detection_rate', 'Fraud Detection Rate', fraud_detection_rate),\n",
    "        ('false_alarm_rate', 'False Alarm Rate', false_alarm_rate)\n",
    "    ]\n",
    "    \n",
    "for key, name, est in metrics_display:\n",
    "    ci = cis[key]\n",
    "    width = ci[1] - ci[0]\n",
    "    print(f\"{name:<25s} {est:<12.4f} {ci[0]:<15.4f} {ci[1]:<15.4f} {width:<12.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b179c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def business_reqs_check(cis, min_recall, max_false_alarm, min_precision, recall, false_alarm_rate, precision):\n",
    "    \n",
    "    print(\"BUSINESS REQUIREMENTS:\")\n",
    "    print(f\"  âœ“ Fraud Detection Rate â‰¥ {min_recall:.0%} (high recall)\")\n",
    "    print(f\"  âœ“ False Alarm Rate â‰¤ {max_false_alarm:.0%} (low false positives)\")\n",
    "    print(f\"  âœ“ Precision â‰¥ {min_precision:.0%} (accuracy when flagging fraud)\")\n",
    "    print()\n",
    "    \n",
    "    # Check requirements using LOWER bounds of CIs (conservative)\n",
    "    recall_lower = cis['recall'][0]\n",
    "    fpr_upper = cis['false_alarm_rate'][1]  # Use upper bound (worst case)\n",
    "    precision_lower = cis['precision'][0]\n",
    "    \n",
    "    meets_recall = recall_lower >= min_recall\n",
    "    meets_fpr = fpr_upper <= max_false_alarm\n",
    "    meets_precision = precision_lower >= min_precision\n",
    "    \n",
    "    req_check = f\"\"\"\n",
    "    EVALUATION (using CI bounds for conservative assessment):\n",
    "    \n",
    "    Recall Requirement:\n",
    "      Point estimate: {recall:.1%}\n",
    "      95% CI: [{cis['recall'][0]:.1%}, {cis['recall'][1]:.1%}]\n",
    "      Lower bound ({recall_lower:.1%}) {'â‰¥' if meets_recall else '<'} {min_recall:.0%}\n",
    "      Status: {'âœ“ PASS' if meets_recall else 'âœ— FAIL'}\n",
    "        \n",
    "    False Alarm Rate Requirement:\n",
    "      Point estimate: {false_alarm_rate:.1%}\n",
    "      95% CI: [{cis['false_alarm_rate'][0]:.1%}, {cis['false_alarm_rate'][1]:.1%}]\n",
    "      Upper bound ({fpr_upper:.1%}) {'â‰¤' if meets_fpr else '>'} {max_false_alarm:.0%}\n",
    "      Status: {'âœ“ PASS' if meets_fpr else 'âœ— FAIL'}\n",
    "    \n",
    "    Precision Requirement:\n",
    "      Point estimate: {precision:.1%}\n",
    "      95% CI: [{cis['precision'][0]:.1%}, {cis['precision'][1]:.1%}]\n",
    "      Lower bound ({precision_lower:.1%}) {'â‰¥' if meets_precision else '<'} {min_precision:.0%}\n",
    "      Status: {'âœ“ PASS' if meets_precision else 'âœ— FAIL'}\n",
    "    \"\"\"\n",
    "    \n",
    "    #print(req_check)\n",
    "    \n",
    "    # Overall decision\n",
    "    all_pass = meets_recall and meets_fpr and meets_precision\n",
    "    \n",
    "    \n",
    "    req_check = req_check + f\"\"\"\n",
    "    DEPLOYMENT DECISION: {'âœ“ APPROVE' if all_pass else 'âœ— DO NOT APPROVE'}\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if all_pass:\n",
    "        print(\"The model meets all business requirements with 95% confidence.\")\n",
    "        print(\"Recommendation: PROCEED TO PRODUCTION\")\n",
    "    else:\n",
    "        print(\"The model does not meet all requirements.\")\n",
    "        print(\"Recommendation: IMPROVE MODEL OR ADJUST REQUIREMENTS\")\n",
    "        \n",
    "    return req_check, all_pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d71286",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_lower = cis['recall'][0]\n",
    "fpr_upper = cis['false_alarm_rate'][1]  # Use upper bound (worst case)\n",
    "precision_lower = cis['precision'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6972659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business requirements\n",
    "min_recall = 0.70  # Must detect at least 70% of fraud\n",
    "max_false_alarm = 0.10  # Maximum 10% false alarm rate\n",
    "min_precision = 0.30  # At least 30% precision\n",
    "    \n",
    "req_check, all_pass = business_reqs_check(cis, min_recall, max_false_alarm, min_precision, recall, false_alarm_rate, precision)\n",
    "\n",
    "print(req_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811179e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# visualisation\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "gs = fig.add_gridspec(4, 3, hspace=0.4, wspace=0.3)\n",
    "\n",
    "# Plot 1: Confusion Matrix\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "\n",
    "cm_display = cm.astype(float)\n",
    "im = ax1.imshow(cm_display, cmap='Blues', alpha=0.7)\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        text = ax1.text(j, i, f'{cm[i, j]}\\n({cm[i,j]/np.sum(cm[i,:]):.1%})',\n",
    "                        ha=\"center\", va=\"center\", color=\"black\",\n",
    "                        fontsize=14, fontweight='bold')\n",
    "\n",
    "ax1.set_xticks([0, 1])\n",
    "ax1.set_yticks([0, 1])\n",
    "ax1.set_xticklabels(['Predicted\\nLegitimate', 'Predicted\\nFraud'])\n",
    "ax1.set_yticklabels(['Actual\\nLegitimate', 'Actual\\nFraud'])\n",
    "ax1.set_title('Confusion Matrix\\n(Test Set Performance)', \n",
    "                fontsize=13, fontweight='bold')\n",
    "\n",
    "# Plot 2: ROC Curve\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "\n",
    "fpr_roc, tpr_roc, _ = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "ax2.plot(fpr_roc, tpr_roc, linewidth=3, color='darkorange',\n",
    "        label=f'ROC (AUC = {auc:.3f})')\n",
    "ax2.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random')\n",
    "\n",
    "# Mark operating point\n",
    "ax2.plot([false_alarm_rate], [recall], 'ro', markersize=15,\n",
    "        label=f'Operating Point\\n(FPR={false_alarm_rate:.3f}, TPR={recall:.3f})')\n",
    "\n",
    "ax2.set_xlabel('False Positive Rate', fontsize=12)\n",
    "ax2.set_ylabel('True Positive Rate (Recall)', fontsize=12)\n",
    "ax2.set_title('ROC Curve', fontsize=13, fontweight='bold')\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Key Metrics with CIs\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "\n",
    "metrics_plot = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "estimates_plot = [accuracy, precision, recall, f1]\n",
    "cis_plot = [cis['accuracy'], cis['precision'], cis['recall'], cis['f1']]\n",
    "colors_plot = ['steelblue', 'green', 'orange', 'purple']\n",
    "\n",
    "y_pos = np.arange(len(metrics_plot))\n",
    "\n",
    "for i, (metric, est, ci, color) in enumerate(zip(metrics_plot, estimates_plot, cis_plot, colors_plot)):\n",
    "    ax3.barh(y_pos[i], ci[1] - ci[0], left=ci[0], height=0.4,\n",
    "            alpha=0.6, color=color)\n",
    "    ax3.plot(est, y_pos[i], 'o', markersize=15, color='red',\n",
    "            markeredgecolor='darkred', markeredgewidth=2, zorder=5)\n",
    "\n",
    "ax3.set_yticks(y_pos)\n",
    "ax3.set_yticklabels(metrics_plot)\n",
    "ax3.set_xlabel('Value', fontsize=12)\n",
    "ax3.set_title('Performance Metrics with 95% CIs\\n(Red = point estimate)',\n",
    "                fontsize=13, fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3, axis='x')\n",
    "ax3.set_xlim(0, 1)\n",
    "\n",
    "# Plots 4-7: Bootstrap distributions for key metrics\n",
    "metrics_boot = [('Accuracy', 'accuracy'), ('Precision', 'precision'),\n",
    "                ('Recall', 'recall'), ('F1-Score', 'f1')]\n",
    "\n",
    "for idx, (name, key) in enumerate(metrics_boot):\n",
    "    ax = fig.add_subplot(gs[1, idx if idx < 3 else idx-3])\n",
    "    \n",
    "    data = np.array(bootstrap_metrics[key])\n",
    "    est = estimates_plot[idx]\n",
    "    ci = cis[key]\n",
    "    \n",
    "    ax.hist(data, bins=50, alpha=0.6, color=colors_plot[idx], edgecolor='black')\n",
    "    ax.axvline(est, color='red', linewidth=3, label=f'Estimate: {est:.3f}')\n",
    "    ax.axvline(ci[0], color='darkred', linewidth=2, linestyle='--')\n",
    "    ax.axvline(ci[1], color='darkred', linewidth=2, linestyle='--')\n",
    "    \n",
    "    ax.set_xlabel(name, fontsize=11)\n",
    "    ax.set_ylabel('Frequency', fontsize=11)\n",
    "    ax.set_title(f'Bootstrap Distribution: {name}',\n",
    "                fontsize=12, fontweight='bold')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 8: Business Metrics\n",
    "ax8 = fig.add_subplot(gs[2, 0])\n",
    "\n",
    "business_names = ['Fraud\\nDetection\\nRate', 'False\\nAlarm\\nRate']\n",
    "business_ests = [fraud_detection_rate, false_alarm_rate]\n",
    "business_cis = [cis['fraud_detection_rate'], cis['false_alarm_rate']]\n",
    "business_colors = ['green', 'red']\n",
    "\n",
    "y_pos_bus = np.arange(len(business_names))\n",
    "\n",
    "for i, (name, est, ci, color) in enumerate(zip(business_names, business_ests, business_cis, business_colors)):\n",
    "    ax8.barh(y_pos_bus[i], ci[1] - ci[0], left=ci[0], height=0.4,\n",
    "            alpha=0.6, color=color)\n",
    "    ax8.plot(est, y_pos_bus[i], 'o', markersize=15, color='darkblue',\n",
    "            markeredgecolor='black', markeredgewidth=2, zorder=5)\n",
    "\n",
    "# Add requirement lines\n",
    "ax8.axvline(min_recall, color='green', linewidth=2, linestyle=':',\n",
    "            label=f'Min Required: {min_recall:.0%}')\n",
    "ax8.axvline(max_false_alarm, color='red', linewidth=2, linestyle=':',\n",
    "            label=f'Max Allowed: {max_false_alarm:.0%}')\n",
    "\n",
    "ax8.set_yticks(y_pos_bus)\n",
    "ax8.set_yticklabels(business_names)\n",
    "ax8.set_xlabel('Rate', fontsize=12)\n",
    "ax8.set_title('Business-Critical Metrics with Requirements',\n",
    "                fontsize=13, fontweight='bold')\n",
    "ax8.legend(fontsize=10)\n",
    "ax8.grid(True, alpha=0.3, axis='x')\n",
    "ax8.set_xlim(0, 1)\n",
    "\n",
    "# Plot 9: Requirements Check\n",
    "ax9 = fig.add_subplot(gs[2, 1])\n",
    "ax9.axis('off')\n",
    "\n",
    "ax9.text(0.5, 0.3, req_check, fontsize=10, family='monospace',\n",
    "        verticalalignment='center', horizontalalignment='center',\n",
    "        bbox=dict(boxstyle='round',\n",
    "                    facecolor='lightgreen' if all_pass else 'lightcoral',\n",
    "                    alpha=0.4))\n",
    "\n",
    "# Plot 10: Cost-Benefit Analysis\n",
    "ax10 = fig.add_subplot(gs[2, 2])\n",
    "\n",
    "# Assuming costs\n",
    "cost_fp = 50  # Cost per false positive (customer friction)\n",
    "cost_fn = 1000  # Cost per false negative (fraud loss)\n",
    "n_transactions_monthly = 100000\n",
    "fraud_rate = 0.05\n",
    "\n",
    "# Expected costs\n",
    "expected_fp = n_transactions_monthly * (1 - fraud_rate) * false_alarm_rate\n",
    "expected_fn = n_transactions_monthly * fraud_rate * (1 - recall)\n",
    "\n",
    "monthly_cost_fp = expected_fp * cost_fp\n",
    "monthly_cost_fn = expected_fn * cost_fn\n",
    "total_monthly_cost = monthly_cost_fp + monthly_cost_fn\n",
    "\n",
    "costs = ['False Positives\\n(Customer Friction)', 'False Negatives\\n(Fraud Losses)']\n",
    "cost_values = [monthly_cost_fp, monthly_cost_fn]\n",
    "cost_colors = ['orange', 'red']\n",
    "\n",
    "bars = ax10.bar(costs, cost_values, color=cost_colors, alpha=0.7,\n",
    "                edgecolor='black', linewidth=2)\n",
    "\n",
    "# Add value labels\n",
    "for bar, value in zip(bars, cost_values):\n",
    "    height = bar.get_height()\n",
    "    ax10.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'${value:,.0f}',\n",
    "                ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "ax10.set_ylabel('Monthly Cost ($)', fontsize=12)\n",
    "ax10.set_title(f'Expected Monthly Costs\\nTotal: ${total_monthly_cost:,.0f}',\n",
    "                fontsize=13, fontweight='bold')\n",
    "ax10.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 11: Production Monitoring Plan\n",
    "ax11 = fig.add_subplot(gs[3, :])\n",
    "ax11.axis('off')\n",
    "\n",
    "monitoring_plan = f\"\"\"\n",
    "PRODUCTION MONITORING PLAN WITH CI-BASED ALERTS\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "ALERT THRESHOLDS (based on 95% Confidence Intervals):\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Metric              â”‚ Point Est     â”‚ CI Lower (95%)    â”‚ Alert Threshold   â”‚ Action          â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ Recall              â”‚ {recall:>6.1%}        â”‚ {recall_lower:>6.1%}            â”‚ < {recall_lower:.1%}          â”‚ CRITICAL         â”‚\n",
    "â”‚ Precision           â”‚ {precision:>6.1%}        â”‚ {precision_lower:>6.1%}            â”‚ < {precision_lower:.1%}          â”‚ WARNING        â”‚\n",
    "â”‚ False Alarm Rate    â”‚ {false_alarm_rate:>6.1%}        â”‚ {fpr_upper:>6.1%}            â”‚ > {fpr_upper:.1%}            â”‚ CRITICAL        â”‚\n",
    "â”‚ F1-Score            â”‚ {f1:>6.1%}        â”‚ {cis['f1'][0]:>6.1%}            â”‚ < {cis['f1'][0]:.1%}            â”‚ WARNING        â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "EXPECTED PERFORMANCE RANGES (with 95% confidence):\n",
    "â€¢ Accuracy: [{cis['accuracy'][0]:.1%}, {cis['accuracy'][1]:.1%}]\n",
    "â€¢ Precision: [{cis['precision'][0]:.1%}, {cis['precision'][1]:.1%}]\n",
    "â€¢ Recall: [{cis['recall'][0]:.1%}, {cis['recall'][1]:.1%}]\n",
    "â€¢ F1-Score: [{cis['f1'][0]:.1%}, {cis['f1'][1]:.1%}]\n",
    "\n",
    "Performance within these ranges is EXPECTED and NORMAL.\n",
    "Performance outside these ranges requires INVESTIGATION.\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\"\n",
    "\n",
    "ax11.text(0.5, 0.1, monitoring_plan, fontsize=8.5, family='monospace',\n",
    "            verticalalignment='center', horizontalalignment='center',\n",
    "            bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3))\n",
    "\n",
    "plt.suptitle('ML Pipeline Executive Dashboard: Fraud Detection Model with Confidence Intervals',\n",
    "            fontsize=16, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ef5dc7",
   "metadata": {},
   "source": [
    "We can imagine the following monitoring strategy:\n",
    "    \n",
    "1. REAL-TIME MONITORING:\n",
    "    - Track all metrics on rolling 24-hour windows\n",
    "    - Compare against alert thresholds\n",
    "    - Automatic alerts when thresholds breached\n",
    "    \n",
    "2. WEEKLY REVIEW:\n",
    "    - Recompute bootstrap CIs on recent data\n",
    "    - Check for distribution drift\n",
    "    - Update thresholds if necessary\n",
    "    \n",
    "3. MONTHLY AUDIT:\n",
    "    - Full model re-evaluation\n",
    "    - Business impact assessment\n",
    "    - Cost-benefit analysis update\n",
    "    - Decision: continue, retrain, or replace\n",
    "    \n",
    "4. ESCALATION PROTOCOL:\n",
    "    - WARNING: Notify ML team, investigate within 48h\n",
    "    - CRITICAL: Page on-call engineer, investigate immediately\n",
    "    - Multiple alerts: Consider emergency rollback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b655aa",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<h4>âš ï¸ Common Misconception: K-Fold CV â‰  Confidence Intervals</h4>\n",
    "<p><strong>The Mistake:</strong> Many practitioners report k-fold cross-validation results as \"mean Â± std\" and treat this as a confidence interval. This is statistically incorrect!</p>\n",
    "\n",
    "<p><strong>Why K-Fold CV Doesn't Give Proper CIs:</strong></p>\n",
    "<ul>\n",
    "    <li><strong>Dependence Problem:</strong> The k scores are <em>not independent</em> â€” training sets overlap heavily between folds (each data point appears in k-1 training sets)</li>\n",
    "    <li><strong>Underestimated Variance:</strong> Because of correlation, the standard error calculated from k folds is biased downward</li>\n",
    "    <li><strong>No Coverage Guarantees:</strong> You can't claim \"95% confidence\" using the normal formula â€” the actual coverage may be far from 95%</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>What Each Method Is Actually For:</strong></p>\n",
    "<table style=\"width:100%; margin: 10px 0; border-collapse: collapse;\">\n",
    "    <tr style=\"background-color: rgba(0,0,0,0.05);\">\n",
    "        <th style=\"padding: 8px; text-align: left; border: 1px solid #ddd;\"></th>\n",
    "        <th style=\"padding: 8px; text-align: left; border: 1px solid #ddd;\">K-Fold Cross-Validation</th>\n",
    "        <th style=\"padding: 8px; text-align: left; border: 1px solid #ddd;\">Bootstrap CI</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"padding: 8px; border: 1px solid #ddd;\"><strong>Purpose</strong></td>\n",
    "        <td style=\"padding: 8px; border: 1px solid #ddd;\">Model selection & comparison</td>\n",
    "        <td style=\"padding: 8px; border: 1px solid #ddd;\">Uncertainty quantification with statistical guarantees</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: rgba(0,0,0,0.02);\">\n",
    "        <td style=\"padding: 8px; border: 1px solid #ddd;\"><strong>What you get</strong></td>\n",
    "        <td style=\"padding: 8px; border: 1px solid #ddd;\">Robust estimate of expected performance</td>\n",
    "        <td style=\"padding: 8px; border: 1px solid #ddd;\">Range with known coverage probability</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"padding: 8px; border: 1px solid #ddd;\"><strong>Valid reporting</strong></td>\n",
    "        <td style=\"padding: 8px; border: 1px solid #ddd;\">\"Mean accuracy: 0.85 Â± 0.03\"</td>\n",
    "        <td style=\"padding: 8px; border: 1px solid #ddd;\">\"95% CI: [0.82, 0.88]\"</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<p><strong>Best Practice in ML Pipelines:</strong></p>\n",
    "<ol>\n",
    "    <li><strong>During development:</strong> Use k-fold CV to compare and select models</li>\n",
    "    <li><strong>For final reporting:</strong> After choosing your model, use bootstrap on the held-out test set to get proper confidence intervals for performance metrics</li>\n",
    "    <li><strong>Never:</strong> Don't treat k-fold CV standard deviation as if it gives you confidence intervals</li>\n",
    "</ol>\n",
    "\n",
    "<p style=\"margin-top: 15px;\"><strong>ðŸ’¡ Remember:</strong> K-fold CV helps you make better decisions about which model to choose. Bootstrap CIs help you communicate the uncertainty in your final model's performance with statistical rigor.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7ad724",
   "metadata": {},
   "source": [
    "## Return to the Opening Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343f4e49",
   "metadata": {},
   "source": [
    "Original scenario:\n",
    "- Reported model accuracy: 94.2%\n",
    "- Reality in production: 92.5%\n",
    "\n",
    "**Need for uncertainty quantification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005fc850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate the original situation\n",
    "n_test = 500\n",
    "observed_correct = 471  # 94.2%\n",
    "p_hat = observed_correct / n_test # proportion point estimate \n",
    "\n",
    "print(f\"Proportion point estimate: {p_hat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ea33ba",
   "metadata": {},
   "source": [
    "What should have been done:\n",
    "\n",
    "1. Compute CI for proportion\n",
    "\n",
    "Let's consider 95% confidence level. Therefore, $\\alpha = 1 - 0.95 = 0.05 \\Rightarrow \\alpha/2 = 0.025 \\Rightarrow z_{\\alpha/2} = 1.96$.\n",
    "\n",
    "$SE = \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}} = \\sqrt{\\frac{0.942(1 - 0.942)}{500}} = \\sqrt{0.0001} = 0.01$\n",
    "\n",
    "$$\\begin{array}{l}\\hat{p} - z_{\\alpha/2}\\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}} = 0.942 - 1.96 \\times 0.01 = 0.9224\\\\ \\hat{p} + z_{\\alpha/2}\\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}} =  0.642 + 1.96 \\times 0.01 = 0.962\\end{array}$$\n",
    "\n",
    "\n",
    "In Python, we can also use [statsmodels.stats.proportion.proportion_confint](https://www.statsmodels.org/dev/generated/statsmodels.stats.proportion.proportion_confint.html) to calculate a confidence interval for a binomial proportion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc24290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportion_confint # CI for binomial proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104a449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = 0.95\n",
    "ci = proportion_confint(observed_correct, n_test, alpha=1-conf, method='normal')\n",
    "    \n",
    "print(f\"CI for proportion:\")\n",
    "print(f\"   Test set: n = {n_test}\")\n",
    "print(f\"   Observed accuracy: {p_hat:.1%}\")\n",
    "print(f\"   95% CI: [{ci[0]:.1%}, {ci[1]:.1%}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40477b0",
   "metadata": {},
   "source": [
    "2. Report to stakeholders:\n",
    "\n",
    "- Our model achieved 94.2% accuracy on the test set.\n",
    "- With 95% confidence, the true accuracy is between 92.2% and 96.2%.\n",
    "- In production, we should expect performance in this range.\n",
    "\n",
    "3. Set expectations:\n",
    "- Worst case: accuracy could be as low as 92.2%\n",
    "- If our minimum requirement is 85%, it still exceeds it.\n",
    "\n",
    "4. Observed in production: 92.2%\n",
    "- Within the predicted range. No crisis.\n",
    "- Stakeholders were properly informed of uncertainty.\n",
    "\n",
    "**Lessons learned:**\n",
    "\n",
    "- Always report uncertainty, not just point estimates\n",
    "- Use CIs to set realistic expectations\n",
    "- Design monitoring systems around CI bounds\n",
    "- Your credibility depends on honest uncertainty quantification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4d2c1b",
   "metadata": {},
   "source": [
    "## Common Mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2dab51",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<h4>âš ï¸ Common Pitfalls</h4>\n",
    "\n",
    "- Misinterpreting CI as probability statement\n",
    "- Using normal approximation for small samples\n",
    "- Forgetting to check assumptions\n",
    "- Reporting point estimate without CI\n",
    "- Confusing statistical and practical significance\n",
    "- Using wrong method for proportions (use Wilson)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4de3176",
   "metadata": {},
   "source": [
    "## ML Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24272526",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-primary\">\n",
    "<h4>ðŸ¤– ML Applications</h4>\n",
    "\n",
    "- Model Evaluation: Always report metrics with CIs\n",
    "- A/B Testing: Compare models using CI for difference\n",
    "- Production Monitoring: Set alert thresholds based on CI bounds\n",
    "- Stakeholder Communication: Honest reporting of uncertainty\n",
    "- Risk Management: Worst-case scenarios from CI bounds\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eafb588",
   "metadata": {},
   "source": [
    "## Key Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099d03c7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-summary\">\n",
    "<h4>ðŸŽ“ Key Takeaways</h4>\n",
    "\n",
    "1. Confidence Intervals:\n",
    "\n",
    "- Range of plausible values for unknown parameter\n",
    "- Correct interpretation: \"95% of such intervals contain $\\theta$\" (frequentist)\n",
    "- NOT: \"95% probability $\\theta$ is in this interval\"\n",
    "- Components: Point estimate Â± Margin of error\n",
    "\n",
    "2. Construction Methods:\n",
    "\n",
    "Pivot method: Use quantity with known distribution\n",
    "Normal approximation: For means (use t-distribution when Ïƒ unknown)\n",
    "Bootstrap: For any statistic, no assumptions needed\n",
    "Special formulas: Proportions, differences, etc.\n",
    "\n",
    "3. Interpreting CIs:\n",
    "\n",
    "- Width indicates precision\n",
    "- Wider CI = more uncertainty\n",
    "- Factors: sample size, variability, confidence level\n",
    "- CI overlapping zero = no significant difference\n",
    "\n",
    "4. Key Formulas:\n",
    "\n",
    "- Mean ($\\sigma$ unknown):\n",
    "$$\\bar{X} \\pm t_{\\alpha/2, n-1} \\times \\frac{s}{\\sqrt{n}}$$\n",
    "- Proportion:\n",
    "$$\\hat{p} \\pm z_{\\alpha/2} \\times \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}$$\n",
    "- Variance:\n",
    "- Bootstrap percentile:\n",
    "$[Q_{\\alpha/2}, Q_{1-\\alpha/2}]$ of bootstrap distribution\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cca1c67",
   "metadata": {},
   "source": [
    "## Useful Links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f3781d",
   "metadata": {},
   "source": [
    "1. [Confidence Intervals, Clearly Explained!!! by StatQuest](https://www.youtube.com/watch?v=TqOeMYtOc1w)\n",
    "2. [What are degrees of freedom? by James Gilbert](https://www.youtube.com/watch?v=rATNoxKg1yA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "probability-statistics-ai-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
